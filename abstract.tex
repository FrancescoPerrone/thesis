\chapter{Abstract}

Moral behaviour emerges not from isolated cognitive modules or explicit reasoning, but from a structured evaluative field shaped by attention, affect, salience, and dispositional architecture. This thesis develops a field-theoretic account of moral cognition grounded in empirical data, formal topology, and the philosophy of information. It argues that artificial systems—particularly humanoid robots—interact with this evaluative field in ways that conventional, rule-based Machine Ethics fails to capture.

A controlled behavioural experiment tested whether the silent presence of a humanoid robot (NAO) modulates prosocial giving under a strong moral cue (the Watching-Eye paradigm). Bayesian estimation and distribution-sensitive regression models reveal a modest but directionally consistent attenuation: participants donated less in the robot’s presence despite identical moral affordances. Psychometric measures (EQ, SQ, BFI-10) were used to construct latent dispositional ecologies, which exhibited *heterogeneous* susceptibility to the perturbation. The Prosocial–Empathic cluster showed the strongest attenuation; the Analytical–Structured cluster showed little to none; the Emotionally Reactive cluster showed high variability. These findings confirm that synthetic presence interacts with evaluative topology rather than exerting a uniform behavioural effect.

Interpreted through the mapping $f(\alpha_E, \beta_C, \gamma_R)$ and Floridi’s Levels of Abstraction, the results support a structural account in which synthetic presence functions as a perturbation operator. NAO’s embodied ambiguity refracts intuitive appraisal: it alters attentional weighting, dilutes affective resonance, and redistributes moral salience before explicit reasoning is engaged. The robot does not supply moral content; it reshapes the perceptual and affective scaffolds through which such content acquires behavioural force.

The thesis concludes that artificial agents, even without agency or intent, act as modifiers of human moral environments. Moral behaviour is shown to be field-dependent, topologically organised, and sensitive to synthetic co-presence. These findings expose a limitation of top-down Machine Ethics and motivate an ecological model of artificial systems—one that prioritises the governance of the evaluative environments machines co-create with humans. The work establishes a methodological foundation for a computational and topological study of moral cognition in the age of artificial presence.
