\chapter{Conclusion}
\label{chap:conclusion}

\section{Returning to the Question: What This Thesis Has Shown}

The Introduction framed this work around a deceptively simple research problem: \emph{does the mere presence of a humanoid robot alter the transformation of morally salient cues into moral action?}  Formally, this was articulated in Question~\ref{q:robot-agent1} and operationalised through three hypotheses (H1–H3) anchored in the evaluative mapping
\[
f(\alpha_E, \beta_C, \gamma_R),
\]

which models how environmental cues, dispositional structure, and synthetic presence jointly shape behavioural output. The core task of the thesis was to determine whether this mapping is susceptible to perturbation, and what such susceptibility reveals about the architecture of human moral cognition.

Across the chapters that followed, this problem—posed abstractly in the Introduction—developed into an empirical and conceptual investigation of how
humans register moral salience in the presence of non-human bodies. Drawing on
contemporary models of moral psychology that emphasise intuitive,
affect-laden appraisals over reflective deliberation~\cite{Haidt2001,Greene2001,Greene2002,Cushman2013},
the experimental work examined whether NAO influences the early evaluative
stages that precede conscious reasoning. The design therefore situated
participants within a minimally structured moral environment, introducing
$\gamma_R$ as a silent, embodied presence whose influence could arise only
through its perceptual affordances.

With this concluding chapter, we return to the commitments articulated at the
start. The results now allow us to say, with the empirical grounding that the
Introduction could only anticipate, that the evaluative process is indeed
sensitive to synthetic presence.  

\vspace{0.2em}
\noindent
\textbf{H1 (Evaluative Deformation)} is supported: the expected behavioural
output under $\Sigma \cup \mathscr{R}$ diverges from that under $\Sigma$ alone.  

\noindent
\textbf{H2 (Synthetic Normativity)} is refined: NAO does not generate new
normative affordances but modulates the salience of existing ones through its
informational and embodied profile.  

\noindent
\textbf{H3 (Synthetic Perturbation of Moral Inference)} is supported: the
influence of $\gamma_R$ manifests in the perceptual–affective transition from
moral cue to action, not in explicit deliberation.  

\noindent
Moreover, the evaluative mapping $f(\alpha_E, \beta_C, \gamma_R)$ predicted a
structured form of dispositional heterogeneity—an expectation borne out in the
latent trait ecologies recovered via clustering, where perturbation effects
concentrated within the Prosocial--Empathic regime and remained muted or
absent elsewhere.

Crucially, the thesis has treated these findings with the epistemic caution appropriate for a subtle effect in a modest dataset. Bayesian estimation explicitly accommodates uncertainty arising from zero-inflated donation data
and uneven cluster sizes: the posterior for the donation difference is skewed toward attenuation, yet reflects the heterogeneity of cognitive–affective architectures rather than compressing evidence into a binary verdict. This probabilistic contour strengthens the interpretive claim: when moral cognition
operates intuitively, ambiguity in the environment should appear as ambiguity in the data.

This leads to the broader significance of the work. The results suggest that:

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{Human moral appraisal is structurally sensitive to the perceptual ecology in
			which it unfolds.}
	\end{leftbar}
\end{center}

\bigskip
\noindent

Moral behaviour emerges from a sequence of cognitive–affective
transitions shaped by what is noticed, foregrounded, or rendered ambiguous. Synthetic presence makes this sensitivity visible: even a minimally expressive artificial body can redirect the flow of evaluative attention, thereby altering
the probability that moral salience becomes action.

In bringing these strands together, this chapter begins where the Introduction left off: with the claim that artificial systems participate in human moral life long before they reason, decide, or speak. What the experiment now shows
is that their influence arises from how they reconfigure the perceptual and affective scaffolds through which moral meaning is formed. 

The remainder of the Conclusion develops this insight, situating it within social robotics, affective computing, and the philosophy of moral cognition, and drawing the
thesis toward its final synthesis.

\section{Contributions to Human--Robot Interaction, Affective Computing, and Moral Cognition}

The empirical and conceptual results developed throughout this thesis amount to a set of contributions that cut across three adjacent domains: human--robot interaction (HRI), affective computing, and the study of moral cognition.  

While each field approaches social behaviour from a distinct methodological tradition, the present work shows that the phenomenon under investigation---the 
attenuation of prosocial action under synthetic co-presence---sits precisely at their intersection. The following synthesis articulates these contributions in a 
form that reflects the structural unity of this research.

\subsection{Contribution to Human--Robot Interaction}

Within HRI, the dominant research programmes have traditionally focused on interactional behaviours: communication, signalling, collaboration, engagement,trust, and alignment~\cite{GoodrichSchultz2007, Breazeal2003, Lee2010, Hancock2011, Fischer2011}. The present study contributes a different insight:


\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{Interaction is not required for a humanoid robot to exert a measurable influence on human behaviour}
	\end{leftbar}
\end{center}

\bigskip
\noindent

NAO's silent presence reshaped the evaluative conditions under 
which participants interpreted a morally salient cue in experimental setting. This demonstrates that robots 
participate in human moral environments not only through explicit social action but also through their perceptual affordances, spatial occupation, and ontological ambiguity. 

This finding positions synthetic presence as an \emph{environmental factor} in HRI---a contributor to the structure of the evaluative field rather than a node in 
an interactional sequence. The notion of robotic co-presence as a ``semiotic operator'' opens conceptual space for a new class of HRI effects: those that emerge upstream of explicit social behaviour, and which operate through shifts in attention, salience, and interpretive framing.

\subsection{Synthetic Presence and Floridi’s Account of Moral Agency}

A central question naturally arises from the empirical findings of this thesis:

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{if NAO reshapes the evaluative conditions under which morally salient cues are interpreted under experimental settings, what does this imply for its moral status within Floridi’s framework of agency, patiency, and informational relevance?}
	\end{leftbar}
\end{center}

\bigskip
\noindent

Addressing this question clarifies both the conceptual footing of the results and their broader implications for social robotics and machine ethics.

Floridi’s theory of moral agency distinguishes between three classes of entities: (i) \emph{moral agents}, capable of performing morally qualifiable actions; (ii) \emph{moral patients}, capable of moral harm or benefit; and (iii) a broader class of \emph{morally relevant informational objects}, whose properties modulate the normative landscape without possessing agency or interests~\cite{FloridiSanders2004,Floridi2013}. 

Within this taxonomy, NAO is neither an agent nor a patient: it issues no commands, performs no autonomous decisions, and has no capacity for norm-responsive deliberation or moral vulnerability.

Yet the empirical results show that NAO is not normatively inert. The robot exerts a measurable influence on the evaluative transformation
\[
f(\alpha_E, \beta_C, \gamma_R),
\]
not by acting or reasoning, but by altering the \emph{informational environment} in which human agents interpret moral cues. In Floridi’s terms, NAO functions as a \emph{morally relevant artefact}: its perceptual 
affordances—embodied form, gaze, spatial presence, and subtle motion—shape the *potential* salience landscape at the operative Level of Abstraction~\cite{Floridi2011,Floridi2013}. 

At this LoA, participants do not encounter the robot as source code or computation. They encounter it as a \emph{semiotic body}~\cite{Coeckelbergh2010,Coeckelbergh2020}: an 
entity that appears socially expressive while lacking the behavioural depth of a human agent. This ontological ambiguity, we claim, is precisely what enables the perturbation observed in the experiment. The robot does not generate new norms (refining H2), nor does it provide explicit reasons for action; instead, it \emph{modulates the salience of existing cues}, 
bending the intuitive trajectory through which the Watching-Eye stimulus gains behavioural force \cite{Conty2016,Dear2019}. 

Situating NAO as a morally relevant informational object strengthens the central conclusion. It shows why synthetic presence can reshape moral behaviour without 
approaching the threshold of moral agency, and it clarifies a conceptual point often missed in Machine Ethics: 

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{artificial systems can exert morally significant influence 
			prior to, and independent of, any capacity for ethical reasoning.}~\cite{Moor2006,Wallach2008}
	\end{leftbar}
\end{center}

\bigskip
\noindent
Their normative impact arises from the environmental and 
semiotic roles they occupy within human cognitive ecologies 
\cite{Floridi2013,Coeckelbergh2020}. In this sense, Floridi’s framework does not merely accommodate the findings; it provides 
the conceptual architecture that renders them intelligible. NAO’s influence is not paradoxical but the predictable consequence of how informational artefacts participate 
in—and subtly deform—the evaluative landscapes through which human moral cognition operates.


\subsection{Contribution to Affective Computing and Social Signal Processing}

In affective computing and social signal processing, a central ambition is to infer 
latent cognitive--affective processes from observable behavioural traces.  
The experiment presented in this thesis provides an empirical demonstration that 
moral behaviour—here, prosocial donation—can serve as such a behavioural indicator.  
The attenuation observed under synthetic presence suggests that moral evaluations, 
although not directly observable, leave systematic behavioural traces when the 
evaluative topology is perturbed.  
This is consistent with the foundational premise of affective computing that latent 
states become inferable through patterned interactions between behaviour and context 
\cite{Picard1997,CalvoD2010,Vinciarelli2009,Vinciarelli2014}.

A methodological insight follows:

\begin{center}
	\begin{leftbar}
		\textit{latent dispositional architecture can be recovered from psychometric and 
			behavioural data in a way that reveals differential susceptibility to contextual 
			perturbation.}
	\end{leftbar}
\end{center}

The three dispositional ecologies identified through clustering (Emotionally 
Reactive, Prosocial--Empathic, Analytical--Structured) illustrate how personality 
configurations form distinct regions in evaluative space.  
These ecologies show that affective modulation by artificial systems is a 
\emph{structure-sensitive} process, linking affective computing’s interest in latent 
state inference with HRI’s concern for the social affordances of synthetic presence.  
Comparable patterns in social signal processing show that stable dispositional 
profiles shape responsiveness to contextual cues and interpersonal signals 
\cite{Pentland2007,Banks2020,Habashi2016}.

Finally, the Bayesian modelling framework demonstrates how uncertainty—a constitutive 
property of both affective states and behavioural data—can be represented as a 
structured epistemic gradient rather than statistical noise.  
This aligns Bayesian inference with the broader aims of affective computing: to 
quantify latent evaluative processes under contextual variability, in continuity with 
hierarchical Bayesian approaches in computational cognitive science 
\cite{Tenenbaum2011,Kruschke2014}.  


\subsection{Contribution to Moral Cognition Research}

Within moral psychology, the present findings contribute evidence for an intuitionist and ecological interpretation of moral judgement. Consistent with leading models of intuitive moral appraisal and dual-process architectures 
\cite{Haidt2001,Greene2001,Greene2002,Greene2014,Cushman2013}, the study shows 
that moral behaviour is shaped by the perceptual and affective scaffolds through 
which salient cues are first registered. The attenuation effect emerges 
\emph{prior} to deliberation, within the cognitive--affective space where 
intuitive appraisals and affect-driven evaluations are formed. This aligns with 
work demonstrating that moral cognition is sensitive to subtle environmental 
modulation—implicit monitoring, gaze cues, ambient social presence 
\cite{Haley2005,Bateson2006,Conty2016,Dear2019}—and extends these findings to 
\emph{synthetic} social affordances \cite{Zlotowski2015,Groom2010,Malle2016}.

A central contribution lies in the demonstration that moral susceptibility is 
\emph{trait-contingent}. The Prosocial--Empathic profile, characterised by high 
interpersonal attunement and affective resonance, exhibited the clearest 
attenuation under NAO’s presence, while the Analytical--Structured and 
Emotionally Reactive profiles did not. This pattern empirically supports the 
prediction derived from the formalism $f(\alpha_E, \beta_C, \gamma_R)$: that 
dispositional architecture modulates how moral salience undergoes evaluative 
transformation. The finding is consistent with research showing that empathy, 
agreeableness, and prosocial orientation shape sensitivity to social cues and 
moral demands \cite{Habashi2016,Hilbig2013,Decety2004}, while extending this 
literature by demonstrating that such sensitivity generalises to \emph{synthetic}
embodied presence.

Taken together, the results show that moral cognition is both intuitive and 
ecologically embedded: structured by the interplay between perceptual 
environments and latent evaluative topologies. Synthetic presence provides a 
novel perturbation of this evaluative field, revealing the dispositional 
contours through which moral meaning becomes behaviour.

\subsection{Integrative Contribution: A Unified Field-Theoretic Approach}

The broader contribution of this research lies in unifying these three domains within a single explanatory framework. By treating moral behaviour as the output of an evaluative function influenced by environmental cues, dispositional 
architecture, and synthetic presence, the thesis provides a consistent conceptual vocabulary for explaining effects that span psychological, computational, and robotic contexts. This framework is field-theoretic in a strict sense: it arises directly from the formal decomposition 
$f(\alpha_E, \beta_C, \gamma_R)$ and models moral appraisal as movement through a structured evaluative landscape.

This account aligns with long-standing findings in moral psychology that behaviour emerges from affective appraisal and intuitive processing~\cite{Haidt2001,Greene2001,Decety2004}, with Social Signal Processing research showing that social cues reorganise attentional and evaluative structures~\cite{Pentland2007,Vinciarelli2009,Conty2016}, and with HRI evidence that robotic presence modulates human social and moral behaviour even in minimal-interaction 
settings~\cite{Kuchenbrandt2011,Malle2016,Bremner2022,Zlotowski2015}. Crucially, Floridi’s Levels of Abstraction supply the conceptual hinge: synthetic presence exerts influence at the perceptual LoA, independent of its internal architecture.

Across HRI, affective computing, and moral cognition, the central insight is the 
same:
\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{synthetic presence need not act, speak, or decide to shape moral behaviour; 
			it need only reorganise the evaluative conditions under which moral salience is 
			processed.}
	\end{leftbar}
\end{center}
\bigskip
\noindent
This insight establishes a theoretical bridge between empirical measurement, computational modelling, and philosophical analysis. It connects affective-computational approaches concerned with latent evaluative states \cite{Picard1997}, 
SSP models of multimodal social inference \cite{Vinciarelli2009}, and ecological accounts of context-sensitive moral judgement \cite{Haidt2001,Greene2014}. 

Taken together, these strands converge on a unified field-theoretic perspective in which artificial agents function not as loci of ethical reasoning but as operators on the 
evaluative topology through which moral meaning becomes behavioural output.

\subsection{A Unified Explanatory Structure Rather Than Three Independent Literatures}

One might ask whether the thesis merely juxtaposes contributions from three 
separate domains—moral psychology, Floridian information ethics, and social 
robotics—or whether these strands genuinely converge into a single explanatory 
framework. The answer, made clear only at the end of the research journey, is that the 
thesis was never structured as three parallel literatures. It was structured around a single phenomenon that demands all three.

The core explanatory object is the evaluative transformation
\[
f(\alpha_E, \beta_C, \gamma_R),
\]

which specifies how environmental cues, dispositional architectures, and synthetic presence jointly shape moral behaviour. Each literature supplies a different layer 
of this model: moral psychology identifies the intuitive and affective mechanisms that generate evaluative trajectories and explains why trait–contingent modulation 
should occur; Floridi's information ethics provides the ontological and epistemic conditions under which synthetic entities acquire moral relevance at a Level of 
Abstraction; and social robotics and Social Signal Processing provide the empirical and computational domains in which such perturbations become observable, measurable, and theoretically tractable.

Seen from this vantage point, the “field-theoretic” perspective is not a metaphor but the necessary generalisation of the mapping $f$. Moral cognition unfolds in a structured space of salience and attention, and synthetic presence acts as an 
operator that subtly reconfigures the geometry of that space. None of the three literatures could explain this phenomenon alone: moral psychology without LoA lacks 
an ontology of synthetic presence; information ethics without empirical grounding lacks a mechanism of perturbation; and HRI without a field-theoretic model lacks an account of why minimal presence should matter at all.

In this respect, the thesis does not merely connect disparate literatures; it reorganises them around a common evaluative architecture. The experimental results show that artificial agents participate in human moral environments not through 
ethical reasoning, but through the way their perceptual and ontological profiles modulate the topology through which moral meaning becomes action. This unification is the conceptual kernel that ties the entire research programme together.


\section{Final Synthesis and Closing Reflections}

\noindent
At the end of this research journey, the central phenomenon around which the thesis
was constructed can be stated with clarity: \emph{synthetic presence alters the
	conditions under which human beings register, evaluate, and act upon moral
	salience}. What began as a question about a quiet, non-interactive humanoid robot
has unfolded into a broader insight about the structure of moral cognition and the
ethical texture of technologically saturated environments.

The empirical work demonstrated that NAO’s presence does not introduce new moral
reasons, nor does it engage participants in explicit social interaction. Instead, it
reshapes the evaluative conditions under which moral cues acquire behavioural force.
This perturbation is subtle, probabilistic, and contingent upon latent dispositional
architecture—yet empirically robust. Across inferential contrasts, cluster-specific
analyses, and Bayesian estimation, the evidence converges on the same structural
interpretation: artificial systems participate in human moral situations by
modulating the perceptual and affective scaffolds from which intuitive moral
appraisals develop.

\medskip

\noindent
What makes this more than an isolated result is the conceptual synthesis that
underwrites it. The thesis has argued that moral behaviour is not a direct output of
rules or principles; it is the trajectory of a cognitive–affective system shaped by
attention, affect, expectation, and salience. Contemporary models of moral
psychology have long emphasised the primacy of intuitive evaluation
\cite{Haidt2001,Greene2001,Cushman2013}. Floridi’s Levels of Abstraction provide the
correct ontological lens for specifying where synthetic entities exert influence. HRI
and Affective Computing supply the methodological tools through which such influence
can be observed and modelled. When joined together, these literatures do not merely
complement one another—they reveal that the phenomenon under investigation requires
all of them to be intelligible~\cite{Katsyri2015, Fischer2023}.

\medskip

\noindent
A key outcome of this integration is the field-theoretic interpretation articulated
throughout the thesis. The evaluative mapping
\[
f(\alpha_E, \beta_C, \gamma_R)
\]
is not a formal artefact appended to the data; it is the conceptual structure that
makes sense of how environmental cues, dispositional architectures, and artificial
systems cooperate to shape moral behaviour. Moral appraisal unfolds within a dynamic
field of salience. Synthetic presence acts as an operator on that field—not by issuing
commands but by shifting the local geometry through which moral meaning is formed.
The experimental results show that even minimal artificial bodies can introduce such a
shift. This finding is modest in magnitude but profound in implication.

\medskip

\noindent
The ethical considerations developed in Chapter~8 sharpen this point. Traditional
Machine Ethics asks how to embed principles into machines. Yet the empirical evidence
here shows that artificial systems shape moral life not through principles but through
presence: through their semiotic affordances, their perceived ontology, and the
attentional demands they impose on human cognitive ecologies. In Floridi’s framework,
NAO is not a moral agent; it is a morally relevant informational object. Its influence
is neither agential nor normative in itself, but environmental: it alters the field in
which human agents construct their moral understanding. This is not a limit case or a
marginal curiosity. It is a demonstration that ethical relevance emerges from the
interaction between artefacts and the conditions of human moral cognition, long before
questions of machine agency arise.

\medskip

\noindent
From this vantage point, the contribution of the thesis becomes unmistakable. The
work provides an empirically grounded demonstration that artificial systems—humanoid
robots today, pervasive AI systems tomorrow—can reshape moral cognition through their
informational presence alone. It offers a formal architecture for modelling such
influence, a set of empirical methods for detecting it, and a conceptual framework for
understanding why it occurs. It also clarifies that the normative stakes of synthetic
presence lie not merely in what machines may eventually \emph{do}, but in how they
silently reorganise the evaluative landscape in which human moral behaviour unfolds.

\medskip

\noindent
This brings us back, finally, to the thesis’s animating question. Yes—synthetic
presence can perturb the evaluative transformation through which moral salience
becomes moral action. It can do so without interacting, without expressing norms,
without engaging in dialogue, and without crossing the threshold of moral agency. It
is enough that it is \emph{perceived}. This insight opens the way for a new research
programme in moral AI: one that takes seriously the structure of moral cognition, the
ecological nature of moral environments, and the field-level effects of artificial
systems embedded within them.

\medskip

\noindent
If this thesis has shown anything, it is that the future of moral AI will not begin
with building artificial moral agents. It will begin with understanding how
artificial systems already shape human moral life. The rest—ethical design, moral
alignment, normative governance—must follow from that foundational fact. The task now
is no longer to ask whether such influence exists, but to learn how to measure it,
model it, anticipate it, and ultimately, to govern the moral topologies we are
already co-constructing with our synthetic companions.

\medskip
\noindent
This is the horizon toward which the work now points. The thesis closes here, but the
evaluative field it uncovers is only beginning to take shape.
