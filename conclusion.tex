\chapter{Conclusion}
\label{chap:conclusion}

\section{Returning to the Question: What This Thesis Has Shown}

The Introduction framed this work around a deceptively simple research problem: \emph{does the mere presence of a humanoid robot alter the transformation of morally salient cues into moral action?}  Formally, this was articulated in Question~\ref{q:robot-agent1} and operationalised through three hypotheses (H1–H3) anchored in the evaluative mapping
\[
f(\alpha_E, \beta_C, \gamma_R),
\]

which models how environmental cues, dispositional structure, and synthetic presence jointly shape behavioural output. The core task of the thesis was to determine whether this mapping is susceptible to perturbation, and what such susceptibility reveals about the architecture of human moral cognition.

Across the chapters that followed, this problem—posed abstractly in the Introduction—developed into an empirical and conceptual investigation of how
humans register moral salience in the presence of non-human bodies. Drawing on
contemporary models of moral psychology that emphasise intuitive,
affect-laden appraisals over reflective deliberation~\cite{Haidt2001,Greene2001,Greene2002,Cushman2013},
the experimental work examined whether NAO influences the early evaluative
stages that precede conscious reasoning. The design therefore situated
participants within a minimally structured moral environment, introducing
$\gamma_R$ as a silent, embodied presence whose influence could arise only
through its perceptual affordances.

With this concluding chapter, we return to the commitments articulated at the
start. The results now allow us to say, with the empirical grounding that the
Introduction could only anticipate, that the evaluative process is indeed
sensitive to synthetic presence.  

\vspace{0.2em}
\noindent
\textbf{H1 (Evaluative Deformation)} is supported: the expected behavioural
output under $\Sigma \cup \mathscr{R}$ diverges from that under $\Sigma$ alone.  

\noindent
\textbf{H2 (Synthetic Normativity)} is refined: NAO does not generate new
normative affordances but modulates the salience of existing ones through its
informational and embodied profile.  

\noindent
\textbf{H3 (Synthetic Perturbation of Moral Inference)} is supported: the
influence of $\gamma_R$ manifests in the perceptual–affective transition from
moral cue to action, not in explicit deliberation.  

\noindent
Moreover, the evaluative mapping $f(\alpha_E, \beta_C, \gamma_R)$ predicted a
structured form of dispositional heterogeneity—an expectation borne out in the
latent trait ecologies recovered via clustering, where perturbation effects
concentrated within the Prosocial--Empathic regime and remained muted or
absent elsewhere.

Crucially, the thesis has treated these findings with the epistemic caution appropriate for a subtle effect in a modest dataset. Bayesian estimation explicitly accommodates uncertainty arising from zero-inflated donation data
and uneven cluster sizes: the posterior for the donation difference is skewed toward attenuation, yet reflects the heterogeneity of cognitive–affective architectures rather than compressing evidence into a binary verdict. This probabilistic contour strengthens the interpretive claim: when moral cognition
operates intuitively, ambiguity in the environment should appear as ambiguity in the data.

This leads to the broader significance of the work. The results suggest that:

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{Human moral appraisal is structurally sensitive to the perceptual ecology in
			which it unfolds.}
	\end{leftbar}
\end{center}

\bigskip
\noindent

Moral behaviour emerges from a sequence of cognitive–affective
transitions shaped by what is noticed, foregrounded, or rendered ambiguous. Synthetic presence makes this sensitivity visible: even a minimally expressive artificial body can redirect the flow of evaluative attention, thereby altering
the probability that moral salience becomes action.

In bringing these strands together, this chapter begins where the Introduction left off: with the claim that artificial systems participate in human moral life long before they reason, decide, or speak. What the experiment now shows
is that their influence arises from how they reconfigure the perceptual and affective scaffolds through which moral meaning is formed. 

The remainder of the Conclusion develops this insight, situating it within social robotics, affective computing, and the philosophy of moral cognition, and drawing the
thesis toward its final synthesis.

\section{Contributions to Human--Robot Interaction, Affective Computing, and Moral Cognition}

The empirical and conceptual results developed throughout this thesis amount to a set of contributions that cut across three adjacent domains: human--robot interaction (HRI), affective computing, and the study of moral cognition.  

While each field approaches social behaviour from a distinct methodological tradition, the present work shows that the phenomenon under investigation---the 
attenuation of prosocial action under synthetic co-presence---sits precisely at their intersection. The following synthesis articulates these contributions in a 
form that reflects the structural unity of this research.

\subsection{Contribution to Human--Robot Interaction}

Within HRI, the dominant research programmes have traditionally focused on interactional behaviours: communication, signalling, collaboration, engagement,trust, and alignment~\cite{GoodrichSchultz2007, Breazeal2003, Lee2010, Hancock2011, Fischer2011}. The present study contributes a different insight:


\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{Interaction is not required for a humanoid robot to exert a measurable influence on human behaviour}
	\end{leftbar}
\end{center}

\bigskip
\noindent

NAO's silent presence reshaped the evaluative conditions under 
which participants interpreted a morally salient cue in experimental setting. This demonstrates that robots 
participate in human moral environments not only through explicit social action but also through their perceptual affordances, spatial occupation, and ontological ambiguity. 

This finding positions synthetic presence as an \emph{environmental factor} in HRI---a contributor to the structure of the evaluative field rather than a node in 
an interactional sequence. The notion of robotic co-presence as a ``semiotic operator'' opens conceptual space for a new class of HRI effects: those that emerge upstream of explicit social behaviour, and which operate through shifts in attention, salience, and interpretive framing.

\subsection{Synthetic Presence and Floridi’s Account of Moral Agency}

A central question naturally arises from the empirical findings of this thesis:

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{if NAO reshapes the evaluative conditions under which morally salient cues are interpreted under experimental settings, what does this imply for its moral status within Floridi’s framework of agency, patiency, and informational relevance?}
	\end{leftbar}
\end{center}

\bigskip
\noindent

Addressing this question clarifies both the conceptual footing of the results and their broader implications for social robotics and machine ethics.

Floridi’s theory of moral agency distinguishes between three classes of entities: (i) \emph{moral agents}, capable of performing morally qualifiable actions; (ii) \emph{moral patients}, capable of moral harm or benefit; and (iii) a broader class of \emph{morally relevant informational objects}, whose properties modulate the normative landscape without possessing agency or interests~\cite{FloridiSanders2004,Floridi2013}. 

Within this taxonomy, NAO is neither an agent nor a patient: it issues no commands, performs no autonomous decisions, and has no capacity for norm-responsive deliberation or moral vulnerability.

Yet the empirical results show that NAO is not normatively inert. The robot exerts a measurable influence on the evaluative transformation
\[
f(\alpha_E, \beta_C, \gamma_R),
\]
not by acting or reasoning, but by altering the \emph{informational environment} in which human agents interpret moral cues. In Floridi’s terms, NAO functions as a \emph{morally relevant artefact}: its perceptual 
affordances—embodied form, gaze, spatial presence, and subtle motion—shape the *potential* salience landscape at the operative Level of Abstraction~\cite{Floridi2011,Floridi2013}. 

At this LoA, participants do not encounter the robot as source code or computation. They encounter it as a \emph{semiotic body}~\cite{Coeckelbergh2010,Coeckelbergh2020}: an 
entity that appears socially expressive while lacking the behavioural depth of a human agent. This ontological ambiguity, we claim, is precisely what enables the perturbation observed in the experiment. The robot does not generate new norms (refining H2), nor does it provide explicit reasons for action; instead, it \emph{modulates the salience of existing cues}, 
bending the intuitive trajectory through which the Watching-Eye stimulus gains behavioural force \cite{Conty2016,Dear2019}. 

Situating NAO as a morally relevant informational object strengthens the central conclusion. It shows why synthetic presence can reshape moral behaviour without 
approaching the threshold of moral agency, and it clarifies a conceptual point often missed in Machine Ethics: 

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{artificial systems can exert morally significant influence 
			prior to, and independent of, any capacity for ethical reasoning.}~\cite{Moor2006,Wallach2008}
	\end{leftbar}
\end{center}

\bigskip
\noindent
Their normative impact arises from the environmental and 
semiotic roles they occupy within human cognitive ecologies 
\cite{Floridi2013,Coeckelbergh2020}. In this sense, Floridi’s framework does not merely accommodate the findings; it provides 
the conceptual architecture that renders them intelligible. NAO’s influence is not paradoxical but the predictable consequence of how informational artefacts participate 
in—and subtly deform—the evaluative landscapes through which human moral cognition operates.


\subsection{Contribution to Affective Computing and Social Signal Processing}

In affective computing and social signal processing, a central ambition is to infer 
latent cognitive--affective processes from observable behavioural traces.  
The experiment presented in this thesis provides an empirical demonstration that 
moral behaviour—here, prosocial donation—can serve as such a behavioural indicator.  
The attenuation observed under synthetic presence suggests that moral evaluations, 
although not directly observable, leave systematic behavioural traces when the 
evaluative topology is perturbed.  
This is consistent with the foundational premise of affective computing that latent 
states become inferable through patterned interactions between behaviour and context 
\cite{Picard1997,CalvoD2010,Vinciarelli2009,Vinciarelli2014}.

A methodological insight follows:

\begin{center}
	\begin{leftbar}
		\textit{latent dispositional architecture can be recovered from psychometric and 
			behavioural data in a way that reveals differential susceptibility to contextual 
			perturbation.}
	\end{leftbar}
\end{center}

The three dispositional ecologies identified through clustering (Emotionally 
Reactive, Prosocial--Empathic, Analytical--Structured) illustrate how personality 
configurations form distinct regions in evaluative space.  
These ecologies show that affective modulation by artificial systems is a 
\emph{structure-sensitive} process, linking affective computing’s interest in latent 
state inference with HRI’s concern for the social affordances of synthetic presence.  
Comparable patterns in social signal processing show that stable dispositional 
profiles shape responsiveness to contextual cues and interpersonal signals 
\cite{Pentland2007,Banks2020,Habashi2016}.

Finally, the Bayesian modelling framework demonstrates how uncertainty—a constitutive 
property of both affective states and behavioural data—can be represented as a 
structured epistemic gradient rather than statistical noise.  
This aligns Bayesian inference with the broader aims of affective computing: to 
quantify latent evaluative processes under contextual variability, in continuity with 
hierarchical Bayesian approaches in computational cognitive science 
\cite{Tenenbaum2011,Kruschke2014}.  


\subsection{Contribution to Moral Cognition Research}

Within moral psychology, the present findings contribute evidence for an intuitionist and ecological interpretation of moral judgement. Consistent with leading models of intuitive moral appraisal and dual-process architectures 
\cite{Haidt2001,Greene2001,Greene2002,Greene2014,Cushman2013}, the study shows 
that moral behaviour is shaped by the perceptual and affective scaffolds through 
which salient cues are first registered. The attenuation effect emerges 
\emph{prior} to deliberation, within the cognitive--affective space where 
intuitive appraisals and affect-driven evaluations are formed. This aligns with 
work demonstrating that moral cognition is sensitive to subtle environmental 
modulation—implicit monitoring, gaze cues, ambient social presence 
\cite{Haley2005,Bateson2006,Conty2016,Dear2019}—and extends these findings to 
\emph{synthetic} social affordances \cite{Zlotowski2015,Groom2010,Malle2016}.

A central contribution lies in the demonstration that moral susceptibility is 
\emph{trait-contingent}. The Prosocial--Empathic profile, characterised by high 
interpersonal attunement and affective resonance, exhibited the clearest 
attenuation under NAO’s presence, while the Analytical--Structured and 
Emotionally Reactive profiles did not. This pattern empirically supports the 
prediction derived from the formalism $f(\alpha_E, \beta_C, \gamma_R)$: that 
dispositional architecture modulates how moral salience undergoes evaluative 
transformation. The finding is consistent with research showing that empathy, 
agreeableness, and prosocial orientation shape sensitivity to social cues and 
moral demands \cite{Habashi2016,Hilbig2013,Decety2004}, while extending this 
literature by demonstrating that such sensitivity generalises to \emph{synthetic}
embodied presence.

Taken together, the results show that moral cognition is both intuitive and 
ecologically embedded: structured by the interplay between perceptual 
environments and latent evaluative topologies. Synthetic presence provides a 
novel perturbation of this evaluative field, revealing the dispositional 
contours through which moral meaning becomes behaviour.

\subsection{Integrative Contribution: A Unified Field-Theoretic Approach}

The broader contribution of this research lies in unifying these three domains within a single explanatory framework. By treating moral behaviour as the output of an evaluative function influenced by environmental cues, dispositional 
architecture, and synthetic presence, the thesis provides a consistent conceptual vocabulary for explaining effects that span psychological, computational, and robotic contexts. This framework is field-theoretic in a strict sense: it arises directly from the formal decomposition 
$f(\alpha_E, \beta_C, \gamma_R)$ and models moral appraisal as movement through a structured evaluative landscape.

This account aligns with long-standing findings in moral psychology that behaviour emerges from affective appraisal and intuitive processing~\cite{Haidt2001,Greene2001,Decety2004}, with Social Signal Processing research showing that social cues reorganise attentional and evaluative structures~\cite{Pentland2007,Vinciarelli2009,Conty2016}, and with HRI evidence that robotic presence modulates human social and moral behaviour even in minimal-interaction 
settings~\cite{Kuchenbrandt2011,Malle2016,Bremner2022,Zlotowski2015}. Crucially, Floridi’s Levels of Abstraction supply the conceptual hinge: synthetic presence exerts influence at the perceptual LoA, independent of its internal architecture.

Across HRI, affective computing, and moral cognition, the central insight is the 
same:
\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{synthetic presence need not act, speak, or decide to shape moral behaviour; 
			it need only reorganise the evaluative conditions under which moral salience is 
			processed.}
	\end{leftbar}
\end{center}
\bigskip
\noindent
This insight establishes a theoretical bridge between empirical measurement, computational modelling, and philosophical analysis. It connects affective-computational approaches concerned with latent evaluative states \cite{Picard1997}, 
SSP models of multimodal social inference \cite{Vinciarelli2009}, and ecological accounts of context-sensitive moral judgement \cite{Haidt2001,Greene2014}. 

Taken together, these strands converge on a unified field-theoretic perspective in which artificial agents function not as loci of ethical reasoning but as operators on the 
evaluative topology through which moral meaning becomes behavioural output.