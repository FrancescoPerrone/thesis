\chapter{Conclusion}
\label{chap:conclusion}

Think back to the question that opened this thesis. Not the formal version with symbols and indices, but the simpler one that sits beneath it:

\begin{center}
	\begin{leftbar}
		\textit{Can the mere presence of a synthetic, non-agentic entity perturb the 
			pathway through which morally salient cues become action?}
	\end{leftbar}
\end{center}

Everything that followed—the topology, the dispositions, the perturbation 
operator—was built to make that question answerable without handwaving.  
But the question itself remains disarmingly small. It asks whether a body that 
does not think, does not intend, and does not judge can nonetheless shift the 
trajectory from perception to (\textit{moral}) action.  

It is the kind of question that appears almost trivial until one tries to answer 
it.  To ask whether \emph{presence alone} matters is to ask 
what moral action depends on in the first place—how attention settles, how 
salience is allocated, how accountability is felt before reasons are ever 
articulated.  It requires stepping beneath the level at which people speak of 
moral principles, and into the evaluative machinery that makes principles usable 
at all.

The study carried out here does not, and could not, tell us whether a robot 
elicits “genuine’’ social cognition or whether humans respond to a sophisticated 
simulation.  That deeper metaphysical question remains open.  That question exceeds the scope of the experiment.  But the work does suggest that something prior to it: that the evaluative field through which moral perception becomes behaviour is sensitive to objects that do not think, do not intend, and do not judge.

A small presence can shift a trajectory. That was the animating intuition of the
opening parable: a traveller’s path bending under forces too subtle to name,
long before he could speak of reasons. The experiment provides a cautious
empirical analogue. The deformation is modest, graded, and shaped by
dispositional topology—but it is detectable. And detectability is the
philosophical point. It suggests that moral action is not insulated from the
ambient ecology of perception; it is responsive to it.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Across the chapters that followed, this question—posed in its simplest form at 
the outset—unfolded into a structured inquiry into how humans register moral 
salience in the presence of non-human bodies. The theoretical work traced the 
architecture that precedes explicit reasoning: the layers of attention, affective 
orientation, and situational meaning through which a cue becomes morally charged.  
The experimental work then placed participants within a deliberately minimal 
moral environment, introducing $\gamma_R$ as a silent, embodied presence whose 
influence, if it existed, could arise only through these upstream evaluative 
processes.

In this closing chapter, we return to the commitments articulated at the start,
now informed by empirical evidence rather than anticipation. The results permit
a measured claim: the evaluative process appears sensitive to synthetic
presence.
 

\medskip
\noindent
\textbf{(H1) Evaluative Deformation} is cautiously supported.  
Behavioural output under $\Sigma \cup \mathscr{R}$ diverges in a directionally 
consistent manner from that under $\Sigma$ alone, aligning with the Bayesian 
posterior and the aggregate attenuation observed in the data.

\noindent
\textbf{(H2) Synthetic Normativity} is conceptually supported, refined.  
NAO does not introduce new normative content, but modulates the salience of 
existing cues through its perceptual and embodied profile. Its normative 
relevance arises from its ontological status at the operative Level of 
Abstraction, not from agency or intention.

\noindent
\textbf{(H3) Synthetic Perturbation of Moral Inference} is supported in structure.  
The influence of $\gamma_R$ manifests in the perceptual–affective transition 
linking moral salience to action, with the clearest refractive modulation 
emerging in the Prosocial–Empathic cluster. The perturbation concerns the 
\emph{pathway} from cue to behaviour, not deliberation itself.
 

\medskip

The evaluative mapping 
\[
f(\alpha_E, \beta_C, \gamma_R)
\]
suggested that any perturbation should express itself heterogeneously across the
dispositional manifold. This expectation is reflected in the latent ecologies
recovered through clustering: the Prosocial–Empathic group shows the clearest
descriptive attenuation, the Analytical–Structured group shows little
displacement, and the Emotionally Reactive group displays variable
susceptibility. Synthetic presence does not act on a single trait; it interacts
with a configuration.

Epistemically, the thesis treats these findings with the caution appropriate to a
graded effect in a modest dataset. Bayesian estimation retains the uncertainty
inherent in zero-inflated donation data and uneven cluster sizes. The posterior
for the donation difference tilts toward attenuation, but does so in a way that
mirrors the heterogeneity of the cognitive–affective landscape rather than
reducing it to a binary contrast. In a domain where moral cognition is itself
sensitive to ambiguity, it is fitting that the data preserve that structure.

This yields the broader claim toward which the thesis has been moving:

\begin{center}
	\begin{leftbar}
		\textit{Human moral appraisal is structurally sensitive to the perceptual ecology in 
			which it unfolds.}
	\end{leftbar}
\end{center}

Moral behaviour emerges from a cascade of evaluative transitions—what is noticed,
what is foregrounded, what is rendered uncertain. Synthetic presence helps make
this cascade visible. A body that does not judge can nonetheless redirect the
flow of evaluative attention, altering the probability that moral salience
becomes action.

In gathering these strands, the Conclusion returns to where the Introduction 
first gestured: artificial systems participate in human moral life not by 
reasoning or speaking but by altering the background against which moral meaning 
crystallises. The experiment suggests that their influence might be subtle, structured, and dispositional. Following draw out what this might implies for Social Robotics, Affective Computing, and the Philosophy of Moral Cognition, preparing the ground for the final synthesis.


\section{Contributions to Human--Robot Interaction, Affective Computing, and Moral Cognition}

The results developed across the thesis now take on a clearer shape.  
Once the evaluative deformation was shown to be detectable—and shown to depend on 
the dispositional topology of the human observer—the phenomenon revealed itself 
as one that cannot be contained within any single discipline.  
HRI, affective computing, and moral cognition each illuminate one facet, but the 
perturbation induced by $\mathscr{R}$ is a boundary phenomenon: it arises 
precisely where perceptual ecology, affective appraisal, and moral action meet.  
What follows is therefore not a catalogue of separate contributions, but a 
synthesis that reflects the structural unity of the work.

\subsection{Contribution to Human--Robot Interaction}

Research in HRI has largely centred on robots as \emph{interactive partners}:
agents that communicate, collaborate, persuade, align, negotiate, or assist%
~\cite{GoodrichSchultz2007,Breazeal2003,Lee2010,Hancock2011,Fischer2011}.
The present study offers a different vantage point.

\begin{center}
	\begin{leftbar}
		\textit{A robot need not act, speak, or engage to influence human behaviour.
			Co-presence alone may reshape the evaluative field in which action is formed.}
	\end{leftbar}
\end{center}

NAO’s silent, minimally animated presence appears to alter the conditions under
which participants interpreted and responded to a morally salient cue.
This positions the robot not as a participant in a dyadic exchange, but as part
of the \emph{environmental scaffolding} that regulates attention, salience, and
accountability.
Its influence arises from its perceptual affordances and ontological ambiguity—
features that operate upstream of social interaction, at the level where the
evaluative topology is configured.

In this light, robotic presence can be understood as a form of \emph{semiotic
	pressure}: a contextual operator that shapes how meaning settles before any
behaviour is produced.
The contribution to HRI is therefore conceptual and methodological:
it extends the field’s explanatory vocabulary beyond interactional mechanics
toward field-level effects—subtle modulations of the perceptual–affective
conditions under which humans determine what a situation calls for.

This reframing suggests that future HRI research should treat robots not only as
agents with whom we interact, but also as elements of the local moral ecology
whose mere presence may shift the dynamics of human judgement and action.

\subsection{Synthetic Presence and Floridi’s Account of Moral Agency}

The empirical finding that a silent, non-deliberative robot may bend the
trajectory from moral perception to action invites a deeper philosophical
question—one that lingers beneath the statistical surface:

\begin{center}
	\begin{leftbar}
		\textit{If NAO appears to reshape the evaluative conditions under which moral cues acquire behavioural force, what does this imply for its status within Floridi’s informational taxonomy of agency, patiency, and moral relevance?}
	\end{leftbar}
\end{center}
\bigskip
Floridi’s framework distinguishes three categories:  
(i) \emph{moral agents}, capable of producing morally qualifiable actions;  
(ii) \emph{moral patients}, capable of being morally harmed or benefited; and  
(iii) a broader class of \emph{morally relevant informational objects}, whose 
properties can modulate the normative landscape without possessing agency or 
interests of their own~\cite{FloridiSanders2004,Floridi2013}.  

Nothing in the present experiment promotes NAO into the first two categories.  
It neither acts, decides, nor suffers. Yet the data might suggest that it is not 
normatively inert. What NAO alters is not the moral rule, nor the participant’s 
belief about the scenario, but the \emph{evaluative field} in which moral 
appraisal takes shape. In the formal notation developed earlier,
\[
f(\alpha_E, \beta_C, \gamma_R),
\]
its contribution is captured by the perturbation operator $\gamma_R$:  
a modification of the perceptual–affective conditions under which moral 
salience becomes operative.

In Floridi’s terms, NAO is best understood as a \emph{morally relevant artefact}.  
Its morally consequential role does not arise from agency but from 
\emph{informational presence}: the way its embodied form, subtle motion, and 
spatial occupation reconfigure what is noticed, how accountability is felt, and 
which cues enter the evaluative pathway. At the operative Level of Abstraction, 
participants do not meet NAO as a computational system; they meet it as a 
\emph{semiotic body}~\cite{Coeckelbergh2010,Coeckelbergh2020}—a perceptually social 
object that invites, but never completes, the attribution of mindedness.  

This ontological ambiguity is not noise around the effect; it is the mechanism 
of the effect. Because NAO does not judge, command, or reason, its influence 
cannot be located in agency.  
Instead, it resides in the way its presence subtly bends the salience gradients 
through which the Watching–Eye cue acquires behavioural weight.  
The experiment therefore refines Hypothesis~H2: synthetic systems need not 
introduce new norms; they can reshape the uptake of existing ones by altering 
the evaluative topology in which those norms are interpreted.

Seen through Floridi’s lens, the central contribution of the experiment becomes 
clearer. It demonstrates that:

\medskip
\begin{center}
	\begin{leftbar}
		\textit{Artificial systems may exert morally significant influence prior to—and entirely independent of—any capacity for ethical reasoning.}
	\end{leftbar}
\end{center}
\medskip

Their normative import appears to arise from their role as 
\emph{environmental operators} within human cognitive ecologies~\cite{Floridi2013}. 
Rather than challenging Floridi’s taxonomy, the findings bring its diagnostic 
power into sharper focus. They show why a non-agentic artefact can participate in 
moral life without ever becoming a moral subject or object.

Seen from this perspective, the result is not unsettling but clarifying.  
Nothing mysterious has entered the moral domain. What has changed is the 
background against which moral meaning takes shape. The robot does not add a new 
voice to the moral conversation; it alters the acoustics of the room in which the 
conversation is already taking place.  

Once this is recognised, the phenomenon becomes intelligible in a deeper sense. 
Moral cognition does not unfold in a vacuum, insulated from the material and 
informational textures that surround it. It unfolds in fields—shaped by bodies, 
presences, absences, and ambiguities. Synthetic artefacts matter, not because 
they reason, but because they quietly reweight the forces that carry perception 
toward action. And it is precisely here, in these subtle modulations of the 
evaluative field, that their moral significance resides.


\subsection{Contribution to Affective Computing and Social Signal Processing}

From the perspective of Affective Computing and Social Signal Processing, the
results of this thesis may speak to a long-standing ambition: to make latent
cognitive--affective processes empirically tractable without reducing them to
surface behaviour alone. What the experiment suggests is not merely that moral
behaviour can be measured, but that it can serve as a \emph{diagnostic trace} of
deeper evaluative dynamics when the surrounding field is carefully perturbed.

The attenuation observed under synthetic co-presence suggests that moral
evaluation, although never directly observable, leaves patterned signatures in
behaviour when the evaluative topology is displaced. This aligns with a
foundational premise of affective computing: that latent states become legible
through systematic relations between context and response, rather than through
introspection or explicit report alone~\cite{Picard1997,CalvoD2010,Vinciarelli2009,Vinciarelli2014}.
Here, moral action itself serves as the signal.

A methodological insight follows naturally:

\begin{center}
	\begin{leftbar}
		\textit{Latent evaluative structure may be inferred not by isolating behaviour
			from context, but by observing how behaviour changes when context is subtly
			altered.}
	\end{leftbar}
\end{center}

The dispositional ecologies recovered through clustering—Prosocial--Empathic,
Analytical--Structured, and Emotionally Reactive—illustrate this principle in
concrete form. They suggest that susceptibility to perturbation is not uniformly
distributed, but organised around relatively stable regions of evaluative space.
In this sense, affective modulation by artificial systems appears to be a
\emph{structure-sensitive} phenomenon: the same environmental cue does not carry
the same weight across cognitive--affective configurations. This connects
Affective Computing’s concern with latent state inference to Social Signal
Processing’s emphasis on how stable individual differences shape responsiveness
to social cues~\cite{Pentland2007,Habashi2016,Banks2020}.

Finally, the Bayesian modelling framework contributes an epistemic stance as much
as a statistical one. By representing uncertainty as a graded posterior rather
than collapsing it into binary outcomes, the analysis treats ambiguity as an
informative feature of moral cognition rather than as noise to be eliminated.
This perspective aligns naturally with hierarchical Bayesian approaches in
computational cognitive science~\cite{Tenenbaum2011,Kruschke2014}, and with the
broader aim of affective computing: to model evaluative processes as
probabilistic, context dependent, and dynamically constrained.


\subsection{Contribution to Moral Cognition Research}

Seen through the lens of Moral Psychology, the findings converge on a view of
moral judgement that is intuitive, situated, and structurally sensitive.
The attenuation observed under synthetic co-presence does not appear at the level
of articulated belief or explicit principle application. It appears to emerge
earlier, within the cognitive--affective space where salience is first registered
and evaluative weight is assigned. What shifts is not what participants think is
right, but how strongly a morally relevant cue presses toward action.

This places the results squarely within, and in dialogue with, intuitionist and
dual-process accounts of moral cognition~\cite{Haidt2001,Greene2001,Greene2002,
	Greene2014,Cushman2013}. Moral behaviour here is not treated as the endpoint of
reflective calculation, but as the outcome of a trajectory that begins with
perception, attention, and affective appraisal. The present study extends
existing evidence that moral judgement is sensitive to subtle environmental
modulation—implicit monitoring, gaze cues, ambient social presence~\cite{Haley2005,
	Bateson2006,Conty2016,Dear2019}—by suggesting that \textbf{this sensitivity is not limited
to human observers, but may generalise to \emph{synthetic} embodied presences}
\cite{Zlotowski2015,Groom2010,Malle2016}.

A further contribution lies in indicating that this sensitivity is not uniformly
distributed. The clearest descriptive attenuation emerges within the
Prosocial--Empathic ecology, characterised by heightened interpersonal
attunement and affective resonance, while other dispositional regimes show more
muted or absent effects. This pattern is consistent with a prediction implicit in
the formal mapping $f(\alpha_E,\beta_C,\gamma_R)$: that the transformation from
moral salience to action is shaped by the internal organisation of the
dispositional manifold. Empathy-related traits appear to amplify responsiveness
to social context, and this responsiveness may extend beyond human sociality to
synthetic bodies occupying the same perceptual field~\cite{Decety2004,
	Habashi2016,Hilbig2013}.

Taken together, these findings portray moral cognition as both intuitive and
ecologically embedded. Moral action arises from the interaction between latent
evaluative structure and the perceptual environment in which judgement unfolds.
Synthetic presence matters not because it introduces new moral content, but
because—by perturbing the field—it helps render visible the contours along which
moral meaning becomes behaviour.

\subsection{Integrative Contribution: A Unified Field-Theoretic Perspective}

What emerges, when these strands are brought together, is not a collection of
parallel contributions but a single explanatory stance. Across Psychology,
Human--Robot Interaction, Affective Computing, and perhaps Information Ethics, a common structural pattern becomes visible: moral behaviour is best understood not as
the execution of rules or the expression of stable preferences, but as movement
within an evaluative field shaped by context, disposition, and presence.

The unifying move of this thesis is to make that structure explicit. By treating
moral action as the output of an evaluative mapping
$f(\alpha_E,\beta_C,\gamma_R)$, the work offers a vocabulary capable of describing
phenomena that might otherwise remain fragmented across disciplines.
Environmental cues ($\alpha_E$), dispositional architecture ($\beta_C$), and
synthetic presence ($\gamma_R$) are not competing explanations but jointly
\textbf{constitutive dimensions of a single landscape}. Moral appraisal, on this view, is
not a point event but a trajectory: a passage through a structured space of
salience, affect, and practical pull.

This perspective resonates with long-standing findings in Moral Psychology, where
affective appraisal and intuitive processing play a generative role
\cite{Haidt2001,Greene2001,Decety2004}; with social signal processing, which shows
that minimal cues can reorganise attentional and evaluative structure
\cite{Pentland2007,Vinciarelli2009,Conty2016}; and with HRI research suggesting
that robotic presence can modulate human behaviour even in the absence of
explicit interaction \cite{Kuchenbrandt2011,Malle2016,Bremner2022,Zlotowski2015}.
What binds these literatures is not a shared methodology, but a shared level of
explanation. Floridi’s Levels of Abstraction provide the hinge: the influence of
synthetic presence appears to operate at the perceptual and affective LoA,
independently of any internal capacity for reasoning or intention.

Seen from this angle, the central insight can be stated simply:

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{Artificial systems need not act, decide, or reason to shape moral
			behaviour; it may be sufficient that they reorganise the conditions under
			which moral salience is registered.}
	\end{leftbar}
\end{center}
\bigskip
\noindent

This reframing does more than connect empirical results to philosophical theory.
It might help explaining--or it might provide minimal tools for investigating--why moral influence can arise without agency, why ambiguity rather than intention can be causally relevant, and why small changes in perceptual ecology can produce measurable shifts in behaviour. Artificial agents, on this account, are not competitors to human moral reasoning. They function as operators on the topology through which moral meaning becomes action.

The field-theoretic perspective articulated here thus closes a conceptual loop.
It links experimental measurement, computational modelling, and philosophical
analysis within a single explanatory structure—one in which moral life is shaped
less by what entities are, than by how they quietly configure the spaces in which
human judgement unfolds.

\section{One Explanatory Object, Not Three Literatures}

At this point, it becomes possible to see the shape of the work as a whole.  
What may have appeared, at earlier stages, as a dialogue between distinct
traditions—moral psychology, information ethics, and social robotics—resolves
into something more unified. This thesis was never an exercise in juxtaposition.
It was organised, from the outset, around a single explanatory object that none
of those literatures could fully grasp in isolation.

That object is the evaluative transformation
\[
f(\alpha_E, \beta_C, \gamma_R),
\]
the process through which moral salience is translated into action under
conditions of situated perception, dispositional structure, and synthetic
co-presence. Each body of work engaged in this thesis illuminates a different
dimension of that transformation, but all are oriented toward the same
phenomenon.

Moral psychology provides the generative core: it explains how intuitive,
affective, and trait-sensitive processes give rise to evaluative trajectories,
and why such trajectories should be differentially susceptible to contextual
modulation. Floridi’s information ethics supplies the ontological and epistemic
frame: it clarifies how artificial entities can become morally relevant at a
given Level of Abstraction without possessing agency, intention, or moral
standing. Social robotics and Social Signal Processing, finally, furnish the
empirical arena in which these abstract claims encounter the world—where
synthetic presence can be instantiated, perturbed, and measured with precision.

From this vantage point, the field-theoretic perspective is not a metaphor
imported for rhetorical effect. It is the natural generalisation of the mapping
itself. Moral cognition unfolds in a structured space of salience, attention, and
affective pull; synthetic presence operates by subtly reshaping the geometry of
that space. No single literature could have revealed this alone. Moral psychology
without Levels of Abstraction lacks an account of why non-agentic artefacts
matter. Information ethics without empirical grounding lacks a mechanism by which
moral relevance becomes behaviourally manifest. HRI without an evaluative model
lacks an explanation for why minimal, silent presence should exert any influence
at all.

What this thesis offers, then, is not a bridge hastily thrown between adjacent
fields, but a reorganisation of them around a common evaluative architecture.
The experimental results show that artificial systems participate in human moral
life neither by reasoning nor by instructing, but by modulating the perceptual
and ontological conditions under which moral meaning takes shape. That insight—
quiet, structural, and easily missed—is the conceptual kernel around which the
entire research programme coheres.



\section{Final Synthesis and Closing Reflections}

\noindent
At the end of this research journey, the central phenomenon around which the thesis
was constructed can be stated with clarity: \emph{synthetic presence alters the
	conditions under which human beings register, evaluate, and act upon moral
	salience}. What began as a question about a quiet, non-interactive humanoid robot
has unfolded into a broader insight about the structure of moral cognition and the
ethical texture of technologically saturated environments.

The empirical work demonstrated that NAO’s presence does not introduce new moral
reasons, nor does it engage participants in explicit social interaction. Instead, it
reshapes the evaluative conditions under which moral cues acquire behavioural force.
This perturbation is subtle, probabilistic, and contingent upon latent dispositional
architecture—yet empirically robust. Across inferential contrasts, cluster-specific
analyses, and Bayesian estimation, the evidence converges on the same structural
interpretation: artificial systems participate in human moral situations by
modulating the perceptual and affective scaffolds from which intuitive moral
appraisals develop.

\medskip

\noindent
What makes this more than an isolated result is the conceptual synthesis that
underwrites it. The thesis has argued that moral behaviour is not a direct output of
rules or principles; it is the trajectory of a cognitive–affective system shaped by
attention, affect, expectation, and salience. Contemporary models of moral
psychology have long emphasised the primacy of intuitive evaluation
\cite{Haidt2001,Greene2001,Cushman2013}. Floridi’s Levels of Abstraction provide the
correct ontological lens for specifying where synthetic entities exert influence. HRI
and Affective Computing supply the methodological tools through which such influence
can be observed and modelled. When joined together, these literatures do not merely
complement one another—they reveal that the phenomenon under investigation requires
all of them to be intelligible~\cite{Katsyri2015, Fischer2023}.

\medskip

\noindent
A key outcome of this integration is the field-theoretic interpretation articulated
throughout the thesis. The evaluative mapping
\[
f(\alpha_E, \beta_C, \gamma_R)
\]
is not a formal artefact appended to the data; it is the conceptual structure that
makes sense of how environmental cues, dispositional architectures, and artificial
systems cooperate to shape moral behaviour. Moral appraisal unfolds within a dynamic
field of salience. Synthetic presence acts as an operator on that field—not by issuing
commands but by shifting the local geometry through which moral meaning is formed.
The experimental results show that even minimal artificial bodies can introduce such a
shift. This finding is modest in magnitude but profound in implication.

\medskip

\noindent
The ethical considerations developed in Chapter~8 sharpen this point. Traditional
Machine Ethics asks how to embed principles into machines. Yet the empirical evidence
here shows that artificial systems shape moral life not through principles but through
presence: through their semiotic affordances, their perceived ontology, and the
attentional demands they impose on human cognitive ecologies. In Floridi’s framework,
NAO is not a moral agent; it is a morally relevant informational object. Its influence
is neither agential nor normative in itself, but environmental: it alters the field in
which human agents construct their moral understanding. This is not a limit case or a
marginal curiosity. It is a demonstration that ethical relevance emerges from the
interaction between artefacts and the conditions of human moral cognition, long before
questions of machine agency arise.

\medskip

\noindent
From this vantage point, the contribution of the thesis becomes unmistakable. The
work provides an empirically grounded demonstration that artificial systems—humanoid
robots today, pervasive AI systems tomorrow—can reshape moral cognition through their
informational presence alone. It offers a formal architecture for modelling such
influence, a set of empirical methods for detecting it, and a conceptual framework for
understanding why it occurs. It also clarifies that the normative stakes of synthetic
presence lie not merely in what machines may eventually \emph{do}, but in how they
silently reorganise the evaluative landscape in which human moral behaviour unfolds.

\medskip

\noindent
This brings us back, finally, to the thesis’s animating question. Yes—synthetic
presence can perturb the evaluative transformation through which moral salience
becomes moral action. It can do so without interacting, without expressing norms,
without engaging in dialogue, and without crossing the threshold of moral agency. It
is enough that it is \emph{perceived}. This insight opens the way for a new research
programme in moral AI: one that takes seriously the structure of moral cognition, the
ecological nature of moral environments, and the field-level effects of artificial
systems embedded within them.

\medskip

\noindent
If this thesis has shown anything, it is that the future of moral AI will not begin
with building artificial moral agents. It will begin with understanding how
artificial systems already shape human moral life. The rest—ethical design, moral
alignment, normative governance—must follow from that foundational fact. The task now
is no longer to ask whether such influence exists, but to learn how to measure it,
model it, anticipate it, and ultimately, to govern the moral topologies we are
already co-constructing with our synthetic companions.

\medskip
\noindent
This is the horizon toward which the work now points. The thesis closes here, but the
evaluative field it uncovers is only beginning to take shape.
