\chapter{On Moral Decision-Making: A Reasoned Review}
\thispagestyle{pprintTitle}


% Adjusting epigraph settings
\setlength\epigraphwidth{.8\textwidth}
\setlength\epigraphrule{0pt}
\renewcommand{\epigraphflush}{flushleft}
\renewcommand{\sourceflush}{flushright}

%% State the main actor: prosocial behavior -> altruism -> donation -> moral reas
%
% --- 

%% Intorduction of the term
%
%
%% A short definition of morality
%
%
The term 'morality' is frequently employed in public discourse, policymaking, and interdisciplinary research with significant conceptual ambiguity, often lacking the precision characteristic of academic subjucts such as moral philosophy and normative ethics. This imprecision results in interpretative inconsistencies and epistemic distortions, particularly when morality is operationalised as an empirical construct~\cite{Joyce2006, Tomasello2016}. While moral philosophy has long sought to formalise the principles underlying moral judgment and moral decision-making, thus the concept of \textit{morality} itself, its transposition across disciplines remains inconsistent, leading to methodological and theoretical fragmentation. Such conceptual instability is especially problematic in research—such as our investigation into machine-detectable moral cues—where empirical analyses necessitate a clearly delineated and operationally sound definition of the term \fpincom{or: sound definition of morality}

Establishing a rigorous conceptual framework is thus a prerequisite for ensuring that empirical approaches to moral pattern detection are rooted in analytical coherence rather than contingent or culturally idiosyncratic interpretations.

A brief etymological analysis of the term is a necessary preliminary step, as it provides critical insights into its conceptual foundations and historical semantic shifts. By tracing the term’s linguistic evolution, we can clarify its epistemic underpinnings and mitigate the risk of importing anachronistic or culturally contingent assumptions into our theoretical framework.

It should be acknowledged that a thorough etymological investigation of the term is an extensive undertaking—arguably the subject of an independent doctoral inquiry—which lies beyond the scope of this work. Instead, we will draw upon existing scholarly analyses and established linguistic research to extract the necessary insights for our purposes. 

Our goal is to illuminate the term’s meaning in a manner that is both conceptually rigorous and functionally relevant to our investigation into machine-detectable moral cues, as well as to enhance our understanding of the meaning and usage of technical terms such as \textit{Moral Judgment} and \textit{Moral Decision-Making}. Given that empirical analyses in this domain require a clearly delineated and operationally sound definition of \textit{morality}, this clarification is not only essential for our study but also valuable for researchers in Computing Science and related sub-fields engaging with similar questions.

%
\section{Linguistic Evolution of "Morality"}
In justifying an etymological analysis as a methodological tool for generating understanding—while maintaining consistency with the empirical nature of this work—it is worth noting that direct empirical studies explicitly linking etymology to enhanced comprehension remain limited. However, scholarly literature in psychology and philosophy supports the claim that examining a word’s etymology can deepen our understanding of its meaning and function by elucidating its conceptual evolution and cognitive associations~\cite{Ibarretxe2004}

Philosophically, hermeneutics—the study of interpretation—emphasizes the significance of historical and contextual analysis in understanding texts and language~\cite{McCaffrey2012}. Etymological inquiry serves as a methodological tool within this tradition, uncovering layers of meaning shaped by cultural and historical contingencies, thereby refining our comprehension of a term’s contemporary usage~\cite{Chiurazzi2017}. This approach aligns with the hermeneutic principle of the fusion of horizons, wherein understanding emerges through the dynamic interplay between a text’s historical context and the interpreter’s conceptual framework~\cite{Gadamer1989}.

Psychologically, the concept of \textit{apperception} involves the process by which new experiences are assimilated into existing cognitive frameworks. Understanding a word's etymology allows individuals to connect new linguistic information to prior knowledge, facilitating deeper comprehension and retention. This process underscores the role of etymology in shaping our cognitive structures and enhancing our understanding of language~\cite{Ibarretxe2004, Bagheri2016}.

Thus, an etymological examination of the term morality serves as both a hermeneutic and cognitive tool, offering deeper epistemic insight into its conceptual foundations and historical evolution. By uncovering the linguistic, cultural, and philosophical contexts that have shaped its meaning over time, this analysis refines our theoretical understanding and enhances the clarity of its contemporary usage.


\subsection{On the Origin of the Word}
The term itself, morality, is a product of Latin intellectual efforts to translate and adapt Greek ethical concepts, yet the ideas it denotes predate this linguistic shift. The history of moral thought cannot be fully understood without tracing its origins to Greek philosophy, where early conceptions of virtue, conduct, and ethical reasoning took form. While Aristotle (384–322 BCE) is often regarded as the first philosopher to systematically explore morality, his work did not emerge in a vacuum. The intellectual landscape of moral thought was already shaped by pre-Socratic traditions, particularly the Pythagorean school (c. 6th century BCE), whose teachings wove together ethical precepts, metaphysical principles, and a structured way of life \cite{SidgwickOutlines}.  

Sidgwick notes~\cite{SidgwickOutlines} that the Pythagorean tradition was less a school of ethical philosophy in the modern sense and more a moral and religious order, built on a cosmological vision that sought to align human conduct with mathematical and harmonic principles. This view extended even to justice, which they conceived as a “square number,” reflecting the idea of proportional retribution \cite[p.~12]{SidgwickOutlines}. Their emphasis on self-discipline, moderation, and purification was closely tied to their belief in metempsychosis (the transmigration of souls), suggesting an early framework in which moral conduct had direct consequences for the fate of the soul \cite[p.~10]{SidgwickOutlines}.  

This connection between early Greek ethical reflection and its later Aristotelian articulation is crucial for understanding the historical development of moral philosophy. If we acknowledge that Greek ethics was expressed in terms of \textit{êthos} (ἦθος) and \textit{êthikê} (ἠθική), rather than through the Latin-derived “morality”, we can better appreciate the conceptual shifts that occurred in both language and thought. Sidgwick points out that while Aristotle ((384–322 BCE) brought moral philosophy into a systematic form, he was inheriting a legacy of moral reflection that had already developed within pre-Socratic traditions (c. 6th–5th century BCE) like Pythagoreanism (6th century BCE onward), Heraclitean thought (c. 535–475 BCE), and Democritean ethics (c. 460–370 BCE) \cite[p.~18]{SidgwickOutlines}. The transition from Greek to Latin terminology was not merely a matter of translation; it also signified a shift in emphasis—from a philosophical discourse concerned with the formation of character and virtue to one increasingly embedded in social norms and customs. The following discussion will explore how the Pythagorean tradition (c. 6th century BCE) contributed to the foundations of moral thought, preceding Aristotle and influencing the trajectory of ethics in Western philosophy.


The word "morality" has a Latin etymology. It derives from the term \textit{moralis}, coined by Cicero to translate the Greek êthikos (ἠθικός), which in turn derives from êthos (ἦθος), meaning "custom," "character," or "habit." In other words, the concept of morality has Greek origins, but the term we use today is of Latin derivation.

\subsection*{Why the Term "Morality"?}

If the earliest discussions on morality can indeed be traced back to the Pythagoreans and later Aristotle, it is also true that the Greek language expressed these concepts with \textgreek{êthos} (êthos, \textgreek{ἦθος}) and \textgreek{êthikê} (êthikê, \textgreek{ἠθική}). However, in the transition from Greek to Latin, an equivalent term became necessary. Cicero, in his attempt to adapt Greek philosophical vocabulary to the Latin language, employed \textit{moralis} as a calque of \textgreek{êthikos} (êthikos, \textgreek{ἠθικός}), deriving it from \textit{mores} (the customs, habits, and traditions of a people).

Indeed, Latin already had words to indicate virtuous behavior or righteous conduct, such as \textit{virtus} (virtue) and \textit{honestas}. However, \textit{moralis} served to translate directly the Greek concept of \textgreek{êthikê} (êthikê, \textgreek{ἠθική}). From this root, \textit{moralitas} later emerged, which, during the medieval period, became established as the term we use today to denote the set of principles regulating human action in relation to good and evil.

\subsection*{An Interesting Detail}

Aristotle uses \textgreek{êthos} (êthos, \textgreek{ἦθος}) in two distinct senses:

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\rightskip1.5cm
	\leftskip1cm
	\item[1)] \textgreek{êthos} (êthos, \textgreek{ἦθος}) with a long eta \textrightarrow\ denotes character and moral dispositions.
	\item[2)] \textgreek{éthos} (éthos, \textgreek{ἔθος}) with a short epsilon \textrightarrow\ denotes habit or custom.
\end{itemize}

This distinction suggests that the Greeks conceived moral behavior both as an innate disposition of character and as something shaped through habit and practice. The Latin \textit{mores}, however, emphasizes above all the social dimension of morality, that is, the set of shared norms within a community. From this perspective, the Latin term implies a more normative conception compared to Aristotle’s, which was more closely linked to ethics as a form of \textit{areté} (areté, \textgreek{ἀρετή}) (personal excellence).

Thus, the term "morality" is the result of a linguistic evolution that originates from Greek philosophy but takes its definitive shape in the Latin tradition, thanks to Cicero and later medieval scholars who solidified it within Western ethical discourse.



\section{Defining Moral}
Understanding morality as a philosophical concept requires engaging with a discourse that spans millennia, drawing on diverse traditions, frameworks, and interpretations. This section does not attempt to provide an exhaustive account of all perspectives on morality—such an endeavor would constitute an entire research work of its own—but instead introduces key philosophical milestones that have shaped the discourse. By referencing fundamental contributions, this review serves as a guide to some of the cornerstone works necessary to understand moral philosophy, without claiming to cover the full breadth of perspectives. Despite the depth and complexity of these contributions, there remains no single, universally accepted definition of morality. The term is used in at least two primary senses: descriptively, to refer to moral norms adhered to by societies or individuals, and normatively, to refer to principles that rational agents would endorse under ideal conditions~\cite{Gert2020}. This inherent ambiguity has led some scholars to question whether morality can be meaningfully defined at all, with some arguing that it lacks a unified essence and is best understood as a historically contingent and philosophically contested construct~\cite{Sinnott-Armstrong2016}. Given this conceptual landscape, the present discussion will focus on how foundational philosophical works have contributed to shaping contemporary understandings of morality, while recognizing that, for the purpose of this work on moral decision-making in human-robot interaction, operational definitions will be employed in a way that is internally consistent but not universally binding. To trace the intellectual development of morality, we begin with Aristotle, whose virtue ethics provides one of the earliest structured accounts of moral thought. 

Aristotle (350 BCE) in Nicomachean Ethics~\cite{Aristotle_nicomachean},  laid the foundation for moral philosophy by defining morality in terms of character and virtue, emphasizing that the highest human good is eudaimonia, or human flourishing, which is achieved through habituation and the exercise of practical wisdom (phronesis). Centuries later, Thomas Hobbes (1651) in Leviathan~\cite{Hobbes1651} introduced a radically different approach by defining morality as a social construct emerging from self-interest, necessary for societal stability and preventing the "state of nature", which he described as a war of all against all. Jean-Jacques Rousseau (1762), in The Social Contract~\cite{Rousseau1762}, responded to Hobbes by proposing that morality derives from an innate human goodness that is later corrupted by society, distinguishing between natural compassion and the moral norms constructed within political communities. Around the same time, David Hume (1739), in A Treatise of Human Nature~\cite{Hume1739}, argued that morality is fundamentally grounded in human emotions rather than pure reason, contending that moral judgments stem from sentiments like sympathy rather than logical deductions. Immanuel Kant’s Groundwork of the Metaphysics of Morals~\cite{Kant_groundwork_moral} (1785) provided a rationalist counterpoint, rejecting Humean sentimentalism and asserting that moral principles must be derived from reason alone, introducing the categorical imperative, which dictates that moral laws should be universalizable and rooted in respect for human dignity. Shortly after, John Stuart Mill (1861), in Utilitarianism~\cite{Mill1861}, introduced a consequentialist approach, defining morality as the maximization of happiness and minimization of suffering, advocating that the rightness of actions is determined by their outcomes in relation to the greatest happiness principle. Friedrich Nietzsche (1887), in On the Genealogy of Morality~\cite{Nietzsche1887}, radically challenged traditional moral frameworks, particularly those influenced by Christianity and Kantian ethics, arguing that moral norms are historically contingent and rooted in power dynamics. He distinguished between master morality, characterized by strength and self-affirmation, and slave morality, which he associated with humility, guilt, and compassion, calling for a re-evaluation of values. These foundational works collectively shape contemporary moral thought, integrating virtue ethics, deontological principles, consequentialism, sentimentalism, social contract theory, and historical critique into a comprehensive framework for understanding morality.

\nextdiv
If we assume that there is such a thing as a linear chronological continuum in the development of a universally accepted definition of \textit{morality}, we could define the term as follows:

\begin{definition}[Morality]
	the system of principles, values, and norms that guide human conduct, balancing reason, emotion, and social cooperation to determine right and wrong. It is grounded in the pursuit of human flourishing (Aristotle), the rational application of universal duties (Kant), the maximization of collective well-being (Mill), the influence of human sentiment (Hume), the historical and cultural re-evaluation of values (Nietzsche), and the necessity of social cohesion (Hobbes and Rousseau).
\end{definition}


This definition acknowledges morality as a multi-faceted construct, shaped by ethical reasoning, human emotions, social agreements, and evolving historical contexts. It integrates the core elements of virtue ethics~\cite{Aristotle_nicomachean, Hursthouse1999}, deontology~\cite{Kant_groundwork_moral, Wood2007}, consequentialism~\cite{Mill1861, Singer2011}, sentimentalism~\cite{Hume1739, Smith2003}, critique of values~\cite{Nietzsche1887}, and social contract theory~\cite{Rachels2012, Audi2010}, making it a synthesis of the most enduring contributions to moral philosophy.

\nextdiv
This comprehensive synthesis, however, does not imply the existence of a single, universally accepted definition of morality. As noted by Gert and Gert~\cite{Gert2020}, the concept of morality is inherently ambiguous, employed in at least two distinct senses: a descriptive sense, referring to the codes of conduct endorsed by societies, groups, or individuals, and a normative sense, which attempts to establish a universal standard that rational agents would accept under ideal conditions. This \textit{duality} or \textit{dicotomy}, alongside historical and cultural variations in moral thought, prevents any definitive, uncontested characterization of morality. Some philosophers, such as Sinnott-Armstrong~\cite{Sinnott-Armstrong2016}, have even argued that morality itself is not a unified domain, making any attempt at a singular definition inherently problematic. Furthermore, while moral philosophers have long engaged in theorizing about moral principles and ethical frameworks, explicit definitions of morality remain scarce, often giving way to discussions about moral judgment instead~\cite{Hare1991, Hare1981}. This ongoing conceptual fragmentation underscores that morality is not a fixed, objectively defined entity, but rather a historically contingent and philosophically contested construct, one that continues to evolve in response to new ethical, social, and scientific challenges.

Morality is a system of guiding principles that regulate behavior by distinguishing between right and wrong actions~\cite{Gert2020, Turiel1983}. It exists in two broad forms: \textit{a)} as a descriptive system, which refers to the moral codes followed by societies or individuals~\cite{Wood2007}, and \textit{b)} as a normative system, which refers to the principles that would be endorsed by all rational agents under specified conditions~\cite{Scanlon1998}. While moral norms vary across cultures and contexts, their function is generally to facilitate social cooperation~\cite{Haidt2012}, reduce harm~\cite{Tarsney2024}, and promote fairness.

\fpincom{Portion about moral judjments here. Also by now there should be two dicotomies and relative figures.}

The study of morality requires not only an examination of specific moral judgments but also an understanding of how moral systems function as a whole. Philosophers attempt to systematically account for morality, treating it as a normative system with defined principles and reasoning structures. At its most basic, morality consists of norms and principles that regulate human actions, particularly in relation to others. These norms are not arbitrary but are seen as carrying a special kind of weight or authority, meaning they are not merely preferences but obligations that structure human interaction~\cite{Strawson1961}.

Beyond this minimal definition, morality can also be understood as a system of moral reasons—either grounded in some more fundamental values or, alternatively, as the foundation upon which value is built~\cite{Raz1999}. This dual perspective raises an important question: Are moral norms universal, or do they vary based on cultural and situational factors?

A common view is that moral norms are universal—they apply to all rational agents in similar circumstances. This universality is supported by the notion that moral principles can be formulated without reliance on specific personal details, meaning they should apply consistently across cases rather than being tailored to individuals~\cite{Rawls1979}. Furthermore, morality is commonly regarded as impartial, requiring that all individuals be considered equally in moral deliberation.

%% Mora decision making
%
%
\section{Moral Decision-Making}
Moral decision-making~\footnote{In philosophy, compound modifiers like "decision-making" are typically hyphenated when used adjectivally to ensure clarity and precision. The hyphen explicitly ties "decision" to "making," emphasizing their joint function as a single concept. "Moral decision-making" aligns with established philosophical and ethical literature, where the term is used to describe the process of evaluating and choosing actions based on moral principles or values. In psychology, "decision-making" is widely recognized as a compound noun, referring to the cognitive process of selecting a course of action. The hyphen is consistently used in research contexts (e.g., "rational decision-making," "emotional decision-making"). Here "Moral decision-making" is preferred to avoid ambiguity, as "moral decision making" could suggest a looser connection between the act of deciding and the process of making, which could lead to interpretive issues.} is a complex cognitive process rooted in the integration of reasoning and affective information within the nervous system~\cite{Buon2016, Glenn2009}. It engages a distributed brain network—including regions responsible for perspective-taking~\cite{Eres2018}, emotional regulation~\cite{Young2012, Fede2020}, and translating cognitive appraisals into behavior~\cite{Garrigan2016}—emphasising action rather than abstract moral deliberation, which collectively work to produce\textit{ actionable outcomes}.

By emphasising action rather than abstract moral deliberation, this process ensures that moral cognition is inherently directed toward navigating real-world societal challenges, translating abstract evaluations into practical behavior. The concept of actionable outcomes underscores the practical implications of moral decision-making processes, transcending abstract moral deliberation to yield measurable behaviors and tangible results. In this framework, the integration of cognitive and affective processes culminates in observable actions, forming a crucial bridge between moral psychology and computational analysis. This approach aligns directly with our second research question (Q2), which explores whether moral decisions leave discernible, machine-detectable behavioral cues. By investigating how moral choices manifest as physical traces, we extend the traditional boundaries of moral psychology into the domain of Computational Machine Ethics. This not only provides empirical grounding for the theoretical frameworks discussed but also establishes a novel methodological foundation for validating human moral behavior theories through technological means.

We should briefly point out that the term \textit{moral cognition}\label{moral_cognition} above refers to the broader set of cognitive and affective processes involved in understanding, evaluating, and reasoning about moral concepts, dilemmas, and principles~\cite{Young2012, Gazzaniga2014}. In contrast, moral decision-making is the \textit{specific process} by which moral cognition culminates in the selection of a course of action in response to a moral scenario~\cite{Cushman2013}. While moral cognition encompasses abstract deliberation, perspective-taking, and the integration of emotional and rational inputs, moral decision-making functions as its \textit{actionable output}, where abstract cognitive evaluations are transformed into concrete behaviors~\cite{Greene2001, Haidt2012}.\\ \hspace*{2em}Both processes stem from a broader psychological framework that governs moral thought and behavior. This framework can be understood through two distinct but interrelated constructs: \textit{moral functioning} and \textit{moral agency}.

\nextdiv
Moral functioning refers to the cognitive, affective, and behavioral mechanisms that enable moral understanding and action\cite{Narvaez2005, Doris2010}. It represents the psychological architecture underlying moral cognition and decision-making, encompassing processes such as moral sensitivity, reasoning, and emotional regulation. In essence, moral functioning provides the internal structure that allows individuals to recognize moral dilemmas, evaluate their ethical dimensions, and formulate responses. However, moral functioning alone does not necessarily lead to moral action. Moral agency, on the other hand, is the capacity to act intentionally and responsibly in moral contexts\cite{Bandura1991, Skitka2012}. While moral functioning supplies the necessary cognitive and emotional structures for moral thought and behavior, moral agency actualises these capacities by incorporating self-awareness, autonomy, and accountability in decision-making. A morally functioning individual may recognize an ethical issue and deliberate on its implications, but moral agency is what allows them to translate this deliberation into socially and ethically accountable action.\\ 
\hspace*{2em}The relationship between these constructs can be understood through an analogy: if moral functioning is the engine of a car, moral agency is the driver. The engine provides the necessary mechanisms for movement (cognition, affect, and decision-making), but it is the driver who exercises intentional control, making conscious decisions about direction, speed, and response to external conditions. Thus, moral functioning is a prerequisite for moral agency, providing the cognitive and emotional foundation upon which autonomous and accountable moral actions are built.\\ 
\hspace*{2em}In this integrated framework, moral cognition provides the evaluative structure upon which moral decision-making operates, while moral functioning and moral agency ensure that these processes are both internally coherent and socially actionable~\cite{Baumeister2010}. At the intersection of moral cognition and moral decision-making lies moral agency, which enables individuals to engage in morally relevant reasoning and behavior. This interplay between cognitive structures, decision-making processes, and individual agency reflects the dynamic and contextual nature of human morality~\cite{Lapsley2015}.

\section{Moral Decision-Making: Neural Evidence for Its Practical Nature}
 
Arguably, the term moral-decision making has often been misunderstood as an abstract exercise in philosophical reasoning outside neurospychological context, likely due to the connotations of the term "moral" that accompanies the tuple "decision-making"~\cite{Doris2002, Greene2001}. Some published work show that this misconception often reduces the discussion around moral cognitive processes to a purely theoretical endeavor divorced from their practical nature~\cite{Lapsley2006}. However, moral decision-making is fundamentally rooted in cognitive processes that prioritise actionable outcomes. Its primary function is not merely to deliberate abstractly but to translate moral evaluations into behaviors that enable agents to navigate complex real-world scenarios.\\
\hspace*{1em}Advancements in neuroscience, particularly the development of functional neuroimaging techniques like Functional Magnetic Resonance Imaging (fMRI) in the early 1990s~\cite{Bigler2017, Faro2010}, have provided robust empirical evidence to support this perspective. By enabling non-invasive visualization of brain activity through blood-oxygen-level-dependent contrast, fMRI has revolutionised our understanding of brain functions in vivo~\cite{Bigler2017}. Studies employing these methods can help identified significant overlaps between neural circuits involved in moral reasoning and those associated with practical, action-oriented decision-making. Several lines of evidence found in the published work suggest that there are key regions clearly implicated might include:

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\rightskip1.5cm
	\leftskip1cm
	\item[a)]the medial prefrontal cortex, 
	\item[b)]the posterior cingulate cortex, 
	\item[c)]superior temporal sulcus (STS), 
	\item[d)]precuneus/posterior parietal cortex, 
	\item[e)]orbitofrontal cortex, and 
	\item[f)]the inferior parietal lobule
\end{itemize}

When analyzed collectively, these regions, which will be referred to by their Brodmann Area (BA) classifications, reveal a pattern: moral decision-making is not an abstract exercise but a cognitive process intrinsically oriented toward producing actions. Cross-analyses of their functional roles, the social pathologies arising from damage to these regions, and their integrative neural linkages might underscore this conclusion~\cite{Greene2002}. This growing empirical literature thus provides a compelling basis for reframing moral decision-making as a process designed for practical, societal applications rather than theoretical abstraction.

\partitle{Medial prefrontal cortex}

In particular, the medial prefrontal cortex (commonly associated with BA 9/10) might serves as a critical neural hub for integrating cognitive and emotional processes that underlie moral decision-making and guide practical behavior. Much of the literature since early 2000s have shown that this region supports higher-order cognitive functions, including decision-making, planning, and behavioral regulation, by integrating information about current goals, contextual cues, and potential future outcomes to facilitate adaptive, goal-directed behavior~\cite{Castelli2013, Frith2001}. Its role in maintaining and updating working memory enables individuals to weigh competing priorities and select optimal courses of action in real-world contexts~\cite{Frith2001}. Functional imaging studies further highlight its involvement in processing complex social information, such as inferring others’ intentions and assessing the contextual appropriateness of responses—capabilities essential for coordinated, intentional actions~\cite{Castelli2013}. Importantly, this region mediates the integration of abstract moral concerns into practical decision-making, directly linking moral reasoning to actionable, goal-directed behavior~\cite{Greene2002}. By bridging moral reasoning with behavior, the medial prefrontal cortex exemplifies how moral cognition operates as a process of practical reasoning.

\partitle{Posterior cingulate cortex and STS}
\label{posterior_cingulate_cortex_STS}
The posterior cingulate cortex and the posterior superior temporal sulcus (STS)/inferior parietal lobule have been widely recognized in the literature as playing critical roles in integrating memory, perception, and social cognition to support practical, goal-directed actions. Evidence from functional neuroimaging studies suggests that the posterior cingulate cortex facilitates the retrieval of episodic memories and integrates them with contextual information, enabling individuals to simulate and evaluate potential actions and their outcomes~\cite{Maddock1999, Kiehl2001}. As noted by Maddock~\cite{Maddock1999}, its connections with the hippocampal formation and parahippocampal cortex provide a foundation for translating memory-based evaluations into adaptive decision-making.\\
\hspace*{2em}In parallel, the posterior STS and inferior parietal lobule have been identified as central to processing socially significant dynamic stimuli, such as biological motion and intentional actions, which are critical for inferring others' goals and guiding contextually appropriate motor responses~\cite{Brothers1992}. Together, these regions are frequently described as integrating episodic memory, spatial reasoning, and social perception to generate informed, actionable behaviors. Greene~\cite{Greene2002} has emphasized how this network links evaluative processes with real-world decision-making, allowing individuals to simulate the social and ethical consequences of their actions. This body of research collectively establishes that these neural structures form a critical basis for moral decision-making, reinforcing its characterization as a practical, adaptive process.

\partitle{The precuneus}
%
The precuneus, also referred to as the posterior parietal cortex, has been extensively studied for its role in integrating spatial, sensory, and social information, which are critical for action-oriented moral decision-making. Previous research has highlighted its involvement in visuospatial processing, mental imagery, and perspective-taking, functions that support the simulation and evaluation of actions within complex, real-world scenarios~\cite{Greene2002, Moll2002}. For instance, Damasio~\cite{Damasio2000} has shown that this region integrates self-referential thought and contextual information, enabling individuals to anticipate the social and ethical consequences of their actions.\\
%
\hspace*{2em}Functional neuroimaging studies frequently report consistent activation of the precuneus during tasks involving moral reasoning and simulations of potential outcomes, as noted by Moll and colleagues~\cite{Moll2001, Moll2002}. These studies suggest that its activation patterns overlap significantly with those observed in regions associated with social cognition, such as the superior temporal sulcus, indicating a broader network dedicated to integrating social and spatial cues into adaptive responses. Additionally, Damasio~\cite{Damasio2000} emphasizes that this region supports attentional control, allowing individuals to evaluate competing priorities and align their behaviour with social norms. Notably, the precuneus appears to bridge abstract moral considerations with practical reasoning by integrating information from both memory systems and perceptual mechanisms, enabling dynamic decision-making across varying contexts.\\
%
\hspace*{2em}Collectively, the literature positions the precuneus as a key node in the neural networks underlying moral reasoning, particularly in its ability to connect visuospatial cognition with moral deliberation and facilitate actionable, goal-directed responses~\cite{Greene2002, Caspers2013}. This capacity to integrate multiple streams of cognitive and affective input underscores its indispensable role in transforming moral reflection into practical, context-sensitive behaviour.

\partitle{The orbitofrontal cortex}
%
The orbitofrontal cortex, commonly associated with Brodmann Areas 10 and 11, has been consistently identified in the literature as a critical integrative hub for transforming abstract moral considerations into practical behavioural outcomes. This region plays a central role in real-world decision-making processes, particularly in reward-based decision-making and behavioural inhibition, which are essential for evaluating the social and ethical consequences of potential actions. As noted by Moll and colleagues~\cite{Moll2002b, Moll2001}, the medial and lateral subdivisions of the orbitofrontal cortex are pivotal in linking actions to their respective social and environmental outcomes, with the medial subdivision specialising in moral and social dimensions of decisions. These functions are underpinned by neural representations of reward and punishment, which guide behaviour in complex, socially charged scenarios~\cite{Greene2002}.\\
%
\hspace*{2em}Functional imaging studies frequently highlight the orbitofrontal cortex's engagement in explicit moral judgment tasks and its involvement in autonomic and emotional regulation during morally relevant decision-making~\cite{Odoherty2001, Damasio2000}. This dual role of cognitive evaluation and emotional regulation reinforces its integrative function in aligning abstract moral reasoning with actionable behaviours. Moreover, evidence from clinical studies underscores the consequences of damage to this region, which often results in impaired social decision-making, diminished moral sensitivity, and inappropriate behaviours~\cite{Damasio2000, Moll2002b}. Such findings provide compelling support for its essential role in ensuring that ethical reasoning translates into socially appropriate behavioural outcomes.\\
%
\hspace*{2em}Taken together, the literature positions the orbitofrontal cortex as a key neural structure in moral decision-making, enabling individuals to navigate ethical challenges within dynamic social environments~\cite{Greene2002}. Its ability to synthesise cognitive, emotional, and social inputs into adaptive, context-sensitive behaviours exemplifies the practical and action-oriented nature of moral cognition.

\partitle{The superior temporal sulcus and inferior parietal lobule}\fpincom{Minor overlaps with  STS paragraph abpve. Stramline to solve.}
%
Unlike the previous discussion, which focused on broader functional networks and integrative roles (see page~\pageref{posterior_cingulate_cortex_STS}), this section highlights the specific contributions of the superior temporal sulcus (STS) and inferior parietal lobule, frequently associated with Brodmann Area 39. These regions are examined together due to their complementary roles in processing dynamic social cues and integrating perceptual and conceptual information, both of which are central to linking moral reasoning with practical, action-oriented behaviour~\cite{Moll2002}.

The superior temporal sulcus (STS) and inferior parietal lobule have been widely recognised in the literature for their pivotal roles in perceiving and interpreting dynamic social cues, such as biological motion, gaze direction, and intentionality~\cite{Allison2000, Decety2004}. These regions are integral to the social cognition processes that underpin moral reasoning, as they enable the detection and interpretation of socially significant movements and intentions. As highlighted by Greene~\cite{Greene2002}, the STS and inferior parietal lobule facilitate the direct linkage between moral judgments and action-relevant social cues, ensuring that moral evaluations inform contextually appropriate responses in real-world scenarios.

Functional neuroimaging studies reveal that the STS is uniquely positioned to process biological motion and goal-directed actions, acting as a computational hub for inferring others' intentions and mental states~\cite{Allison2000, Moll2002}. Moll et al.\cite{Moll2002} further demonstrate that the STS collaborates with regions such as the medial prefrontal cortex to translate social cues into moral evaluations, reinforcing its role in facilitating practical, socially guided behaviour. Simultaneously, the inferior parietal lobule, as emphasised by Decety\cite{Decety2004}, is crucial for representing intentional actions and integrating sensory and motor information, enabling moral reasoning to bridge abstract ethical considerations with concrete, action-oriented outcomes. This dual functionality ensures that both regions work in tandem to support the seamless transition from moral deliberation to behavioural execution.

Cross-analyses of neuroimaging studies and lesion-based evidence further highlight how these regions interact within a broader network underpinning moral cognition. For example, Greene et al.\cite{Greene2002} observed that tasks requiring moral judgment consistently activate the inferior parietal lobule in concert with the STS, suggesting their joint involvement in integrating perceptual and conceptual information for adaptive decision-making. Additionally, evidence from Lane et al.\cite{Lane1997} indicates that disruptions in these regions due to damage or pathology can impair social cognition, leading to deficits in empathy and moral sensitivity. Such findings underline the indispensable role of the STS and inferior parietal lobule in facilitating contextually appropriate moral decisions.

Together, these regions exemplify the practical nature of moral decision-making, as they allow individuals to process dynamic social environments and produce adaptive behaviours. Their capacity to synthesise sensory, social, and cognitive information not only supports the detection of morally salient cues but also ensures that moral reasoning leads to actionable outcomes in ethically complex scenarios. This integrative function situates the STS and inferior parietal lobule at the core of a neural network dedicated to the real-world applicability of moral cognition~\cite{Greene2002, Allison2000, Decety2004, Lane1997, Moll2002}.

The collective insights derived from the literature reviewed foreground moral decision-making as a fundamentally social and action-oriented process, deeply embedded in practical reasoning. Rather than being purely reflective or rational, moral cognition emerges as an intuitive and dynamic mechanism, where evaluative processes are seamlessly integrated with contextual, emotional, and social cues to guide adaptive behaviours. Each neural region examined contributes to this framework by prioritising actionable outcomes over abstract deliberations, thereby aligning moral decision-making with its practical and context-sensitive nature.

The medial prefrontal cortex exemplifies this integrative function by harmonising affective and cognitive signals to support goal-directed actions. Similarly, the posterior cingulate cortex and superior temporal sulcus underscore the role of memory and social cognition in situating moral choices within a broader context of lived experience. These regions, in tandem with the precuneus, enable individuals to simulate potential actions and anticipate their outcomes, embedding moral deliberation within the spatial and social fabric of human interaction. Meanwhile, the orbitofrontal cortex transforms abstract ethical principles into behaviourally relevant responses, mediating between competing priorities and the demands of real-world scenarios. The superior temporal sulcus and inferior parietal lobule, critical for interpreting dynamic social cues, ensure that moral reasoning remains sensitive to the social and ethical intricacies of everyday life.

Crucially, this synthesis reinforces a social intuitionist perspective of moral reasoning, wherein decisions are not solely the product of deliberative rationality but are grounded in pre-reflective, affect-laden intuitions that are subsequently shaped by cognitive and social processes. This challenges traditional rationalist views, suggesting instead that moral reasoning is often a post hoc rationalisation of intuitions arising from evolved neural mechanisms designed to prioritise social cohesion and practical action.

Moreover, this framework sets the stage for exploring the dichotomy between teleological and deontological reasoning. The empirical evidence supports the view that moral decision-making is not limited to rigid rule-following (as in deontological ethics) but reflects the adaptive flexibility of teleological reasoning, where decisions are oriented toward achieving ethical outcomes in specific, context-dependent scenarios. This aligns with the Aristotelian notion of practical reason, where moral reasoning is inherently purposive, aiming to resolve ethical challenges in complex and dynamic social environments.

By bridging neuroscience with the normative theories of practical and teleological reasoning, this synthesis not only advances our understanding of moral cognition but also highlights the fundamentally social and intuitive nature of moral decision-making. This perspective has significant implications for applied fields such as artificial intelligence, where designing morally intuitive systems necessitates prioritising action-oriented and socially adaptive ethical frameworks.

with little consensus about a precise definition~\cite{Wallace2020, SEP-moral-reasoning}. 

\nextdiv
Differences in research approaches to moral decision-making, informed by various theories and perspectives, have led to a discrepancy in the definitions of its nature. This complexity arises from the interplay between cognitive, emotional, social, and cultural factors, each of which plays a significant role in shaping moral judgments~\cite{Bartels2015}. Dual-process theories highlight this interplay, suggesting that moral decisions involve both rational, deliberative processes and fast, intuitive judgments. For example, the Social Intuitionist Model emphasizes the primacy of emotional responses, with reasoning often serving as a post hoc justification for decisions, rather than their origin.

Situational and contextual influences further complicate the definition of moral decision-making. Cultural norms, social pressures, and environmental factors significantly impact what is considered moral, making it challenging to create a universal framework for understanding these decisions. Additionally, individual differences, such as personal values, upbringing, and prior experiences, add to the variability in how morality is processed cognitively. This diversity is reflected in neuroscientific evidence, which shows that moral decision-making activates a distributed network of brain regions associated with reasoning, emotion, and social cognition, illustrating its integrative and context-dependent nature.

Moreover, developmental and evolutionary considerations demonstrate that morality is not static but evolves over time. Developmental theories, such as Kohlberg's stages of moral development, show how cognitive and emotional maturity interact to shape moral reasoning. From an evolutionary perspective, moral behaviors are thought to have developed as adaptive mechanisms for promoting cooperation and social cohesion, blending innate instincts with learned cultural norms. These perspectives highlight that moral decision-making cannot be reduced to a single cognitive domain but rather encompasses an interplay of diverse influences.

The inherent multidimensionality of moral decision-making also poses challenges for researchers attempting to measure and define it. The overlap of cognitive processes with emotional and social dimensions often results in conflicting definitions and findings across disciplines. As a result, moral decision-making remains a dynamic and multifaceted process that resists simplification, reflecting its deeply rooted integration within human cognition, emotion, and society.

\nextdiv
This conceptual challenge becomes even more pronounced when examined through philosophical terms, where debates persist to date about the intricate relationship~\cite{SEP-moral-reasoning} between:

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\rightskip1.5cm
	\leftskip1cm
	\item[-] \textit{first-order moral truths}: in the realm of moral philosophy are propositions that directly govern or describe the ethical principles for example, statements such as "It is wrong to harm others without justification" or "Justice demands equal treatment for all" are considered first-order moral truths because they articulate specific moral norms or values without delving into the underlying frameworks or theories that validate their authority 
	\item[-] \textit{duties}, or values: obligations or responsibilities that arise from moral, legal, or social principles, guiding individuals to act in specific ways deemed necessary or appropriate, that {ought} to guide human action, where:
	\item[-] \textit{ought} refers to normative imperatives indicating how individuals are morally or rationally required to act, based on principles of ethical reasoning.	
\end{itemize}

together with the metaphysics of morality, and the practical application of these in real-life situations.

\nextdiv
Moreover, different philosophical, and psychological, schools of thought offer diverging perspectives on the role of key core concepts for defyingn precisily moral decision making such as:

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\rightskip1.5cm
	\leftskip1cm
	\item [-] Moral facts:  Some emphasise the direct perception of moral facts~\cite{Ross2002, Haidt2001, Audi2015}, while others argue for more complex reasoning processes in situations with novel perplexities and conflicting moral considerations~\cite{Kant_groundwork_moral, Greene2014, Rawls2020}.
	\item[-] Moral principles: Some find moral principles essential for reasoning~\cite{Kant_groundwork_moral, Rawls2020}, while others, like particularists, argue for the existence of moral reasons independent of any general principle~\cite{Dancy2004, McDowell1979, Hooker2000}.
	\item[-] Moral psychology: Differing views on the role of emotions and motivations in shaping reasoning also contribute to the lack of a unitary definition.
\end{itemize}

%% This definition is mine, I need to check it is okay to use it.
%
% In this part we Moral Decision mking as a process that deliberates what action
% agents ought to take in real settings, and thus perfor a real phisical
% action that acts on her environment.
%

\begin{definition}[Rational Model]
	\textit{Moral decision making}, is the cognitive process of choosing between competing moral judgments \ie, mutually exclusive evaluations we make on what is right or wrong, good or bad, and that we use as motive, purpose and direction for our conscious, and practical behaviour.
\end{definition}

While widely varying definitions of the term moral have been suggested, a precise definition of moral decision making has proved elusive~\cite{Wallace2020, SEP-moral-reasoning}. The deficition we adopt here our own version as presented above. This version is a first particular case of a more general version of the definition which we will introduce at the end of this chapter, after discussing its components. Moral decision making embobies a multitude of which we will only introduce for completeness:

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\rightskip1.5cm
	\leftskip1cm
	\item [a)] \textbf{Cognitive Process} This term refers to the mental actions or operations that individuals use to acquire knowledge and understanding. It includes processes such as perception, memory, reasoning, decision-making, and problem-solving. Cognitive processes are essential for interpreting and interacting with the world~\cite{APA2015, Anderson2005_cognitive, Neisser1967, Baddeley2020, Kahneman2011};
	\item [b)] \textbf{Behaviours:} In academic terms, behaviours are the observable actions or reactions of an individual in response to external or internal stimuli. These actions can be voluntary or involuntary and are influenced by various factors, including cognitive processes, emotions, and environmental conditions~\cite{Skinner1953, APA2020, Baumeister2020}

	
\end{itemize}

\nextdiv
\nextdiv
and more complex process \ie, 

\nextdiv
\textit{Moral Reasoning: Theories in Philosopy}

\noindent
In an exclusively and formally philosophycal acceptance, provided \textit{not} in any particular chronological order, \fpincom{...but in a what that the computer science reader can ... or anything that glue the next portion of text} Jonathan Dancy, a prominent moral particularist, argues that "reasons holism", the idea that a reason in one case may be different or absent in another, supports philosophical position known as Moral Particularism according to which moral reasoning does not rely on fixed principles but instead depends on the context-specific evaluation of reasons~\cite{Potrc2010}. At its core, particularism rejects the idea that the morally perfect person is the "person of principle." Instead, it posits that moral sensitivity requires recognizing how features of a situation contribute to moral judgments in contextually variable ways. Dancy illustrates this with the "holism of reasons," which argues that a reason that counts in favor of an action in one situation might count against it or hold no relevance in another. For example, promising to do something is generally a reason to act, but this reason can be nullified or inverted in unique cases, such as when the promise itself is immoral or coerced~\cite{Dancy2017-SEP}. The practical implications of particularism are significant. It suggests that moral agents must focus on the specific details of a situation rather than applying pre-set rules. This approach allows for greater flexibility and responsiveness to moral complexity. For example, a rule prohibiting lying might fail to account for scenarios where lying protects an innocent life, while a particularist framework would weigh the specific reasons at play and decide accordingly~\cite{Dancy2004}

\nextdiv



%% Where we close the philosophical overview on moral reasoning
%
\nextdiv
The key aspect of the traditional philosophycal discourse on the topic is to characterised moral reasoning as a specific form of practical reasoning, emphasizing its role in guiding moral actions and resolving conflicts, operating as the process through which agents figure out what they \textit{morally ought to do} in concrete situations. Unlike theoretical reasoning, which seeks to understand principles or truths, moral reasoning directly addresses the question: "What should I do?"~\cite{Richardson2018} and frames moral reasoning as practical reasoning because it resolves \textit{real-life dilemmas} by weighing competing moral values and considerations. For instance, deciding whether to prioritize loyalty to family or a broader duty to society exemplifies moral reasoning in action. This deliberative process of moral reasoning is, indeed, \textit{practical} in two essential respects. Firstly, it pertains to the \textit{domain of action}, as its focus is on resolving questions related to what \textit{should be done}. Secondly, it is practical in its \textit{outcomes}, as the act of reflecting on matters of action inherently guides and motivates individuals toward acting~\cite{Wallace2020}. A natural way to interpret this point of view is to contrast it with the standpoint of theoretical reason.

\nextdiv
Theoretical reasoning is concerned with resolving questions that are fundamentally theoretical rather than practical in nature. It focuses on explanation and prediction, retrospectively asking why events have occurred and prospectively determining what might happen in the future. Paradigmatic expressions of theoretical reasoning are found in the natural and social sciences, where causal relationships and empirical evidence are central~\cite{Nagel1979, Hempel1965, Tversky1974, Hirschfeld1994}. Beyond this, theoretical reasoning also extends to \textit{non-causal explanations}, such as those explored in metaphysical, logical, and conceptual inquiries. Its focus on understanding matters of fact is distinct in its impersonal and \textit{universally accessible approach}, which contrasts with the more situated and action-oriented focus of practical reasoning. Practical reasoning, by contrast, centers on deliberation about what one \textit{ought to do}, providing guidance for action in specific circumstances. Unlike theoretical reasoning, which seeks to understand the world as it is, practical reasoning addresses how to navigate complex situations and achieve goals. It operates across a wide range of contexts, from moral obligations, such as promoting well-being or fulfilling promises, to professional domains like medicine, scientific experimentation, artistic creation, or athletic performance. Practical reasoning is also tied to how-to knowledge and technical skill, enabling individuals to adapt to dynamic environments and deliberate effectively about actions.

\nextdiv
Theoretical reasoning, in this sense, reflects on what reasons justify accepting particular claims as true. Its focus is on evidential considerations that indicate the likelihood of propositions being correct. Practical reasoning, by contrast, deliberates on what makes actions desirable or worthy of choice. Its reasons are those that justify actions as worth performing. This divergence in subject matter also leads to different outcomes: theoretical reasoning modifies one’s belief system by aligning it with truth, whereas practical reasoning culminates in action. As previously noted, practical reasoning is tied to action not only in its subject matter but also in its purpose and results.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{/home/francesco/Desktop/research/work/thesis/img/diagrams/TypesOfReasoning.pdf}
	\caption{Diagram illustrating the types of reasoning, distinguishing between theoretical and prescriptive reasoning.}
	\label{fig:types_of_reasoning}
\end{figure}

\nextdiv
Lastly, it should be said that despite their differences, theoretical and practical reasoning share an underlying structural unity. Both involve evaluating reasons, assessing justification, and adhering to principles of rationality, albeit in different domains. This shared framework is evident in our common vocabulary: we \textit{speak} of what is "right to do" and "right to think," of being "justified" in both actions and beliefs, or of having reasons for what we choose or conclude. This structural unity reveals how the forms of reasoning mirror one another, even as their substantive concerns diverge—whether focusing on understanding facts, guiding action, or grounding belief.

\nextdiv
Historically, the term moral reasoning as been used in philosophical discourse to describe any deliberative thinking that responsibly engages with moral considerations, to arrive at \textit{actionable conclusions}. Unlike purely theoretical ethics, moral reasoning directly influences practical outcomes, often navigating conflicts between competing moral principles or obligations~\cite{Richardson2018}. This practical orientation ensures that moral reasoning is treated not merely as an abstract exercise but is tied to real-world actions and decisions. The philosophical importance of moral reasoning lies in its capacity to handle conflicts of values and integrate competing moral considerations into coherent courses of \textit{action}.

%% Is moral reasoning different from practical reasoning?
%
\nextdiv
Finally, the source questions whether moral reasoning is truly distinct from practical reasoning more generally. Different moral theories offer different answers. Aristotle, for example, saw a unified structure in practical reasoning, with the virtuous person simply having their sights set on the true good. Kant, however, saw moral reasoning as distinct, involving considerations of universalizability that aren't present in prudential reasoning. Given this diversity, the source suggests remaining agnostic on the relationship between moral and non-moral practical reasoning unless one assumes the correctness of a particular moral theory.

%% We start here a scietific, laboratory based description of moral reasoning.
%
\nextdiv
However, there are challenges. Empirical studies suggest we often reason poorly in moral situations. We can be 'dumbfounded' when asked to justify our moral intuitions and are susceptible to biases. This could lead to revisions in our norms of moral reasoning, a point the source acknowledges.

\nextdiv
This process involves an array of cognitive functions such as perception, memory, reasoning, and problem-solving, which collectively inform our moral evaluations and decisions~\cite{Greene2001, Bechara2000, Churchland2011}. Moreover, these cognitive processes translate into behaviours, which are the \textit{observable} manifestations of our moral choices. These behaviours, whether conscious or subconscious, reflect our internal moral deliberations and are influenced by a complex interplay of cognitive functions, emotions, and contextual factors. A number of recent experimental work have explored how cognitive attributions of intentionality influence moral judgments and subsequent behaviors, demonstrating the observable translation of moral cognition into action.

In~\cite{Bechara2000}, Antoine Bechara et.al., explores the neurobiological underpinnings of decision-making through the lens of the somatic marker hypothesis. This framework posits that decision-making is shaped by marker signals, which arise from bioregulatory processes—including emotions and feelings, and guide behavior by associating specific outcomes with somatic states. These processes are mediated by a network of cortical and subcortical structures, with the ventromedial prefrontal cortex (VMPC) playing a pivotal role.

Central to the hypothesis is the idea that decision-making is influenced by both conscious and unconscious processes. While reasoning and knowledge about options are critical, emotional responses provide biases that help narrow the decision-making space. These biases, often experienced as gut feelings or anticipatory emotions, act as alarm signals, highlighting advantageous or disadvantageous outcomes and allowing rapid, context-sensitive decisions.

The role of the VMPC in this system is particularly significant. Damage to this region disrupts the ability to generate somatic markers, leading to impairments in social and moral behavior. Patients with VMPC lesions exhibit an inability to make advantageous decisions, particularly in complex, uncertain scenarios. The article discusses this through the "gambling task," a laboratory simulation that mimics real-life decision-making by factoring in reward and punishment. While healthy participants learn to select options with favorable long-term outcomes, VMPC patients persistently choose options offering immediate rewards despite long-term losses, demonstrating a "myopia for the future."

The inability of VMPC patients to generate anticipatory physiological responses, such as skin conductance changes, underscores the importance of somatic markers in decision-making. In healthy individuals, these anticipatory responses develop before conscious knowledge of advantageous choices, suggesting that unconscious emotional signals precede and guide cognitive reasoning. VMPC patients, in contrast, fail to produce these signals, even when they consciously understand the consequences of their choices. This dissociation highlights the critical role of emotion in shaping decisions, beyond purely rational calculations.

The article also distinguishes decision-making processes from related cognitive functions, such as working memory. While the dorsolateral prefrontal cortex (DLPFC) is essential for maintaining and manipulating information, the VMPC's primary function lies in linking knowledge about situations with emotional valence. This distinction is supported by evidence that VMPC patients with intact working memory still exhibit impaired decision-making, emphasizing the specialized contribution of emotional processing to ethical and practical deliberations.

From a broader perspective, the findings reinforce the argument that moral and practical decision-making behaviors are not solely products of rational deliberation but are profoundly influenced by the interplay of cognitive and emotional systems. The somatic marker hypothesis provides a compelling explanation for how unconscious emotional biases, shaped by prior experiences, dynamically interact with conscious reasoning to produce decisions. These processes align with the claim that moral deliberations and behaviors reflect a complex integration of cognitive functions, emotions, and contextual factors.

By identifying the neural substrates and mechanisms of these interactions, the article advances our understanding of decision-making as a holistic process. It underscores the necessity of considering emotional and somatic components in ethical theory, legal frameworks, and practical applications, such as treatment for decision-making deficits in clinical populations or the development of artificial intelligence systems capable of emulating human moral reasoning.

\nextdiv
Churchland’s work~\cite{Churchland2011} supports the claim that moral deliberations and behaviors are influenced by a complex interplay of cognitive functions, emotions, and contextual factors. By grounding morality in neurobiological processes, Churchland demonstrates how moral decision-making reflects the integration of innate capacities with cultural and environmental influences. This perspective aligns with broader interdisciplinary efforts to understand morality as a dynamic and adaptive feature of human cognition, with implications for philosophy, psychology, and practical ethics.


%% This is an introduction to empirical work as whole.
%% It might need to be move up
%
\nextdiv
There is a large volume of published empirical studies describing the guiding stenght that moral decision-making has on practial actions, as observable behavioural course of actions, from agents on their enviroment\fpincom{needs changes in the phrasing, and connection to the rest of the chapter. Maybe start using "guiding behaviour?}.  
%% Greene here but lacks of previous definition of Judgment and moral judgment
\nextdiv
In works such has~\cite{Greene2015, Greene2009a} Greene provides a detailed exploration of how moral decision-making operates as a practical function grounded in brain mechanisms, supported by empirical evidence and demonstrates that moral reasoning is not isolated to specific brain regions but emerges from the interplay of multiple systems tasked with value representation, cognitive control, and emotional regulation (largely discussed later on in this chapter)\fpincom{This part relates to emotional dimension of moral decision-making.}. 

\nextdiv
The authors argue that moral decision-making is \textit{inherently practical}, aimed at resolving conflicts between competing values and guiding behavior. This practicality is exemplified in dilemmas such as the trolley problem~\cite{Thomson1984}, where decisions require balancing the harm to one person against the benefit to others. Through functional magnetic resonance imaging (fMRI) studies, Greene and colleagues have shown that "personal" moral dilemmas (e.g., pushing someone off a bridge to save others) engage emotion-related areas like the amygdala and ventromedial prefrontal cortex (vmPFC). By contrast, "impersonal" dilemmas (e.g., pulling a lever) activate regions like the dorsolateral prefrontal cortex (DLPFC), associated with controlled reasoning and cost-benefit analysis.

\nextdiv
The article emphasizes that moral decision-making extends beyond theoretical principles, manifesting in observable behaviors shaped by brain function. Altruistic actions, such as donating to charity\fpincom{important for our case}, involve the frontostriatal pathway, which integrates social cues and rewards. Similarly, cooperative behaviors are supported by neural mechanisms that encode trust and reciprocity, demonstrating how moral reasoning translates into real-world practices.

Pharmacological studies also provide practical insights. For instance, increased serotonin levels, which amplify emotional reactivity, enhance deontological judgments, while decreased emotional engagement promotes utilitarian reasoning. These findings underscore the brain’s adaptability in modulating moral behavior based on biological and environmental factors.The neuroscientific evidence supports the view that moral decision-making is not only about abstract reasoning but also deeply embedded in the practical, embodied realities of human life.


\nextdiv
Hence, moral decision making encompasses both 

\begin{itemize}
	\setlength{\itemsep}{0pt}
	\rightskip1.5cm
	\leftskip1cm
	\item [1)] the mental operations that guide our judgments, and 
	\item [2)] the resultant (observable) actions that embody our moral principles in the practical realm. 
\end{itemize}
	
Here we are concerned with point 2 above, \ie, the resultant \textit{observable} actions that, as such, we hypotesize being a physical traces in terms of observable, machine detectable behavioural cues of an agent's moral decision.

\nextdiv


%% But Moral Decision Making is anyway practical and this is the point we need to keep in mind
%


%% Introducing the problem
%
The perception of direct gaze, that is, of other individual gaze directed at the observer, is know to influence a wide range of cognitive processes and behaviours. 

Practical reason refers to the distinctively human capacity to determine, through reflective deliberation, the appropriate course of action in a given situation~\cite{Aristotle_nicomachean, Aquinas_summa, Kant_practical_reason}. 

\nextdiv
In this context, reflective deliberation is a cognitive function often characterised by conscious, effortful, and reason-guided evaluation of options, or courses of action. It usualy characterised in the literature as involving:

\begin{enumerate}[label=\arabic*)\,, leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	
	\item \textbf{ Philosophical Perspective:} The capacity to critically assess one's desires, beliefs, and values, often engaging in second-order thinking to evaluate not just what one wants but whether those wants align with broader principles or long-term goals. Rooted in Kantian ethics and Aristotelian practical reasoning, it emphasizes autonomy and rationality~\cite{Aristotle_nicomachean, Korsgaard1996}.
	\item \textbf{Psychological Perspective:} A metacognitive process where individuals engage in controlled, systematic thinking to weigh evidence, consider alternatives, and predict outcomes. Reflective deliberation contrasts with automatic or heuristic-driven decision-making, drawing from dual-process theories of cognition~\cite{Kahneman2011, Stanovich2000}.
\end{enumerate}


This deliberative process in practical reasoning is, indeed, \textit{practical} in two essential respects. Firstly, it pertains to the \textit{domain of action}, as its focus is on resolving questions related to what \textit{should be done}. Secondly, it is practical in its \textit{outcomes}, as the act of reflecting on matters of action inherently guides and motivates individuals toward acting~\cite{Wallace2020}.

People may act differently in public environments due to actual reputation concerns, or due to the mere presence of others. People often act differently when others are observing them, reputational concerns and signaling are widely theorized to be a driving mechanism explaining why people become more prosocial and moral when observed in public.

One of the two main objective of this work is to determine wheater the presence of social robots can affect the outcome of \textit{moral decisions} made by humans in controlled, experimental settings.


In the discourse regarding evolution of moral theories across philosophy and modern psychology, it emerges a nuanced interconnection where \textit{emotional} and \textit{rational} elements not only diverge but also integrate in explaining how agents takes moral decisions. This interconnection reveals the intricate complexities inherent in the formulation of moral models, transcending a mere dichotomy to embrace a more holistic, undefined perspective.


\begin{definition}[Emotional Model]
	Moral decision-making is an emotive process, wherein individuals navigate and choose between competing moral judgments \ie, mutually exclusive evaluations we make on what is right or wrong, good or bad. This process is driven by emotional responses and intuitions, which guide and inform our conscious and practical behaviour, often preceding and shaping cognitive deliberation.
\end{definition}

Moral decision-making represents a cognitive exercise in the calculus of ethics. Within this framework of moral calculus, contemporary and classical scholars offer a spectrum of perspectives on the central role of emotional and cognitive faculties alike that incorporates both emotional and cognitive faculties.

It is worth delineating the concept of 'moral calculus' as distinct from \textit{hedonistic calculus}. While the latter term typically refers to Benthamite utility maximization, often quantified in terms of pleasure and pain, 'moral calculus' serves as a broader framework for ethical deliberation. Unlike hedonistic calculus, which is generally rooted in consequentialist traditions, moral calculus navigates the complexities of diverse ethical systems, be they deontological, virtue-based, or others.



\nextdiv
The philosophical canon profoundly integrates the conceptual distinction between emotion-driven and reason-driven moral philosophies. This differentiation has seen considerable evolution over centuries, leading to a significant impact on contemporary psychological thinking, especially in the sphere of moral psychology. The nuanced separation of emotion-driven and reason-driven moral frameworks, deeply rooted in philosophical discourse, has evolved extensively over time, culminating in its marked influence on modern psychological studies, with a particular focus on moral psychology. This journey begins with the foundational works of ancient philosophy. In this era, thinkers like Plato in his 'Republic' delineate a clear preference for reason over emotion in guiding ethical conduct. Aristotle, in his 'Nicomachean Ethics,' echoes this sentiment to some extent by emphasizing rational virtues, yet he also acknowledges the significant role emotions play in ethical existence.

Moving forward into the Enlightenment, this conceptual distinction was further crystallized. A paradigmatic figure of this era, Immanuel Kant, championed a morality firmly rooted in reason and universal maxims in his works, such as 'Critique of Pure Reason' and 'Groundwork for the Metaphysics of Morals,' thereby relegating emotions to a subsidiary role. This period marked a significant shift toward a rationalist perspective in moral philosophy.

However, this shift was met with a counterpoint in the British empirical tradition. Figures like David Hume presented a challenge to the Kantian rationalism. In his 'A Treatise of Human Nature,' Hume provocatively posited that reason is subordinate to passions, thereby anchoring moral judgments in emotional responses. This perspective from British empiricists highlighted the importance of emotions, or 'sentiments', in moral considerations, offering a contrasting view to the prevailing rationalist approach.

Moral decision making, is a cognitive process of choosing between competing moral judgments- \ie, mutually exclusive evaluations we make on what is right or wrong, good or bad, and that we use as motive, purpose and direction for our conscious, \gls{practical_behaviour}.

Moral decision-making is primarily an emotive process, wherein individuals navigate and choose between competing moral judgments \ie, mutually exclusive evaluations we make on what is right or wrong, good or bad. This process is driven by emotional responses and intuitions, which guide and inform our conscious and practical behaviour, often preceding and shaping cognitive deliberation.




\nextdiv
Hence, in the discourse of moral calculus, certain schools of thought, notably those propounded by Haidt (2012) and Greene (2007), assert with compelling vigour that the substratum of emotional faculties, rather than those of the cognitive domain, governs the architecture of ethical decision-making. This viewpoint finds a harmonic resonance in the philosophical canon, corroborated by seminal treatises such as Nussbaum's 'Upheavals of Thought' (2001) and Damasio's 'Descartes' Error' (1994).

\nextdiv
The theoretical edifice of moral calculus, while intellectually robust, gains tangible relevance when juxtaposed with empirical and phenomenological data. Bridging these domains allows for a more encompassing understanding of moral decision-making, marrying the abstract with \textit{the} concrete, \textit{the} theoretical with \textit{the} experiential.

For the empirical aspect:

Neuroscientific research offers valuable empirical insight into the machinery of moral cognition. Studies have implicated regions like the prefrontal cortex and the amygdala in the ethical decision-making process (Greene et al., 2001; Decety \& Cacioppo, 2012). These findings suggest that our 'moral calculus' may indeed have a tangible neurological substrate, grounding ethical theory in the biological realm.

For the phenomenological aspect:

Complementing these empirical observations, phenomenological accounts provide a subjective lens through which moral decision-making can be examined. Authors such as Sartre and Merleau-Ponty have explored the existential dimensions of choice, capturing the lived experience of moral deliberation (Sartre, 1943; Merleau-Ponty, 1945). 

These works serve to enrich our understanding of 'moral calculus' by infusing it with the subjective quality of human experience.

\paragraph{Emotion-Centered Models:} Some theories argue \cite{} that emotional processes, rather than cognitive ones, are at the core of moral decision making. Your definition may not adequately capture the emotive factors often considered essential. onathan Haidt's work in "The Righteous Mind" explores the role of emotional intuition in moral judgments, arguing that reasoning often follows, rather than guides, our moral intuitions~\cite{Haidt2012}

\textit{Practical behaviour} is a term widely used across philosophy and psychology, it's challenging to create an exhaustive chronological definition because the term does not correspond to a singular theory or concept that has evolved over time in a linear fashion. Instead, it has been interpreted and applied differently depending on the context, theoretical framework, or school of thought.

\nextdiv
Practical behaviour in philosophy: has been interpreted in various ways across different philosophical schools of thought. 1) In Aristotelian philosophy, practical behaviour is associated with "praxis" or action guided by moral virtue aimed at the good life. Practical wisdom ("phronesis") is crucial here as it guides one's decisions and actions in accordance with moral virtue. 2) Immanuel Kant distinguished between theoretical reason (used to understand the natural world) and practical reason (used to govern behaviour and moral decision-making). For Kant, practical behaviour is guided by the categorical imperative, an absolute moral law. 3) In the late 19th and early 20th century, the pragmatists (like William James and John Dewey) viewed practical behaviour as action informed by the effects that such behaviour would bring about. 

\nextdiv
Practical Behaviour in Psychology has been understood as observable actions and reactions to stimuli in behaviourism, deeply intertwined with internal cognitive processes during the cognitive revolution, and as a complex interplay of cognitive processes, emotional states, individual traits, and environmental influences in contemporary psychology. 1) In the behaviourist approach (Early 20th Century) pioneered by John Watson and B.F. Skinner, practical behaviour is understood in terms of observable actions and reactions to stimuli, often studied through conditioning processes. 2) With the cognitive revolution (Mid-20th Century), practical behaviour started to be seen as deeply intertwined with internal cognitive processes like problem-solving, decision-making, and planning. 3) Social-Cognitive Theory (Late 20th Century): Albert Bandura's social-cognitive theory emphasised the role of observational learning, self-efficacy, and goal setting in practical behaviour. \textbf{Modern times}: today, in ethics and action theory, practical behaviour typically refers to behaviour guided by practical reason, that is, reason concerned with action and decision-making. This involves deliberation about means and ends, moral obligations, and the values at stake in different courses of action. Similarly in Contemporary Psychology, practical behaviour is understood as a complex interplay of cognitive processes, emotional states, individual traits, and environmental influences. It is typically studied in context-specific terms, such as health behaviour, consumer behaviour, or prosocial behaviour.


This is quite an encompassing scope, but there are inevitable aspects of the broader discourse on moral decision making that we need to include in this purview. 

---
\textbf{the following needs to be integrated in the text}
---

\textcolor{orange}{The term "practical behaviour" is a broad one, encompassing a wide range of actions that an individual might take in their everyday life. These can range from simple behaviours like brushing teeth or driving to work, to more complex ones like making a significant decision about one's career or personal life."Moral behaviour," on the other hand, is a subset of practical behaviour. It refers specifically to actions that involve moral or ethical considerations. In other words, all moral behaviours are practical behaviours, but not all practical behaviours are moral behaviours. The distinguishing feature is the presence of moral or ethical considerations in the motivations, implications, or consequences of the action. So, in response to your question, the key to understanding the difference between "practical behaviour" and "moral behaviour" does indeed lie in understanding the specific meaning and implications of "behaviour" in these contexts. However, it's also crucial to consider the specific nature and context of the action itself, including the intentions behind it and its potential consequences. the key to understanding the difference between "practical behaviour" and "moral behaviour" does indeed lie in understanding the specific meaning and implications of "behaviour" in these contexts. However, it's also crucial to consider the specific nature and context of the action itself, including the intentions behind it and its potential consequences. Moral domain: A behaviour typically falls within the moral domain when it pertains to questions of right and wrong, fairness, justice, harm, and welfare. So, for instance, deciding to donate to charity falls within the moral domain because it involves considerations about the welfare of others. Playing the piano, on the other hand, would generally fall outside the moral domain because it's largely a personal interest or skill, not directly associated with the welfare or rights of others. Intention and motive: Moral behaviour often involves a level of intentionality, where the individual acts with a specific purpose or motive that is morally charged. An individual who donates to charity with the motive of helping others is engaging in moral behaviour. In contrast, an individual who plays the piano for personal enjoyment is engaging in a practical behaviour that isn't inherently moral or immoral. Consequences: The potential or actual impact of behaviour on others also plays a crucial role in determining its moral status. Behaviours with positive or negative impacts on others are often evaluated on a moral basis. \textbf{Additional notes}: 1) \textit{Interaction of factors determining behaviour:} In both philosophy and psychology, behaviour is viewed as a result of a complex interplay of multiple factors, including cognitive processes, emotional states, individual traits, and environmental influences. 1) Cognitive processes: Cognitive processes, such as perception, memory, decision-making, and problem-solving, play a critical role in practical behaviour. For example, decision-making theories, such as the Dual Process Theory, suggest that people use both intuitive (automatic, fast, and emotional) and deliberative (slow, controlled, and logical) systems in guiding their behaviours \cite{kahneman2011}. 2) Emotional states: Emotions can also guide our behaviour. The James-Lange theory of emotion suggests that our emotional experiences are a response to our bodily reactions to a stimulus. For example, we don't run away because we're afraid; instead, we're afraid because we see ourselves running\cite{james1884}. 3) Individual traits: Personality traits influence how individuals interpret and respond to their environment. The Big Five personality traits (openness, conscientiousness, extraversion, agreeableness, and neuroticism) have been linked to various behavioural outcomes. For instance, high levels of conscientiousness have been associated with better job and academic performance\cite{costa1992}. 4) Environmental influences: Social and physical environments shape behaviour. Social Cognitive Theory emphasises the reciprocal nature of this relationship: our behaviour can both influence and be influenced by our environment. For example, observational learning suggests we learn behaviours by observing others, while self-efficacy can determine how we respond to challenges\cite{bandura1986}. Modern psychology acknowledges that many behaviours are driven by processes outside of conscious awareness. For instance, implicit bias research shows that we often harbour unconscious biases that can influence our behaviour, including decision-making and interpersonal interactions\cite{greenwald2006}.Decision-making is not always rational and is often influenced by cognitive biases. For example, the 'availability heuristic' suggests that people are more likely to consider information that's easily retrievable when making decisions, which may not always lead to accurate or optimal outcomes\cite{tversky1973}.This interdisciplinary field combines psychology and economics to understand decision-making and behaviour. For example, the concept of 'nudge theory' suggests that subtle changes in how choices are presented can significantly influence decisions and behaviour, a principle that has been applied in various domains like healthcare, finance, and public policy\cite{thaler2008}. These insights suggest that our understanding of practical behaviour needs to be multifaceted, taking into account not only conscious, deliberate processes but also unconscious influences and the way cognitive biases and heuristics shape our decisions and actions. They also underscore the importance of considering the individual within their social and environmental context}

\nextdiv 
Moral decisions theories are often analysed into components features such as the model of judgment adopted- whether factual or normative, rational of affects laden-  its causes, and the ethical outset it seems to follow. All three components happen to be useful for identifying and organise methods and work done in Computational Ethics since they are easily linked to different scientific approaches adopted in the field, and their basis deeply root into both philosophical and psychological theories which have deeply inspired and implicitly shaped the objectives set for this field in the past two decades.

In particular, most modern philosophers have frequently written about the conflict between factual and normative judgments \cite{Black1972}, between reason and emotions \cite{Haidt2001}, and between normative and motivating reasoning \cite{Gert2020} three dichotomies.

\subsection{Normative Non-Ethical agents}
A moral decision is what we \textit{judged} necessary to resolve conflicts with an explicitly moral dimension via special type of judgements which often called \textit{normative} or \textit{value judgements}: responses to stimuli with a moral dimension. Normative judgements assert or deny what \textit{ought} to be the case whether or not it is \textit{actually} the case (see figure \ref{judgments}, page \pageref{judgments}), in contrast to factual judgements which assert or deny facts that \textit{are the case} or a properly justified believe.

Factual judgements assert or deny facts that \textit{are the case} or a properly justified believe, while normative judgements assert or deny what \textit{ought} to be the case whether or not it \textit{actually} is the case.

\begin{figure}[h]
    \centering
    \scalebox{0.65}{
    \includegraphics[width=\textwidth]{img/graphs/judgments.pdf}
    }
    \caption{This distinction presuppose a sufficient prior understanding of the relevant uses of \textit{is} and \textit{ought} (or \textit{should}) which will not discuss in details here. It is important to notice that, the presence of such marks as is neither a sufficient nor necessary criterion for the distinction we make, due to the striking variability of the relevant uses of the two words in every day language. For example, the sentence 'copper should be a metal' is not intended to be normative, and 'murder is evil' is not meant to be factual. Some philosophical theories claim that moral judgements lack of some desirable properties that factual statements have such as \textit{objectivity} or \textit{truth-apt}.}
    \label{judgments}
\end{figure}

\noindent
Judgements such as 'copper is a metal' \cite{Black1972} or '$2 + 2 = 4$' express what is the case because they are \textit{truth-apt} judgements which means that they are either true or false in there being some corresponding \textit{fact} which settles the question of their truth value. In simple terms, we cannot have different opinions on '$2 + 2 = 4$' because there exists a system of mathematical principles that, if accepted, makes us committed to the believe that '$2 + 2 = 4$': there are corresponding \textit{facts} that make these locutions true or false. 

\nextdiv
On the other hand, judgements such as 'innocents ought not to be punished' \cite{Black1972} or 'wrongful killing is always wrong' are judgments about what \textit{ought} to be the case but that do not have any corresponding fact that makes it true or false. Can machines grasp the difference between the two? In contrast with other more empirical judgments, moral judgements seem to have an intrinsic connection to motivation and action, for they form in us a uniquely bonding intentions to perform a behaviour, and motivate us to act in accordance with it \cite{Rosati2016}.

\nextdiv
Moor in \cite{Moor2011} was one of the fist to examine how this distinction is relevant for a predominate class of works in Machine Ethics. Moor noticed that ordinary computers are designed with a purpose in mind, they are \textit{normative agents} in the sense that they perform something on our behalf, executing rule-based instructions of which efficacy can be assessed assessed. However, ethical agents are those that perform actions with an ethical impact (positive or negative), but not by being constrained by their designers as this would not count has ethical act by the the very same definition of Ethics.


\subsection{Other}
Hence, genuine moral decisions must have as 'end-product', actions or inactions. In The Language of Morals \cite{Hare1991}, R.M. Hare, one of the leading British moral philosopher of the twentieth century, gives this clear characterisation:

\blockquote[\cite{Hare1991}]{If we were to ask of a person "What are his moral principles?" the way in which we could be most sure of a true answer would be by studying what he did. He might, to be sure, profess in his conversation all sorts of principles, which in his actions he completely disregarded; but it would be when, knowing all the relevant facts of a situation, he was faced with choices or decisions between alternative courses of action, between alternative answers to the question "What shall I do?", that he would reveal in what principles of conduct he really believed. The reason why actions are in a peculiar way revelatory of moral principles is that the function of moral principles is to guide conduct.}

\nextdiv
By the same token, the main objective of Machine Ethics is to develop implicit ethical agents that is to say, machines that have been programmed in a way that can decide on actions with an ethical impact on their environment. Machine Ethics revolves around a precise subset of decision-type, since not all decisions have a moral dimension, and therefore not all types of judgments are relevant to morality. For example, whether I should get a frosty cold drink on a hot day using my last pound is not a moral decision. Whether I should use my last pound to get a cold drink, or give it to the women begging for money, appears to be. Both are instances of decision concerned with actions, they drive \textit{goal-oriented behaviours} in which our perceptual and memory system support decisions that determine our \textit{actions} \cite{Gazzaniga2006}.

\section{Extended Types of Judgments}

Typically, judgments are classified into two primary types: factual (descriptive or necessary) and normative (prescriptive or contingent). However, these categories, though fundamental, may not fully encompass the range of judgments humans engage with. Various disciplines, including philosophy, psychology, and mathematics, suggest other classifications or subcategories. 


While factual and normative categories provide a foundational classification of judgments, the diversity and complexity of human thought suggest the utility of additional categories. The appropriateness of any specific set of categories, however, depends on the nature of the subject matter and the research questions at hand.

\begin{enumerate}
    \item \textbf{Value Judgments:} Value judgments focus on the worth, importance, or intrinsic merit of a subject. As a subset of normative judgments, they often pertain to ethical or moral dimensions. However, their unique emphasis on 'value' might warrant a separate consideration.
    \item \textbf{Aesthetic Judgments:} Aesthetic judgments concern beauty or other aesthetic attributes. Although they might be regarded as a form of value or normative judgments, the discipline of aesthetics often treats them as a distinct category due to their specialised focus.
    \item \textbf{Prudential Judgments:} Prudential judgments, often used in economics, decision theory, and practical ethics, consider what is prudent or practically wise. These judgments typically involve an interplay of both descriptive and normative elements.
    \item \textbf{Probabilistic Judgments:} Probabilistic judgments, prevalent in statistics, psychology, and decision theory, assess the likelihood or probability of a given event or condition. They often require a balance between empirical data and theoretical models.
    \item \textbf{Counterfactual Judgments:} Counterfactual judgments, commonly used in philosophy and cognitive psychology, speculate on alternate realities or conditions. These judgments often hinge on the ability to imagine and reason about hypothetical situations.
    \item \textbf{Analytic Judgments:} In Kantian philosophy, analytic judgments are those in which the predicate concept is included within the subject concept. These judgments are typically tautological and contrast with synthetic judgments.
    \item \textbf{Synthetic Judgments:} Kant also proposed synthetic judgments, wherein the predicate concept is not contained within the subject concept. They can be classified further into a priori (based on reasoning independent of experience) and a posteriori (based on experience).
\end{enumerate}


for example, the judgments made in physics, like those in other scientific disciplines, can be seen to fall into several categories depending on the specific context. Much of the work in physics involves making \textit{descriptive (factual) judgments} about the nature of the physical world. These judgments are usually based on observation and experimentation and aim to accurately describe how the world is. While less common in physics than in other fields such as ethics, \textit{prescriptive (normative) judgments} are sometimes made in the context of methodological rules about how to do physics. Physics often involves making \textit{probabilistic judgments}. In quantum mechanics, the behaviour of particles is often described in terms of probabilities rather than definite outcomes. Physicists also frequently make \textit{counterfactual judgments}, considering what would happen under different hypothetical scenarios. The distinction between \textit{analytic and synthetic judgments} is also relevant in physics. An example of an analytic judgment in physics might be a mathematical truth that holds by definition within a certain model, while a synthetic judgment might be a statement about the physical world that is supported by empirical evidence.

 The judgments made in physics, like those in other scientific disciplines, can be seen to fall into several categories depending on the specific context. Drawing upon Chalmers' work on the philosophy of science \cite{chalmers2013}, we find that much of the work in physics involves making \textit{descriptive (factual) judgments} about the nature of the physical world. These judgments are usually based on observation and experimentation and aim to accurately describe how the world is.  While less common in physics than in other fields such as ethics, \textit{prescriptive (normative) judgments} are sometimes made in the context of methodological rules about how to do physics, a concept explored by Laudan in his work on normative naturalism \cite{laudan1987}.  Physics often involves making \textit{probabilistic judgments}. In quantum mechanics, the behaviour of particles is often described in terms of probabilities rather than definite outcomes \cite{bricmont2016}.  Physicists also frequently make \textit{counterfactual judgments}, considering what would happen under different hypothetical scenarios, a concept explored in the work of Woodward \cite{woodward2007}.  The distinction between \textit{analytic and synthetic judgments} is also relevant in physics. Drawing on Bird's exploration of Kuhn's philosophy \cite{bird2000}, we see that an example of an analytic judgment in physics might be a mathematical truth that holds by definition within a certain model, while a synthetic judgment might be a statement about the physical world that is supported by empirical evidence.   In practice, many judgments in physics may involve a combination or an interplay of these types. The specific context and objectives of the work play a large role in determining which types of judgments are most relevant.


In practice, the types of judgments made in physics often involve a mixture of these categories. For instance, a descriptive judgment about the behaviour of a particle might be based on a combination of observation (a synthetic judgment) and mathematical reasoning (often involving analytic judgments). Thus, the understanding and classification of judgments in physics, like in other fields, benefit from a nuanced approach. 

In a field such as Computer Science, a discipline that often intersects with logic, mathematics, and engineering, several types of judgments can be identified. Much of the work in computer science involves making \textit{descriptive (factual) judgments}. These often take the form of specifying the behaviour of algorithms or systems, such as a judgment about the time complexity of a particular sorting algorithm. \textit{Prescriptive (normative) judgments} are also found in computer science, often relating to best practices for coding, architectural decisions in system design, or ethical considerations in AI development. \textit{Analytic judgments}, where the predicate is contained within the subject, often emerge from logical deductions that follow from the definition of a concept or operation. \textit{Synthetic judgments}, which refer to empirical findings that don't just follow from definitions, might involve observations about the performance of certain algorithms in specific contexts. Especially in areas like machine learning and algorithm analysis, computer scientists often make \textit{probabilistic judgments}, like assessing the probability of a certain outcome given a set of inputs. In troubleshooting, system design, or in planning the development process, \textit{counterfactual judgments} often play a significant role as computer scientists consider alternate scenarios or possibilities. 

The rise of fields such as AI ethics and Human-Computer Interaction (HCI) has brought attention to \textit{value judgments} in computer science. These might concern what constitutes fair treatment in an algorithm's decision-making process, for example. In practice, many judgments in computer science may involve a combination or an interplay of these types. The specific context and objectives of the work play a large role in determining which types of judgments are most relevant.

\section{A definition of judgment}

So, what is \textit{judgment}? 

A \textit{judgment} has been defined differently across various fields. From a logical and mathematical perspective, it carries specific interpretations. In formal logic, a judgment is typically understood as an assertion that a proposition is true. This idea can be represented as follows:
\[
J(P)
\]

Here, \(J\) denotes the judgment operation and \(P\) is a proposition. The entire expression, \(J(P)\), is read as "\textit{it is judged that \(P\)}".


In mathematics, a judgment can be considered akin to a function. If we think of a judgment as mapping from a set of premises to a conclusion, we can represent it in a similar way to a function:

\[
J : P \rightarrow C
\]

Here, \(J\) is the judgment, \(P\) represents the premises, and \(C\) is the conclusion. This can be understood as a judgment \(J\) mapping a set of premises \(P\) to a conclusion \(C\). Note, however, that this is a rather abstract and non-standard interpretation. Judgments in mathematics and logic are more typically represented as statements or propositions that are asserted to be true. German logician Gottlob Frege's work in the field of logic provides valuable insight into the concept of judgment. His Begriffsschrift, or concept script, was a formal language of logic devised to represent clear, logical thoughts. In Frege's system, judgments about a proposition can be symbolically expressed and manipulated.
