\chapter{ETHICAL COGNITION AND NORMATIVE FOUNDATIONS}
\label{chap:ethics_s}

\section{From Moral Cognition to Ethical Theory}
\addcontentsline{toc}{section}{Bridging Note: From Moral Cognition to Ethical Theory}

\noindent
The preceding chapter established three claims that structure the transition to the present discussion. 

First, moral judgments were analysed as \emph{first-order evaluative outputs}: context-sensitive assessments generated by the cognitive--affective architecture through which agents register morally salient features of their environment. These judgments are psychologically real, behaviourally tractable, and empirically measurable, but they are neither required to be internally consistent nor grounded in articulated principles. 

Second, we showed that such judgments arise from distributed processes---intuitive, affective, inferential, and regulatory---whose integration is sensitive to perturbations in the social and perceptual field. 

Third, the experimental work that follows relies on this architecture: what we measure are not abstract commitments but the \emph{practical expression} of moral cognition within environments made ambiguous by synthetic presence.

\noindent
The present chapter moves from these \emph{first-order phenomena} to the \emph{second-order frameworks} through which philosophers and psychologists, attempt to explain, justify, or discipline them. Whereas moral judgments are the data of moral life, \emph{ethics} is the systematic attempt to interpret that data: to uncover the principles, norms, and justificatory structures that purport to govern moral reasoning. Ethical theory is therefore reflexive in a way that moral cognition is not. It asks not merely \emph{What do agents judge?} but:

 \emph{What should count as a reason? How are obligations justified? What is the normative architecture that makes moral claims intelligible?} 
 
These questions operate at a different Level of Abstraction, and they require a different methodological apparatus.

\noindent
Seen from this perspective, the opening claim of this chapter---that classical ethical theory treats moral judgment as the outcome of structured deliberation---is not an empirical hypothesis but a \emph{second-order commitment}. It reflects the aspiration that normative authority arises from principled reasoning: the articulation of justifiable rules, duties, or values. Yet the Morality Primer revealed a systematic tension between this normative ideal and the empirical reality of moral cognition. Human agents rarely deliberate in the manner ethical theories presuppose; instead, their judgments emerge from perceptual salience, affective valuation, heuristics of social meaning, and dynamic integration across intuitive and deliberative systems. 

\noindent
The central task of this chapter, therefore, is to reconcile these levels: to examine whether, and under what constraints, ethical theory can remain normatively meaningful while respecting the psychological mechanisms through which moral judgments actually arise. 

Computing science, especially in domains such as Machine Ethics, Social Signal Processing, and Affective Computing, faces this tension acutely. It must model behaviour that is empirically grounded yet normatively interpretable, avoiding both the error of treating first-order outputs as if they were principled ethical commitments and the converse error of designing artificial agents around abstract principles that human agents do not in practice instantiate.  

\noindent
This dual demand---empirical fidelity and normative coherence---is the point of departure for what follows.


\section{Introduction: Why Ethics Needs Psychology (and Why Computing Science Needs Both)}

\noindent
Ethical theory, in its classical formulation, treats moral judgment as the outcome of structured deliberation: a process mediated by reasons, principles, and the articulation of normatively defensible positions. Yet this picture has long been recognised as descriptively incomplete. Human moral behaviour rarely emerges from extended reflection; rather, it unfolds through rapid, affectively mediated evaluations shaped by perception, context, and embodied interaction (see discussion in Chapter~\ref{chap:moral_primer}). The distance between what people \emph{ought} to do, what they \emph{think} they do, and what they \emph{actually} do is substantial. To understand moral action in practice—particularly in technologically saturated environments—ethical inquiry must therefore be coupled with the empirical machinery of moral psychology.

%%%

\noindent
For computing science, this coupling is not optional. Artificial agents are increasingly situated in social contexts where their presence, form, and behaviour modulate human inference, expectation, and decision-making. Fields such as \emph{Social Signal Processing}~\cite{Vinciarelli2009} and \emph{Affective Computing}~\cite{Picard1997} have already demonstrated that human social cognition is deeply sensitive to subtle cues: gaze, posture, micro-expressions, spatial orientation, and embodied co-presence. These cues structure the “interaction order”~\cite{Goffman1967} within which humans interpret intention, assign agency, and evaluate normatively significant behaviour. When synthetic systems enter this order, they perturb it—not through explicit commands, but by altering the informational and affective landscape in which human cognition operates.

\noindent
This thesis proceeds from the premise that \emph{ethical behaviour cannot be understood without moral psychology}, and that \emph{moral psychology cannot be operationalised within computing science without an account of social signals and affective processes}. Moral action is not reducible to computation over explicit propositions; it is embedded in a situated cognitive ecology shaped by embodied agents, environmental cues, and rapidly deployed intuitive processes.

\noindent
The central claim developed across the thesis is that \emph{moral behaviour is systematically sensitive to the structure of the immediate perceptual–social environment}. This is not merely a theoretical commitment but the empirical hypothesis that the experimental chapter will interrogate: if moral cognition is dynamically shaped by intuitive appraisals, attentional salience, and affective resonance, then even a silent, behaviourally neutral synthetic presence can modulate the trajectory from moral perception to moral action. The results previewed later in the thesis provide convergent evidence for this claim, showing that robotic co-presence can \emph{attenuate} prosocial donation despite the presence of a strong moral cue (the Watching-Eye stimulus).

\noindent
Framed through the lens of ethical theory, the foregoing claim has deeper implications. Ethics, as understood in contemporary philosophy, is a \textit{second-order discipline}: it does not produce moral judgments, but seeks to analyse, justify, or critique them \cite{Scanlon1998, Darwall2006, Audi2015}. It examines the \emph{structure} of reasons, obligations, and values, not the psychological mechanisms that generate first-order moral appraisals. The field of Machine Ethics has historically blurred this distinction. By attempting to \textbf{engineer} “ethical agents” directly at the level of second-order principles—rule sets, deontic logics, utility functions—it tacitly presumes that moral behaviour can be derived from explicit normative propositions \cite{Moor2006, Anderson2011}. This presumption is philosophically naïve and empirically untenable. It treats ethics as if it were a generative model of behaviour, rather than a reflective framework that presupposes the very psychological capacities it seeks to evaluate. In doing so, classical Machine Ethics mistakes the normative \emph{grammar} of moral theory for the mechanistic \emph{causality} of moral cognition.

\noindent
The argument developed in this thesis directly challenges this assumption. If moral action is shaped primarily by perceptual salience, intuitive appraisal, affective resonance, and the dynamics of social attention—as the experimental results later confirm—then second-order normative structures cannot be treated as the proximate drivers of behaviour. They are interpretive and justificatory, \textit{not computationally generative}. 

This insight reframes the goal of what I call \textit{Computational Morality}: rather than embedding ethical theories into machines, we must first understand the cognitive–affective machinery that underwrites human moral responsiveness, and only then determine what ethical oversight or normative constraints are appropriate. Classical Machine Ethics inverted this order; the empirical findings of this thesis re-establish it.

\noindent
At the same time, the scope of this chapter is deliberately circumscribed. It does not attempt a comprehensive reconstruction of moral philosophy, nor does it pursue the full normative debates surrounding moral realism, contractualism, utilitarianism, or virtue theory. Such an undertaking would exceed the remit of an empirical thesis. Instead, the chapter isolates the conceptual and mechanistic structures necessary for the remainder of the work: how ethical theory relies on assumptions about moral judgment, how moral judgment is psychologically realised, and why any account of ethical behaviour in computational settings must be anchored in the empirical architecture of moral cognition. The goal is thus foundational rather than encyclopaedic: to articulate the theoretical substrate that motivates, constrains, and ultimately validates the experimental investigation that follows.

As such, the integration of ethical theory, psychological insight, and computational modelling is not merely interdisciplinary ambition—it is a methodological necessity.

\noindent
In the chapters that follow, we develop this integration along three axes. First, we introduce foundational ethical concepts—deontic, consequentialist, and virtue-theoretic—that define the normative landscape in which moral behaviour is interpreted. Second, we examine the empirical architecture of moral cognition, with emphasis on intuitionist and dual-process models~\cite{Haidt2001, Greene2001, Cushman2013} that capture the rapid, affectively-driven nature of everyday moral judgment. Third, we link these philosophical and psychological constructs to the computational disciplines that analyse social behaviour—most notably Social Signal Processing and Affective Computing—thereby establishing a unified framework for studying ethical decision-making in environments populated by artificial agents.

\noindent
This synthesis prepares the conceptual ground for the experimental investigation at the heart of this thesis. The manipulation of robotic co-presence, the use of moral primes such as the Watching Eye stimulus, and the measurement of prosocial donation are not methodological curiosities: they are principled probes into the cognitive machinery through which moral cues acquire behavioural force. By integrating ethics, psychology, and computational social science, this chapter equips the reader with the normative and conceptual tools required to understand how—and why—synthetic presence can reshape the moral topology of human decision-making.

\label{sec:test}

%%% CHUNCK 2

\section{Ethical Theory as Second-Order Analysis}
\label{sec:second_order_ethics}

\noindent
If the introductory sections of this chapter establish the transition from first-order moral cognition to second-order normative reflection, the next task is to make explicit the methodological consequences of this shift. The distinction is not merely terminological. It determines which claims are explanatory, which are justificatory, and which are subject to empirical constraint. Failure to maintain this distinction has led to recurring conceptual errors in both philosophical ethics and computational modelling~\cite{Black1972,Hare1981,Hempel1965,Floridi2008,Moor2006,FloridiSanders2004,McLaren2006,Coeckelbergh2023}. This section therefore articulates a principled account of what second-order ethical theory \emph{is}, what it \emph{explains}, and what it \emph{cannot} plausibly do.

\subsection{Ethical Reflection and the Second-Order Stance}

\noindent
First-order moral judgments arise from the cognitive--affective processes analysed in the Morality Primer. They are psychologically realised, context-sensitive, and behaviourally measurable. Their structure reflects the architecture of moral cognition: operations on perceptual salience, affective intuitions, social meaning, and regulated deliberation. These are the \emph{phenomena} that ethical theory seeks to interpret.

Second-order ethical theory is structurally different. It is reflexive rather than generative. It asks: What counts as a reason? What makes an obligation binding? What is the source of justificatory authority? These questions presuppose capacities for abstraction, generalisation, and rational evaluation that are not themselves the proximate causal mechanisms of moral behaviour~\cite{Haidt2001,Greene2001,Young2012,Kohlberg1969,Narvaez2005,Kahneman2011,Baumeister2010}. Sidgwick already insisted on this point in \emph{The Methods of Ethics}, where he distinguished between the psychology of moral sentiments and the ``\emph{method} of determining right conduct'' \cite[Book~I]{SidgwickMethods}. Lemos's treatment of epistemic justification exhibits a similar structural separation between doxastic psychology and the normative assessment of belief \cite{Lemos2020}. The parallel here is instructive: ethics stands to moral judgment as epistemology stands to belief-formation.

Seen from this perspective, second-order theory is not a set of instructions that moral agents follow in producing judgments. It is a framework for articulating the standards by which judgments are evaluated. It makes explicit the \emph{normative architecture} that is only tacitly present in first-order moral life. Its success therefore depends on conceptual clarity and justificatory coherence, not on behavioural predictiveness.

\subsection{Levels of Abstraction and the Proper Location of Ethical Explanation}

\noindent
The distinction between first-order moral cognition and second-order ethical theory can be sharpened through Floridi’s framework of \emph{Levels of Abstraction} (LoA) \cite{Floridi2008, Floridi2010}. On this account, every explanatory enterprise selects a perspective defined by its observables, its conceptual resolution, and the class of questions it is equipped to answer. Moral cognition and ethical theory do not merely operate at different LoAs—they answer \emph{different kinds of questions} and employ \emph{different explanatory primitives}.

\medskip

At the \textbf{cognitive LoA}, the relevant variables are those that govern the generation of moral judgments in real time:
\begin{itemize}
	\item perceptual salience and attentional capture,
	\item affective appraisal and embodied valuation,
	\item intuitive heuristics and rapid social inferences,
	\item controlled modulation under conflict or uncertainty,
	\item the temporal dynamics by which these processes integrate.
\end{itemize}
These are mechanistic, psychologically instantiated processes. They have causal influence on behaviour and can be perturbed by contextual or environmental changes. \emph{This is the LoA at which the experimental work of this thesis operates.}

\medskip

At the \textbf{normative LoA}, by contrast, the objects of analysis are:
\begin{itemize}
	\item principles of justification,
	\item conceptions of duty, value, and obligation,
	\item standards of admissible reasons,
	\item structural norms governing deliberation, agency, and responsibility.
\end{itemize}
These are not causal operators but \emph{interpretive} and \emph{justificatory} constructs. They evaluate, discipline, or systematise moral claims but do not themselves generate behaviour. Ethical theory is reflexive: it examines the grammar of reasons, not the mechanisms of cognition.

\medskip

\noindent
\textbf{Classical Machine Ethics collapsed these LoAs.}  
By treating principles, rules, or utility structures as if they were mechanistic generative elements, it implicitly assumed that normative constructs function like cognitive processes. This assumption is doubly mistaken:

\begin{enumerate}
	\item It attributes to normative concepts a causal role they do not possess: ethical duties do not operate like perceptual salience or affective appraisal.
	\item It ignores the empirical architecture of moral cognition, which shows that behaviour emerges from intuitive, affective, and situational dynamics long before explicit reasoning is engaged.
\end{enumerate}

From the perspective developed across this thesis, such an approach is not merely incomplete; it is methodologically incoherent. It attempts to engineer behaviour by manipulating abstractions at a LoA that is \emph{not behaviourally operative}.

\medskip

\noindent
\textbf{LoA discipline therefore becomes a philosophical and methodological necessity.}  
Explanations of behaviour must occur at the cognitive LoA; evaluations of reasons and principles must occur at the normative LoA. Neither can be reduced to the other. Crucially, however, the two LoAs are not independent: normative evaluation presupposes an underlying psychology capable of generating moral sensitivity and action, while psychological findings constrain the plausibility of normative theories.

\medskip

This interdependence is the key insight that links this chapter to the preceding Morality Primer and to the experimental chapter that follows. The Primer established that the cognitive LoA is \emph{topologically structured}: moral cognition involves the continual reshaping of an evaluative field whose gradients are determined by affective cues, attentional dynamics, and social interpretive processes. Perturbations to this field—whether by altering salience, modifying affective tone, or introducing ambiguous social presence—can shift the system’s behavioural trajectory even when normative commitments remain unchanged.

\medskip

\noindent
Seen through the LoA framework, the core question of this thesis can now be reformulated with greater precision:  
\emph{How do normative expectations, psychological mechanisms, and environmental structures jointly determine the transition from moral perception to moral action?}

\medskip

This question cannot be answered by ethical theory alone, nor by psychology in isolation. It requires a representational structure capable of linking the causal architecture of moral cognition (first-order) with the justificatory architecture of ethical evaluation (second-order). The remainder of this chapter argues that \textbf{evaluative topology}---introduced in the Morality Primer and returned to throughout the thesis---provides precisely such a bridge.

Classical Machine Ethics provides a clear illustration of the dangers of LoA confusion. A recurring methodological assumption in early systems was that normative concepts themselves—obligations, duties, utilities, or virtues—could be implemented at the computational LoA and thereby function as direct generators of behaviour. Early top-down approaches treated ethical theory as if its abstractions could be operationalised without remainder. For example, Arkin’s “ethical governor” encoded deontological constraints derived from Just War Theory as behavioural regulators \cite{Arkin2009}; Anderson and Anderson’s principlist architectures computationalised Rossian prima facie duties as decision rules \cite{Anderson2007,Anderson2011}; and logic-based approaches by Bringsjord and colleagues modelled deontic operators as executable action-selection mechanisms \cite{Bringsjord2006,Ganascia2007}. Parallel lines of work assumed that utility functions could serve as moral evaluators in consequentialist agents \cite{Abel2016,Arkin2009}, while virtue-theoretic systems attempted to reify character traits as algorithmic dispositions governing moral performance \cite{Powers2006,Thornton2013}. In all these cases, normative structures were treated as if they occupied the same LoA as the cognitive mechanisms responsible for actual moral behaviour. 

Floridi’s LoA framework clarifies why such reductions are unsustainable: normative categories belong to a reflective, second-order LoA concerned with justification, whereas computational models operate at an implementational LoA concerned with causal processes. Conflating the two not only mischaracterises the role of normative theory but also yields systems whose behavioural outputs are artefacts of representational choices rather than genuine ethical competence.

\subsection{Evaluative Topology as a Bridge Between Orders}

\noindent
The challenge, then, is not to collapse first-order cognition into second-order theory, but to articulate a structure that permits principled interaction between them without confusing their explanatory roles. \emph{Evaluative topology}, introduced in the Morality Primer (Chapter~\ref{chap:moral_primer}) and returned to throughout this thesis (see Chapter~\ref{chap:experimental_methods}), provides precisely such a structure.

%%%
Evaluative topology can be naturally situated within a long-standing tradition in computational cognitive science that conceptualises perception, valuation, and action as parts of continuous, dynamical systems rather than discrete symbolic modules. Research in moral psychology already demonstrates that moral cognition emerges from distributed interactions between perceptual salience, affective appraisal, attentional dynamics, and context-sensitive social meaning. Empirical models—from Haidt’s social intuitionism to Greene’s dual-process account—show that moral perception is shaped by multi-dimensional affective and social fields rather than rule-based computations \cite{Haidt2001,Greene2001,Young2012}. Neurocognitive analyses extend this point: Nussbaum’s and Churchland’s treatments of emotion as evaluative perception imply a graded, vector-like structure underlying moral appraisals \cite{Nussbaum2001,Churchland2011}. Likewise, work in social signal processing models interpersonal evaluation as a shifting landscape of cues that modulate behavioural trajectories in real time \cite{Pentland2007}.

Against this background, evaluative topology provides a computationally meaningful formalisation: it treats the moral landscape as a dynamic field that shapes the flow from perceptual input to action readiness. Instead of assuming that behavior results from the application of discrete maxims or utility scores, evaluative topology models moral cognition as continuous transformations across a structured state-space. This aligns with dynamical-systems approaches in cognitive science that explain action selection through attractors, gradients of salience, and field-like organisation rather than propositional inference. The topology encodes the shape of the evaluative field—the stability of certain trajectories, the resistance of others, and the way local variations in perceptual or affective input can redirect the subject toward different moral outcomes.

By locating moral appraisal within a dynamic state-space, evaluative topology offers a principled bridge between first-order moral cognition and second-order ethical theory. It is sensitive to the empirical architecture of human cognition—distributed, affectively grounded, context-responsive—while remaining compatible with the reflective, justificatory concerns of ethical theory. It thus becomes possible to characterise the points of interaction between descriptive and normative orders without reducing one to the other: normative theory shapes the global constraints and evaluative contours within which first-order processes operate, while first-order processes provide the empirical basis upon which second-order theorising must reflect.
%%%

\medskip
At its core, evaluative topology treats the moral landscape not as a set of discrete judgments or isolated principles, but as a \emph{dynamic field} whose configuration determines the pathways through which perception becomes moral action~\cite{Haidt2001,Greene2001,Churchland2011,Young2012,Nussbaum2001,Narvaez2005}
. Its explanatory primitives include:

\begin{itemize}
	\item \textbf{salience gradients}: patterns of perceptual and affective prominence,
	\item \textbf{affective attractors}: regions of the evaluative field toward which intuitive appraisal rapidly converges,
	\item \textbf{attentional pathways}: trajectories through which cognitive resources flow,
	\item \textbf{normative deformations}: structural constraints introduced by commitments, duties, or normative expectations,
	\item \textbf{social or synthetic perturbations}: distortions induced by the presence of other agents---including artificial ones.
\end{itemize}

\noindent
Unlike classical ethical theory, which specifies norms at an abstract and often idealised level~\cite{SidgwickMethods,Rawls2020,Mill1861,Korsgaard2009,Scanlon1998}
, evaluative topology is sensitive to the \emph{real-time architecture} of moral cognition. And unlike purely mechanistic models in psychology, which describe causal processes but lack normative structure, topology captures the relational, structural, and counterfactual properties of moral appraisal~\cite{Haidt2001,Greene2001,Young2012,Narvaez2005,SidgwickMethods,Scanlon1998,Korsgaard2009}
: how evaluative trajectories \emph{could} unfold under alternative configurations of salience, affect, or context.

\medskip

This topological approach thus identifies the precise level at which first-order and second-order analyses intersect. It supports the following alignment:

\begin{enumerate}
	\item \textbf{Ethical theory} identifies which evaluative configurations \emph{ought} to have normative authority.
	\item \textbf{Moral psychology} identifies which configurations \emph{do} govern actual behaviour.
	\item \textbf{Evaluative topology} identifies how these structures interact, when they diverge, and how they can be perturbed.
\end{enumerate}

\noindent
This tripartite structure yields both a diagnostic and a constructive insight. Diagnostically, it clarifies why many classical models in Machine Ethics failed: they attempted to engineer behaviour by manipulating abstractions at a normative LoA, ignoring the topological organisation of the cognitive LoA through which behaviour actually emerges. Constructively, it shows how normative analysis can be anchored in a psychologically realistic substrate without reducing ethics to psychology or cognition to normativity.

\medskip

\paragraph{Topological Consequences for Moral Perturbation.}
The Morality Primer established that moral behaviour emerges from the traversal of a dynamically shaped evaluative field. Within this framework, \emph{perturbation} has a precise and measurable meaning: any alteration that changes the curvature, gradients, or attractor structure of the field will shift the probability distribution over behavioural trajectories. This is true whether the perturbation arises from shifts in salience, affective modulation, attentional competition, or the introduction of a new agent into the interaction ecology.

A synthetic presence---perceptually social yet ontologically indeterminate---is therefore not merely an “observer” but a topological operator. It changes the field in which moral meaning becomes behaviourally operative. This was the central theoretical insight that shaped the experimental design: by embedding a morally charged cue (the Watching-Eye stimulus) within a field perturbed by a humanoid robot, we could test whether subtle topological deformation is sufficient to attenuate prosocial behaviour.

\medskip

\paragraph{Interim Synthesis: Where the Chapter Now Stands.}
The conceptual architecture developed thus far establishes the conditions for experimental design (Chapter~\ref{chap:experimental_methods}):

\begin{itemize}
	\item First, moral judgment operates at the cognitive LoA through dynamic, affectively responsive, socially sensitive processes.
	\item Second, ethical theory operates at the normative LoA, providing justificatory structures but not generative mechanisms.
	\item Third, evaluative topology provides the bridge between these orders by modelling the structural constraints and transformations that govern the transition from moral perception to moral action.
	\item Fourth, this bridge is indispensable for understanding how synthetic agents perturb human moral behaviour.
\end{itemize}

\noindent
We are therefore equipped to proceed. With the methodological scaffolding in place, we can now introduce the major normative theories not as abstract philosophical positions but as structured attempts to locate sources of normativity within the evaluative field. Their reconstruction in the next section is guided by the LoA discipline established above and constrained by the topological account of moral cognition developed throughout this thesis.



\section{The Normative Landscape: Structuring Ethical Theories Through LoA and Topology}
\label{sec:normative_landscape}

\noindent
With the methodological groundwork established, we can now introduce the main normative frameworks that structure the philosophical landscape. This section does not attempt a comprehensive exposition of each theory. Instead, it reconstructs them at a level appropriate to the aims of the thesis: identifying how each theory positions the source of normativity, the mode of evaluation, and the mechanism of action-guidance. This reconstruction is constrained by two methodological requirements:

\begin{enumerate}
	\item It must preserve the conceptual integrity of the theories as they appear in the philosophical literature.
	\item It must express them in a form that allows integration with the architecture of moral cognition and evaluative topology.
\end{enumerate}

The following subsections introduce this framework. In later sections, each theory is examined in depth.

\subsection{The Three Dimensions of Normative Analysis}

\noindent
Normative theories differ not merely in their prescriptions but in the \emph{structure} of normativity they posit. For analytical clarity, we distinguish three dimensions, each corresponding to a distinct aspect of evaluative topology and LoA:

\begin{enumerate}
	\item \textbf{Source of Normativity}: where justificatory authority originates.\\
	Examples include rational agency (Kant), human flourishing (Aristotle), aggregated welfare (Mill, Sidgwick), and affective sentiment (Hume).
	
	\item \textbf{Mode of Evaluation}: what aspects of action or character are morally relevant.\\
	These include maxims, consequences, virtues, motives, or relational duties.
	
	\item \textbf{Action-Guidance Mechanism}: how evaluations translate into behaviour.\\
	Mechanisms include categorical imperatives, utilitarian calculation, perceptual sensitivity to salience, or contract-based justification.
\end{enumerate}

Mapping classical theories onto these axes allows us to see how each defines a distinct \emph{evaluative topology}:
\begin{itemize}
	\item Kantian ethics imposes strict deontic invariants that constrain permissible trajectories.
	\item Consequentialism defines a gradient field over outcomes, where action follows steepest ascent.
	\item Virtue ethics defines attractors corresponding to stable dispositional patterns.
	\item Sentimentalism defines affective resonance networks that modulate evaluative flow.
	\item Contractualism defines justificatory equilibria among mutually recognisable claims.
	\item Particularism rejects fixed evaluative structures, treating topology as fully context-dependent.
\end{itemize}

\subsection{Why This Framework Matters for the Experimental Chapter}

\noindent
This structured taxonomy is not an intellectual exercise. It is the conceptual apparatus that connects ethical theory to the empirical investigation of synthetic presence. The experiment relies on three claims derived from this framework:

\begin{enumerate}
	\item Moral action depends on the topology of salience, affect, and social meaning.
	\item Synthetic presence---silent, behaviourally neutral, ontologically ambiguous---modulates this topology by perturbing social attention and perceived evaluation.
	\item Classical ethical theories must be reinterpreted in topological and cognitive terms if they are to illuminate these modulations.
\end{enumerate}

This sets the stage for the next phase of the chapter: a reconstruction of deontology, consequentialism, virtue ethics, sentimentalism, contractualism, and particularism as \emph{evaluative topologies} embedded within the psychological architecture of moral cognition.

\bigskip

\noindent
With these foundations in place, the chapter now turns to the first major normative framework: deontological ethics and the architecture of practical reason.

