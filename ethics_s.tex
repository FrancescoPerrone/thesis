\chapter{Ethical Theory in a Cognitive–Topological Framework}
\label{chap:ethics_s}
\thispagestyle{pprintTitle}

\section{From Moral Cognition to Ethical Theory}
\addcontentsline{toc}{section}{Bridging Note: From Moral Cognition to Ethical Theory}

\noindent
The preceding chapter established three claims that structure the transition to the present discussion. 

First, moral judgments were analysed as \emph{first-order evaluative outputs}: context-sensitive assessments generated by the cognitive--affective architecture through which agents register morally salient features of their environment. These judgments are psychologically real, behaviourally tractable, and empirically measurable, but they are neither required to be internally consistent nor grounded in articulated principles. 

Second, we showed that such judgments arise from distributed processes---intuitive, affective, inferential, and regulatory---whose integration is sensitive to perturbations in the social and perceptual field. 

Third, the experimental work that follows relies on this architecture: what we measure are not abstract commitments but the \emph{practical expression} of moral cognition within environments made ambiguous by synthetic presence.

\noindent
The present chapter moves from these \emph{first-order phenomena} to the \emph{second-order frameworks} through which philosophers and psychologists, attempt to explain, justify, or discipline them. Whereas moral judgments are the data of moral life, \emph{ethics} is the systematic attempt to interpret that data: to uncover the principles, norms, and justificatory structures that purport to govern moral reasoning. Ethical theory is therefore reflexive in a way that moral cognition is not. It asks not merely \emph{What do agents judge?} but:

 \emph{What should count as a reason? How are obligations justified? What is the normative architecture that makes moral claims intelligible?} 
 
These questions operate at a different Level of Abstraction, and they require a different methodological apparatus.

\noindent
Seen from this perspective, the opening claim of this chapter---that classical ethical theory treats moral judgment as the outcome of structured deliberation---is not an empirical hypothesis but a \emph{second-order commitment}. It reflects the aspiration that normative authority arises from principled reasoning: the articulation of justifiable rules, duties, or values. Yet the Morality Primer revealed a systematic tension between this normative ideal and the empirical reality of moral cognition. Human agents rarely deliberate in the manner ethical theories presuppose; instead, their judgments emerge from perceptual salience, affective valuation, heuristics of social meaning, and dynamic integration across intuitive and deliberative systems. 

\noindent
The central task of this chapter, therefore, is to reconcile these levels: to examine whether, and under what constraints, ethical theory can remain normatively meaningful while respecting the psychological mechanisms through which moral judgments actually arise. 

Computing science, especially in domains such as Machine Ethics, Social Signal Processing, and Affective Computing, faces this tension acutely. It must model behaviour that is empirically grounded yet normatively interpretable, avoiding both the error of treating first-order outputs as if they were principled ethical commitments and the converse error of designing artificial agents around abstract principles that human agents do not in practice instantiate.  

\noindent
This dual demand---empirical fidelity and normative coherence---is the point of departure for what follows.


\section{Introduction: Why Ethics Needs Psychology (and Why Computing Science Needs Both)}

\noindent
Ethical theory, in its classical formulation, treats moral judgment as the outcome of structured deliberation: a process mediated by reasons, principles, and the articulation of normatively defensible positions. Yet this picture has long been recognised as descriptively incomplete. Human moral behaviour rarely emerges from extended reflection; rather, it unfolds through rapid, affectively mediated evaluations shaped by perception, context, and embodied interaction (see discussion in Chapter~\ref{chap:moral_primer}). The distance between what people \emph{ought} to do, what they \emph{think} they do, and what they \emph{actually} do is substantial. To understand moral action in practice—particularly in technologically saturated environments—ethical inquiry must therefore be coupled with the empirical machinery of moral psychology.

%%%

\noindent
For computing science, this coupling is not optional. Artificial agents are increasingly situated in social contexts where their presence, form, and behaviour modulate human inference, expectation, and decision-making. Fields such as \emph{Social Signal Processing}~\cite{Vinciarelli2009} and \emph{Affective Computing}~\cite{Picard1997} have already demonstrated that human social cognition is deeply sensitive to subtle cues: gaze, posture, micro-expressions, spatial orientation, and embodied co-presence. These cues structure the “interaction order”~\cite{Goffman1967} within which humans interpret intention, assign agency, and evaluate normatively significant behaviour. When synthetic systems enter this order, they perturb it—not through explicit commands, but by altering the informational and affective landscape in which human cognition operates.

\noindent
This thesis proceeds from the premise that \emph{ethical behaviour cannot be understood without moral psychology}, and that \emph{moral psychology cannot be operationalised within computing science without an account of social signals and affective processes}. Moral action is not reducible to computation over explicit propositions; it is embedded in a situated cognitive ecology shaped by embodied agents, environmental cues, and rapidly deployed intuitive processes.

\noindent
The central claim developed across the thesis is that \emph{moral behaviour is systematically sensitive to the structure of the immediate perceptual–social environment}. This is not merely a theoretical commitment but the empirical hypothesis that the experimental chapter will interrogate: if moral cognition is dynamically shaped by intuitive appraisals, attentional salience, and affective resonance, then even a silent, behaviourally neutral synthetic presence can modulate the trajectory from moral perception to moral action. The results previewed later in the thesis provide convergent evidence for this claim, showing that robotic co-presence can \emph{attenuate} prosocial donation despite the presence of a strong moral cue (the Watching-Eye stimulus).

\noindent
Framed through the lens of ethical theory, the foregoing claim has deeper implications. Ethics, as understood in contemporary philosophy, is a \textit{second-order discipline}: it does not produce moral judgments, but seeks to analyse, justify, or critique them \cite{Scanlon1998, Darwall2006, Audi2015}. It examines the \emph{structure} of reasons, obligations, and values, not the psychological mechanisms that generate first-order moral appraisals. The field of Machine Ethics has historically blurred this distinction. By attempting to \textbf{engineer} “ethical agents” directly at the level of second-order principles—rule sets, deontic logics, utility functions—it tacitly presumes that moral behaviour can be derived from explicit normative propositions \cite{Moor2006, Anderson2011}. This presumption is philosophically naïve and empirically untenable. It treats ethics as if it were a generative model of behaviour, rather than a reflective framework that presupposes the very psychological capacities it seeks to evaluate. In doing so, classical Machine Ethics mistakes the normative \emph{grammar} of moral theory for the mechanistic \emph{causality} of moral cognition.

\noindent
The argument developed in this thesis directly challenges this assumption. If moral action is shaped primarily by perceptual salience, intuitive appraisal, affective resonance, and the dynamics of social attention—as the experimental results later confirm—then second-order normative structures cannot be treated as the proximate drivers of behaviour. They are interpretive and justificatory, \textit{not computationally generative}. 

This insight reframes the goal of what I call \textit{Computational Morality}: rather than embedding ethical theories into machines, we must first understand the cognitive–affective machinery that underwrites human moral responsiveness, and only then determine what ethical oversight or normative constraints are appropriate. Classical Machine Ethics inverted this order; the empirical findings of this thesis re-establish it.

\noindent
At the same time, the scope of this chapter is deliberately circumscribed. It does not attempt a comprehensive reconstruction of moral philosophy, nor does it pursue the full normative debates surrounding moral realism, contractualism, utilitarianism, or virtue theory. Such an undertaking would exceed the remit of an empirical thesis. Instead, the chapter isolates the conceptual and mechanistic structures necessary for the remainder of the work: how ethical theory relies on assumptions about moral judgment, how moral judgment is psychologically realised, and why any account of ethical behaviour in computational settings must be anchored in the empirical architecture of moral cognition. The goal is thus foundational rather than encyclopaedic: to articulate the theoretical substrate that motivates, constrains, and ultimately validates the experimental investigation that follows.

As such, the integration of ethical theory, psychological insight, and computational modelling is not merely interdisciplinary ambition—it is a methodological necessity.

\noindent
In the chapters that follow, we develop this integration along three axes. First, we introduce foundational ethical concepts—deontic, consequentialist, and virtue-theoretic—that define the normative landscape in which moral behaviour is interpreted. Second, we examine the empirical architecture of moral cognition, with emphasis on intuitionist and dual-process models~\cite{Haidt2001, Greene2001, Cushman2013} that capture the rapid, affectively-driven nature of everyday moral judgment. Third, we link these philosophical and psychological constructs to the computational disciplines that analyse social behaviour—most notably Social Signal Processing and Affective Computing—thereby establishing a unified framework for studying ethical decision-making in environments populated by artificial agents.

\noindent
This synthesis prepares the conceptual ground for the experimental investigation at the heart of this thesis. The manipulation of robotic co-presence, the use of moral primes such as the Watching Eye stimulus, and the measurement of prosocial donation are not methodological curiosities: they are principled probes into the cognitive machinery through which moral cues acquire behavioural force. By integrating ethics, psychology, and computational social science, this chapter equips the reader with the normative and conceptual tools required to understand how—and why—synthetic presence can reshape the moral topology of human decision-making.

\label{sec:test}

%%% CHUNCK 2

\section{Ethical Theory as Second-Order Analysis}
\label{sec:second_order_ethics}

\noindent
If the introductory sections of this chapter establish the transition from first-order moral cognition to second-order normative reflection, the next task is to make explicit the methodological consequences of this shift. The distinction is not merely terminological. It determines which claims are explanatory, which are justificatory, and which are subject to empirical constraint. Failure to maintain this distinction has led to recurring conceptual errors in both philosophical ethics and computational modelling~\cite{Black1972,Hare1981,Hempel1965,Floridi2008,Moor2006,FloridiSanders2004,McLaren2006,Coeckelbergh2023}. This section therefore articulates a principled account of what second-order ethical theory \emph{is}, what it \emph{explains}, and what it \emph{cannot} plausibly do.

\subsection{Ethical Reflection and the Second-Order Stance}

\noindent
First-order moral judgments arise from the cognitive--affective processes analysed in the Morality Primer. They are psychologically realised, context-sensitive, and behaviourally measurable. Their structure reflects the architecture of moral cognition: operations on perceptual salience, affective intuitions, social meaning, and regulated deliberation. These are the \emph{phenomena} that ethical theory seeks to interpret.

Second-order ethical theory is structurally different. It is reflexive rather than generative. It asks: What counts as a reason? What makes an obligation binding? What is the source of justificatory authority? These questions presuppose capacities for abstraction, generalisation, and rational evaluation that are not themselves the proximate causal mechanisms of moral behaviour~\cite{Haidt2001,Greene2001,Young2012,Kohlberg1969,Narvaez2005,Kahneman2011,Baumeister2010}. Sidgwick already insisted on this point in \emph{The Methods of Ethics}, where he distinguished between the psychology of moral sentiments and the ``\emph{method} of determining right conduct'' \cite[Book~I]{SidgwickMethods}. Lemos's treatment of epistemic justification exhibits a similar structural separation between doxastic psychology and the normative assessment of belief \cite{Lemos2020}. The parallel here is instructive: ethics stands to moral judgment as epistemology stands to belief-formation.

Seen from this perspective, second-order theory is not a set of instructions that moral agents follow in producing judgments. It is a framework for articulating the standards by which judgments are evaluated. It makes explicit the \emph{normative architecture} that is only tacitly present in first-order moral life. Its success therefore depends on conceptual clarity and justificatory coherence, not on behavioural predictiveness.

\subsection{Levels of Abstraction and the Proper Location of Ethical Explanation}

\noindent
The distinction between first-order moral cognition and second-order ethical theory can be sharpened through Floridi’s framework of \emph{Levels of Abstraction} (LoA) \cite{Floridi2008, Floridi2010}. On this account, every explanatory enterprise selects a perspective defined by its observables, its conceptual resolution, and the class of questions it is equipped to answer. Moral cognition and ethical theory do not merely operate at different LoAs—they answer \emph{different kinds of questions} and employ \emph{different explanatory primitives}.

\medskip

At the \textbf{cognitive LoA}, the relevant variables are those that govern the generation of moral judgments in real time:
\begin{itemize}
	\item perceptual salience and attentional capture,
	\item affective appraisal and embodied valuation,
	\item intuitive heuristics and rapid social inferences,
	\item controlled modulation under conflict or uncertainty,
	\item the temporal dynamics by which these processes integrate.
\end{itemize}
These are mechanistic, psychologically instantiated processes. They have causal influence on behaviour and can be perturbed by contextual or environmental changes. \emph{This is the LoA at which the experimental work of this thesis operates.}

\medskip

At the \textbf{normative LoA}, by contrast, the objects of analysis are:
\begin{itemize}
	\item principles of justification,
	\item conceptions of duty, value, and obligation,
	\item standards of admissible reasons,
	\item structural norms governing deliberation, agency, and responsibility.
\end{itemize}
These are not causal operators but \emph{interpretive} and \emph{justificatory} constructs. They evaluate, discipline, or systematise moral claims but do not themselves generate behaviour. Ethical theory is reflexive: it examines the grammar of reasons, not the mechanisms of cognition.

\medskip

\noindent
\textbf{Classical Machine Ethics collapsed these LoAs.}  
By treating principles, rules, or utility structures as if they were mechanistic generative elements, it implicitly assumed that normative constructs function like cognitive processes. This assumption is doubly mistaken:

\begin{enumerate}
	\item It attributes to normative concepts a causal role they do not possess: ethical duties do not operate like perceptual salience or affective appraisal.
	\item It ignores the empirical architecture of moral cognition, which shows that behaviour emerges from intuitive, affective, and situational dynamics long before explicit reasoning is engaged.
\end{enumerate}

From the perspective developed across this thesis, such an approach is not merely incomplete; it is methodologically incoherent. It attempts to engineer behaviour by manipulating abstractions at a LoA that is \emph{not behaviourally operative}.

\medskip

\noindent
\textbf{LoA discipline therefore becomes a philosophical and methodological necessity.}  
Explanations of behaviour must occur at the cognitive LoA; evaluations of reasons and principles must occur at the normative LoA. Neither can be reduced to the other. Crucially, however, the two LoAs are not independent: normative evaluation presupposes an underlying psychology capable of generating moral sensitivity and action, while psychological findings constrain the plausibility of normative theories.

\medskip

This interdependence is the key insight that links this chapter to the preceding Morality Primer and to the experimental chapter that follows. The Primer established that the cognitive LoA is \emph{topologically structured}: moral cognition involves the continual reshaping of an evaluative field whose gradients are determined by affective cues, attentional dynamics, and social interpretive processes. Perturbations to this field—whether by altering salience, modifying affective tone, or introducing ambiguous social presence—can shift the system’s behavioural trajectory even when normative commitments remain unchanged.

\medskip

\noindent
Seen through the LoA framework, the core question of this thesis can now be reformulated with greater precision:  
\emph{How do normative expectations, psychological mechanisms, and environmental structures jointly determine the transition from moral perception to moral action?}

\medskip

This question cannot be answered by ethical theory alone, nor by psychology in isolation. It requires a representational structure capable of linking the causal architecture of moral cognition (first-order) with the justificatory architecture of ethical evaluation (second-order). The remainder of this chapter argues that \textbf{evaluative topology}---introduced in the Morality Primer and returned to throughout the thesis---provides precisely such a bridge.

Classical Machine Ethics provides a clear illustration of the dangers of LoA confusion. A recurring methodological assumption in early systems was that normative concepts themselves—obligations, duties, utilities, or virtues—could be implemented at the computational LoA and thereby function as direct generators of behaviour. Early top-down approaches treated ethical theory as if its abstractions could be operationalised without remainder. For example, Arkin’s “ethical governor” encoded deontological constraints derived from Just War Theory as behavioural regulators \cite{Arkin2009}; Anderson and Anderson’s principlist architectures computationalised Rossian prima facie duties as decision rules \cite{Anderson2007,Anderson2011}; and logic-based approaches by Bringsjord and colleagues modelled deontic operators as executable action-selection mechanisms \cite{Bringsjord2006,Ganascia2007}. Parallel lines of work assumed that utility functions could serve as moral evaluators in consequentialist agents \cite{Abel2016,Arkin2009}, while virtue-theoretic systems attempted to reify character traits as algorithmic dispositions governing moral performance \cite{Powers2006,Thornton2013}. In all these cases, normative structures were treated as if they occupied the same LoA as the cognitive mechanisms responsible for actual moral behaviour. 

Floridi’s LoA framework clarifies why such reductions are unsustainable: normative categories belong to a reflective, second-order LoA concerned with justification, whereas computational models operate at an implementational LoA concerned with causal processes. Conflating the two not only mischaracterises the role of normative theory but also yields systems whose behavioural outputs are artefacts of representational choices rather than genuine ethical competence.

\subsection{Evaluative Topology as a Bridge Between Orders}

\noindent
The challenge, then, is not to collapse first-order cognition into second-order theory, but to articulate a structure that permits principled interaction between them without confusing their explanatory roles. \emph{Evaluative topology}, introduced in the Morality Primer (Chapter~\ref{chap:moral_primer}) and returned to throughout this thesis (see Chapter~\ref{chap:experimental_methods}), provides precisely such a structure.

%%%
Evaluative topology can be naturally situated within a long-standing tradition in computational cognitive science that conceptualises perception, valuation, and action as parts of continuous, dynamical systems rather than discrete symbolic modules. Research in moral psychology already demonstrates that moral cognition emerges from distributed interactions between perceptual salience, affective appraisal, attentional dynamics, and context-sensitive social meaning. Empirical models—from Haidt’s social intuitionism to Greene’s dual-process account—show that moral perception is shaped by multi-dimensional affective and social fields rather than rule-based computations \cite{Haidt2001,Greene2001,Young2012}. Neurocognitive analyses extend this point: Nussbaum’s and Churchland’s treatments of emotion as evaluative perception imply a graded, vector-like structure underlying moral appraisals \cite{Nussbaum2001,Churchland2011}. Likewise, work in social signal processing models interpersonal evaluation as a shifting landscape of cues that modulate behavioural trajectories in real time \cite{Pentland2007}.

Against this background, evaluative topology provides a computationally meaningful formalisation: it treats the moral landscape as a dynamic field that shapes the flow from perceptual input to action readiness. Instead of assuming that behavior results from the application of discrete maxims or utility scores, evaluative topology models moral cognition as continuous transformations across a structured state-space. This aligns with dynamical-systems approaches in cognitive science that explain action selection through attractors, gradients of salience, and field-like organisation rather than propositional inference. The topology encodes the shape of the evaluative field—the stability of certain trajectories, the resistance of others, and the way local variations in perceptual or affective input can redirect the subject toward different moral outcomes.

By locating moral appraisal within a dynamic state-space, evaluative topology offers a principled bridge between first-order moral cognition and second-order ethical theory. It is sensitive to the empirical architecture of human cognition—distributed, affectively grounded, context-responsive—while remaining compatible with the reflective, justificatory concerns of ethical theory. It thus becomes possible to characterise the points of interaction between descriptive and normative orders without reducing one to the other: normative theory shapes the global constraints and evaluative contours within which first-order processes operate, while first-order processes provide the empirical basis upon which second-order theorising must reflect.
%%%

\medskip
At its core, evaluative topology treats the moral landscape not as a set of discrete judgments or isolated principles, but as a \emph{dynamic field} whose configuration determines the pathways through which perception becomes moral action~\cite{Haidt2001,Greene2001,Churchland2011,Young2012,Nussbaum2001,Narvaez2005}
. Its explanatory primitives include:

\begin{itemize}
	\item \textbf{salience gradients}: patterns of perceptual and affective prominence,
	\item \textbf{affective attractors}: regions of the evaluative field toward which intuitive appraisal rapidly converges,
	\item \textbf{attentional pathways}: trajectories through which cognitive resources flow,
	\item \textbf{normative deformations}: structural constraints introduced by commitments, duties, or normative expectations,
	\item \textbf{social or synthetic perturbations}: distortions induced by the presence of other agents---including artificial ones.
\end{itemize}

\noindent
Unlike classical ethical theory, which specifies norms at an abstract and often idealised level~\cite{SidgwickMethods,Rawls2020,Mill1861,Korsgaard2009,Scanlon1998}
, evaluative topology is sensitive to the \emph{real-time architecture} of moral cognition. And unlike purely mechanistic models in psychology, which describe causal processes but lack normative structure, topology captures the relational, structural, and counterfactual properties of moral appraisal~\cite{Haidt2001,Greene2001,Young2012,Narvaez2005,SidgwickMethods,Scanlon1998,Korsgaard2009}
: how evaluative trajectories \emph{could} unfold under alternative configurations of salience, affect, or context.

\medskip

This topological approach thus identifies the precise level at which first-order and second-order analyses intersect. It supports the following alignment:

\begin{enumerate}
	\item \textbf{Ethical theory} identifies which evaluative configurations \emph{ought} to have normative authority.
	\item \textbf{Moral psychology} identifies which configurations \emph{do} govern actual behaviour.
	\item \textbf{Evaluative topology} identifies how these structures interact, when they diverge, and how they can be perturbed.
\end{enumerate}

\noindent
This tripartite structure yields both a diagnostic and a constructive insight. Diagnostically, it clarifies why many classical models in Machine Ethics failed: they attempted to engineer behaviour by manipulating abstractions at a normative LoA, ignoring the topological organisation of the cognitive LoA through which behaviour actually emerges. Constructively, it shows how normative analysis can be anchored in a psychologically realistic substrate without reducing ethics to psychology or cognition to normativity.

\medskip

\paragraph{Topological Consequences for Moral Perturbation.}
The Morality Primer established that moral behaviour emerges from the traversal of a dynamically shaped evaluative field. Within this framework, \emph{perturbation} has a precise and measurable meaning: any alteration that changes the curvature, gradients, or attractor structure of the field will shift the probability distribution over behavioural trajectories. This is true whether the perturbation arises from shifts in salience, affective modulation, attentional competition, or the introduction of a new agent into the interaction ecology.

A synthetic presence---perceptually social yet ontologically indeterminate---is therefore not merely an “observer” but a topological operator. It changes the field in which moral meaning becomes behaviourally operative. This was the central theoretical insight that shaped the experimental design: by embedding a morally charged cue (the Watching-Eye stimulus) within a field perturbed by a humanoid robot, we could test whether subtle topological deformation is sufficient to attenuate prosocial behaviour.

\medskip

\paragraph{Interim Synthesis: Where the Chapter Now Stands.}
The conceptual architecture developed thus far establishes the conditions for experimental design (Chapter~\ref{chap:experimental_methods}):

\begin{itemize}
	\item First, moral judgment operates at the cognitive LoA through dynamic, affectively responsive, socially sensitive processes.
	\item Second, ethical theory operates at the normative LoA, providing justificatory structures but not generative mechanisms.
	\item Third, evaluative topology provides the bridge between these orders by modelling the structural constraints and transformations that govern the transition from moral perception to moral action.
	\item Fourth, this bridge is indispensable for understanding how synthetic agents perturb human moral behaviour.
\end{itemize}

\noindent
We are therefore equipped to proceed. With the methodological scaffolding in place, we can now introduce the major normative theories not as abstract philosophical positions but as structured attempts to locate sources of normativity within the evaluative field. Their reconstruction in the next section is guided by the LoA discipline established above and constrained by the topological account of moral cognition developed throughout this thesis.

\noindent
Before turning to the main normative traditions, it is important to clarify \emph{why} this reconstruction is required within the architecture of the thesis. The experimental work developed later does not simply measure behavioural differences; it interrogates a deeper question concerning the \emph{normative interpretation} of those differences. If robotic co-presence reshapes the evaluative topology through which moral salience becomes action, then any claim about the ethical significance of this perturbation---whether it constitutes a moral cost, a distortion, or a benign behavioural shift---presupposes a framework for understanding how normativity itself is structured. Without situating the experiment within a landscape of ethical theories, one could describe \emph{what} changes but not \emph{what the change means}. 

\noindent
The purpose of the next section, therefore, is not to provide a survey of moral philosophy, but to identify the minimal normative scaffolding required to make sense of the empirical findings. Deontic, consequentialist, and virtue-theoretic perspectives articulate distinct accounts of (i) where normative authority resides, (ii) how moral relevance is determined, and (iii) how action-guidance is understood. These differences matter directly for the thesis: each theory yields a different interpretation of what it means for synthetic presence to attenuate prosocial behaviour. By reconstructing these normative architectures through the lens of Levels of Abstraction and evaluative topology, we prepare the conceptual ground for assessing the ethical significance of the perturbation demonstrated experimentally.

\noindent
What follows, then, is not philosophical ornamentation but a methodological necessity: establishing the normative coordinates that will allow the later empirical results to be interpreted, evaluated, and ultimately situated within a defensible ethical framework.



\section{The Normative Landscape: Structuring Ethical Theories Through LoA and Topology}
\label{sec:normative_landscape}

\noindent
With the methodological scaffolding now in place, we can introduce the major normative frameworks that constitute the philosophical backdrop against which the experimental findings must ultimately be interpreted. The aim here is not encyclopaedic exposition but conceptual reconstruction: each theory is presented in a form that preserves its philosophical integrity while situating it within the Levels of Abstraction (LoA) discipline and the evaluative-topological architecture developed in this thesis.

\noindent
This reconstruction is guided by two methodological constraints:

\begin{enumerate}
	\item \textbf{Philosophical fidelity}: the theories must be represented in a manner faithful to their canonical formulations in moral philosophy.
	\item \textbf{Integrative compatibility}: the theories must be articulated in a form that allows principled interaction with the psychological and topological models of moral cognition established in Chapter~\ref{chap:moral_primer}.
\end{enumerate}

\noindent
The purpose of this section, therefore, is not to catalogue doctrines, but to map the deep structure of normativity in a way that can later illuminate the ethical significance of the empirical perturbations induced by synthetic presence.

\subsection{The Three Dimensions of Normative Analysis}

\noindent
Normative theories differ not only in content, but in the \emph{architecture of normativity} they assume. To analyse them systematically, we distinguish three fundamental dimensions—each corresponding to an aspect of evaluative topology and LoA structure:

\begin{enumerate}
	\item \textbf{Source of Normativity}:
	the origin of justificatory authority. This may lie in rational agency (Kant), human flourishing (Aristotle), aggregated welfare (Mill, Sidgwick), affective sentiment (Hume), or interpersonal justification (Scanlon).
	
	\item \textbf{Mode of Evaluation}:
	the features of action or character deemed morally relevant—maxims, consequences, virtues, motives, relational duties, or context-sensitive particulars.
	
	\item \textbf{Action-Guidance Mechanism}:
	the process that connects evaluative judgments to behaviour—categorical imperatives, utilitarian optimisation, virtue-structured perception, affective resonance, or justificatory equilibrium.
\end{enumerate}

\noindent
These dimensions allow us to re-express classical theories as \emph{evaluative topologies}:

\begin{itemize}
	\item \textbf{Kantian ethics} imposes rigid deontic invariants: absolute constraints that carve the evaluative field into sharply bounded permissible and impermissible regions.
	\item \textbf{Consequentialism} defines a gradient field over outcomes: moral action follows the steepest ascent toward welfare-maximising states.
	\item \textbf{Virtue ethics} defines dispositional attractors: stable patterns of moral sensitivity that shape the agent’s perceptual and evaluative orientation.
	\item \textbf{Sentimentalism} defines networks of affective resonance: moral evaluation flows along affectively weighted pathways anchored in human sympathy or aversion.
	\item \textbf{Contractualism} defines justificatory equilibria: a topology structured by mutual recognisability of claims.
	\item \textbf{Particularism} dissolves fixed topologies altogether: normativity emerges from fully context-dependent patterns of salience and relation.
\end{itemize}

\noindent
This analytic framing is essential because it provides a common representational language in which ethical theory and moral psychology can be jointly expressed. Theories that differ profoundly in content can be compared in structural terms—how they sculpt the evaluative landscape, where they locate normative constraints, and how they understand the movement from judgment to action.

\subsection{Why This Framework Matters for the Experimental Chapter}

\noindent
This normative topology is not abstract machinery; it is the conceptual infrastructure that enables us to interpret what the experiment later reveals. The empirical question—whether synthetic presence attenuates prosocial behaviour—cannot be ethically assessed without first situating it within a framework for understanding how moral cues acquire force.

\noindent
Three claims follow directly from the preceding reconstruction:

\begin{enumerate}
	\item \textbf{Moral action depends on the configuration of the evaluative field.}  
	Normative theories specify different sources of authority and diverse mechanisms of action-guidance, but all agree that moral behaviour arises from structured evaluative relations, not arbitrary choice.
	
	\item \textbf{Synthetic presence modulates this field by perturbing salience, attention, and affective resonance.}  
	A humanoid robot does not supply new reasons; it reshapes the environment in which reasons become behaviourally operative.
	
	\item \textbf{Normative theories must therefore be reinterpreted through the joint lens of LoA and evaluative topology if they are to explain or critique the behavioural perturbations observed experimentally.}
\end{enumerate}

\noindent
This is the philosophical function of the section: to establish the normative coordinates that will allow the experimental findings to be understood not merely as statistical differences, but as shifts in the moral significance of an action within a structured evaluative landscape.

\noindent
The stage is now set for the substantive reconstruction. In the following sections, each major normative framework—deontological, consequentialist, virtue-theoretic, sentimentalist, contractualist, and particularist—is examined as a topology of normativity embedded within the cognitive–affective architecture of moral agents. These reconstructions will serve as the interpretive foundation for evaluating how, and why, synthetic presence can reshape the moral field in the experiment to come.

%%% Terza porzione di contenuto da Lecce

\section{Deontological Structures: The Architecture of Practical Reason}
\label{sec:deontology}

\noindent
The methodological framework established in the preceding sections motivates a disciplined reconstruction of the major normative theories. Having clarified how ethical explanation must respect both Levels of Abstraction (LoA) and the evaluative topology that mediates the transition from perception to action, we begin with deontological ethics. This is not because deontology offers a direct model of human moral cognition—it does not—but because it illustrates, with exceptional clarity, the gap between \emph{normative authority} and \emph{psychological generation}. This gap is precisely where classical Machine Ethics collapsed distinctions, and where the present thesis departs from that monolithic approach.

\noindent
The aim here is not historical exegesis. The task is to reconstruct deontological normativity in a form compatible with the cognitive–topological architecture developed so far, and to show how deontological invariants function as structural constraints within the evaluative field investigated empirically in later chapters.

\noindent
The reconstruction must satisfy three constraints:

\begin{enumerate}
	\item \textbf{Preserve philosophical identity}: retain the core commitments that distinguish deontological ethics.
	\item \textbf{Avoid LoA confusion}: do not treat deontic principles as if they were psychological mechanisms or generative cognitive operators.
	\item \textbf{Embed deontology in topology}: express duties as constraints on the evaluative landscape, rather than as engines of behaviour.
\end{enumerate}

\noindent
When formulated in this way, deontology occupies a precise role: it identifies \emph{invariant structures} within the moral field that delimit the boundaries of permissible action. These invariants are not computational rules; they are reflective standards through which agents assess the coherence of their maxims and commitments.

\subsection{The Source of Normativity: Rational Agency and the Form of Law}

\noindent
On the Kantian account, moral authority arises from the structure of rational agency. The categorical imperative does not prescribe concrete actions but establishes a formal test for the permissibility of maxims: whether one’s maxim could be willed as a universal law \cite{Kant1785,Korsgaard2009,Allison2011}. This places the source of normativity at a \emph{higher} LoA than psychological description. It concerns the \emph{conditions of reflective justification}, not the causal mechanisms that generate everyday judgments.

\noindent
This distinction is essential. Classical Machine Ethics implemented the categorical imperative as a procedural decision rule—an algorithmic operator~\cite{Anderson2007,Anderson2011,Bringsjord2006,Govindarajulu2017,Ganascia2007,Arkin2009}
. But Kant never intended universalisability tests to function as cognitive processes.\footnote{See the discussion in \cite{Allison2011} and \cite{Korsgaard1996} on the reflective rather than psychological status of the categorical imperative.} Their purpose is normative: to articulate the standards under which a maxim can be defended as consistent with rational agency. Treating these tests as computational procedures constitutes precisely the LoA confusion diagnosed earlier.


A survey of Classical Machine Ethics reveals this recurring methodological error: the assumption that Kantian constraints, universalisability tests, or duty-based norms could be directly implemented as procedural decision rules. Early top-down approaches explicitly treated the categorical imperative, or close deontological analogues, as algorithmic operators determining action permissibility. The most widely cited examples are the principlist architectures developed by Anderson and Anderson, where prima facie duties are computationalised as weighted decision procedures whose outputs determine ethically “permissible” behaviour \cite{Anderson2007,Anderson2011}. Similarly, logic-based systems developed by Bringsjord and collaborators represent obligations and prohibitions using deontic logic embedded in the cognitive event calculus, thereby converting normative constraints into executable operators that mechanically evaluate action options \cite{Bringsjord2006,Govindarajulu2017}. Ganascia’s formalisation of ethical rules of warfare follows the same strategy, modelling universally applicable duties as logical conditions that an autonomous agent must satisfy prior to acting \cite{Ganascia2007}. Arkin’s “ethical governor” for lethal autonomous robots likewise encodes deontological constraints—derived from Just War Theory and Kantian doctrine—as computational filters that block impermissible actions at run time \cite{Arkin2009}. In each case, a normative principle originally intended for reflective justification is treated as a psychological mechanism or behaviour-generating operator. As Moor and Coeckelbergh observe, this amounts precisely to the Level-of-Abstraction confusion: normative tests designed for rational self-assessment are misinterpreted as causal algorithms capable of producing moral behaviour \cite{Moor2023,Coeckelbergh2023}. These systems thus instantiate the very conflation at issue—collapsing reflective ethical reasoning into first-order cognitive processing.


\subsection{Mode of Evaluation: Maxims, Duties, and the Structure of Permissibility}

\noindent
Deontological theories evaluate actions through the \emph{form} of the underlying maxim and the duties that follow from rational consistency. These duties generate a characteristic structure within the evaluative field:

\begin{itemize}
	\item \textbf{Invariance}: duties bind independently of consequences or affective states.
	\item \textbf{Non-gradience}: obligations typically define discrete boundaries—permissible vs.\ impermissible.
	\item \textbf{Symmetry}: the universal law test imposes interpersonal consistency.
	\item \textbf{Role-relativity}: some duties depend on one’s position or relationship (e.g.\ duties of fidelity, respect, and beneficence).
\end{itemize}

\noindent
Topologically, these features correspond to \emph{hard constraints} on the evaluative landscape. Rather than shaping the gradients that guide behaviour, deontological duties carve the field into admissible and inadmissible regions. They define the regulatory geometry within which trajectories must lie.

\subsection{Action-Guidance: How Normative Constraints Influence Behaviour}

\noindent
A central challenge arises here: if deontological rules do not describe cognitive processes, how do they guide action?

\noindent
The answer, consistent with LoA discipline, is twofold:

\begin{enumerate}
	\item \textbf{At the cognitive LoA}: deontological principles do not produce behaviour. Moral action emerges from intuitive appraisal, affective valuation, attentional salience, and controlled modulation—precisely the components analysed in the Morality Primer (Chapter \ref{chap:moral_primer}).
	
	\item \textbf{At the normative LoA}: deontological principles determine which behavioural trajectories can be reflectively justified. They also shape long-term dispositions, thereby influencing the evaluative topology indirectly through moral training, socialisation, and self-constitution.
\end{enumerate}

\noindent
Thus, while deontology does not operate the machinery of moral cognition, it contributes to the \emph{calibration} of that machinery over developmental time. Internalised deontic commitments:

\begin{itemize}
	\item heighten sensitivity to cues of respect and violation,
	\item modulate affective responses to dishonesty or unfairness,
	\item strengthen top–down control when intuitive impulses conflict with duty.
\end{itemize}

\noindent
In this sense, deontological ethics functions as a form of \emph{normative scaffolding}: it shapes the agent’s evaluative posture but does not compute their moment-to-moment behaviour.

\subsection{Deontological Normativity as Topological Invariance}

\noindent
We can now state the central insight of this reconstruction. Within a topological model of moral cognition, deontological ethics corresponds to the identification of \emph{non-negotiable invariants}—fixed points that define the structural integrity of the moral field.

\noindent
These invariants:

\begin{itemize}
	\item partition the space of possible actions into permitted and forbidden zones,
	\item resist deformation by contextual changes, affective fluctuations, or strategic incentives,
	\item stabilise behavioural tendencies by constraining rational endorsement,
	\item provide the reflective standpoint from which agents assess the legitimacy of their conduct.
\end{itemize}

\noindent
The categorical imperative thus appears not as an algorithm for decision-making but as a \emph{topological principle}: a formal constraint ensuring that evaluative structure is globally coherent rather than locally opportunistic.

\subsection{Why Deontology Matters for the Experimental Logic}

\noindent
This reconstruction is essential for integrating the experiment into a normative framework. The purpose of the experiment is not merely to detect behavioural differences but to determine their \emph{moral} significance. Deontology supplies the conceptual structure required for this evaluation.

\noindent
Before stating the relevance of deontological norms for the experimental logic, one brief clarification is required. Throughout this thesis, the experimental paradigm employs a widely studied behavioural prime sometimes referred to as a “Watching-Eye” cue: a minimal visual stimulus (in our case, a charity poster depicting a child in need) that subtly increases the perceived presence of a moral or social observer. The detailed psychological literature and methodological justification for this paradigm are presented later in Chapter~\ref{chap:experimental_methods}. Here, it suffices to note that such cues are known to activate expectations of accountability, reciprocity, and norm compliance—even though they involve no real observer and no explicit instruction.

\noindent
With this context in place, we can now express why deontological theory is indispensable for interpreting the experiment:

\begin{enumerate}
	\item \textbf{If synthetic presence alters behaviour}, we must ask whether the observed perturbation reflects a shift that remains within deontically permissible space or whether it involves a deeper distortion of obligations associated with beneficence, fairness, or respect.
	
	\item \textbf{The Watching-Eye cue implicitly invokes deontic expectations}: even a minimal representation of an observing other tends to activate norms of accountability and reciprocity. A reduction in prosocial action under this cue suggests that the presence of a synthetic agent may interfere with the agent’s sensitivity to these deontic constraints.
	
	\item \textbf{Deontology provides the normative vocabulary} for diagnosing whether a behavioural shift constitutes a morally relevant deviation or a benign modulation of preference or affect.
\end{enumerate}


\noindent
This is precisely where the present thesis diverges from monolithic approaches in Machine Ethics. Classical frameworks attempted to model moral action by encoding deontological rules directly into artificial agents. The empirical results of this thesis show why that strategy misunderstands the architecture of moral cognition: deontic rules do not generate behaviour, and perturbations to behaviour cannot be understood purely in terms of deviations from codified principles. Instead, the influence of synthetic presence must be interpreted through the evaluative topology in which deontic invariants reside.

\medskip

\noindent
With deontology reconstructed as a system of topological constraints rather than computational rules, we can now turn to consequentialism. There, normativity is expressed not through invariants but through gradient fields over outcomes—structures that interact with the evaluative machinery of moral cognition in different but equally illuminating ways. This will further clarify how different theoretical lenses illuminate different dimensions of the behavioural perturbations uncovered in the experiment.

%% Recommended insertion: directly after the first paragraph of Section~\ref{sec:consequentialism},
%% before introducing the Source of Normativity subsection.
%% See detailed placement advice after the block.

\subsection*{Conceptual Note: Gradient Fields in Consequentialist Topology}

\noindent
In the topological framework developed across this thesis, a \emph{gradient field} designates a structured evaluative landscape in which each possible action or state of the world is associated with a scalar value—typically representing expected welfare, utility, or outcome-based moral worth. Formally, a gradient field assigns to each point in an abstract space of action–outcome configurations a direction of steepest ascent: the direction in which an incremental shift would produce the greatest increase in expected value. In classical moral philosophy, this structure is implicit in utilitarian reasoning, which assesses actions by their tendency to promote the greatest balance of good over bad consequences \cite{Bentham1789,Mill1861,SidgwickMethods}. Within this thesis, the notion is used in a non-formal but conceptually rigorous sense: as a way of modelling how consequentialist evaluation imposes directional structure on the moral field, where moral improvement corresponds to movement along the gradient toward higher expected welfare.

\noindent
A gradient field thus has three key features:

\begin{enumerate}
	\item \textbf{Scalar valuation}: each point in the evaluative space has a determinable value, allowing continuous comparison along a single dimension of moral assessment (e.g.\ total or average welfare).
	
	\item \textbf{Directional guidance}: the moral significance of a possible action is given by its vector orientation relative to the gradient; actions are increasingly morally preferable as they align with the direction of steepest ascent.
	
	\item \textbf{Sensitivity to empirical structure}: because the gradient depends on expected outcomes, it varies with changes in belief, evidence, context, and the agent’s model of the world.
\end{enumerate}

\noindent
In this topological reconstruction, consequentialist gradient fields do not function as cognitive mechanisms. Human agents do not compute explicit gradients when acting morally, nor do they evaluate global states of the world through analytic integration. Rather, consequentialist structures operate at the \emph{normative Level of Abstraction}: they specify how actions are \emph{justified} in reflective evaluation, not how they are generated in real-time cognition. This LoA separation parallels Sidgwick’s distinction between the ``point of view of the universe'' and ordinary motivational psychology \cite[Book~IV]{SidgwickMethods}.

\medskip

\noindent
\textbf{Interaction with the Evaluative Machinery of Moral Cognition.}  
Although gradient fields do not describe the causal architecture of moral cognition, they interact with it in conceptually important ways. The evaluative machinery developed in Chapter~\ref{chap:moral_primer}—perceptual salience, affective appraisal, intuitive heuristics, and controlled modulation—does not implement consequentialist reasoning, but it is nevertheless shaped by outcome-related information in several distinct modes:

\begin{enumerate}
	\item \textbf{Salience modulation}.  
	Perceived consequences influence which features of a situation become salient. Potential harm, benefit, or risk amplifies attentional capture, thereby altering the local configuration of the evaluative field even before explicit reasoning occurs.
	
	\item \textbf{Affective valuation}.  
	The human affective system registers outcomes (especially those involving harm or welfare) with strong valence. These affective signals act as local gradient approximations: they bias intuitive appraisal toward or away from particular actions in a manner that roughly tracks expected value.
	
	\item \textbf{Heuristic extraction}.  
	Over developmental time, agents internalise outcome-sensitive heuristics ("help when it is easy", "avoid causing harm") that serve as psychologically tractable proxies for gradient following. These heuristics allow the cognitive system to approximate consequentialist structure without computing it.
	
	\item \textbf{Deliberative correction}.  
	In cases of conflict or ambiguity, controlled processes may approximate aspects of consequentialist evaluation—comparing potential harms or weighing benefits—thereby engaging the gradient field at a coarse-grained level. However, this is slow, effortful, and limited by computational constraints.
	
	\item \textbf{Perturbation sensitivity}.  
	Because consequentialist evaluation depends on expected consequences, perturbations to perception, attention, or social meaning—such as the presence of a humanoid robot—can reshape the agent’s perceived gradient field. This makes consequentialist structures especially sensitive to the kinds of environmental shifts tested experimentally in this thesis.
\end{enumerate}

\noindent
The interaction between consequentialist topology and moral cognition therefore occurs \emph{indirectly}. Consequentialism specifies the normative gradient that ought to guide reflective endorsement; the cognitive system provides a noisy, heuristic, context-sensitive approximation of this structure. Evaluative topology makes this relationship explicit by modelling behaviour as the traversal of a dynamically shaped field whose gradients, although not explicitly computed by the agent, are nevertheless partially approximated through affective and attentional processes.

\medskip

\noindent
This conceptual integration is essential for the purposes of the present thesis. It allows consequentialism to be reconstructed in a form compatible with the empirical findings that moral behaviour is sensitive to subtle perturbations in the perceptual–social environment. It also provides one of the normative lenses through which the experimentally observed attenuation of prosocial donation under synthetic presence can be interpreted: as a topological distortion of the gradient field that normally favours prosocial action.


%%% Parte 4 da Lecce

\section{Consequentialist Structures: Value Gradients and the Topology of Outcomes}
\label{sec:consequentialism}

\noindent
Having reconstructed deontological ethics as a system of topological invariants that constrain the space of permissible action without directly generating behaviour, we now turn to the second major normative framework: consequentialism. Here the conceptual architecture differs in every relevant dimension. Where deontology posits \emph{fixed boundaries} within the evaluative field, consequentialism posits \emph{gradients}. Where deontology locates normativity in the form of maxims, consequentialism locates it in the structure of outcomes. And where deontology articulates duties, consequentialism articulates value-based trajectories across possible states of the world.

\noindent
As with deontology, the aim is not historical exegesis. Rather, the task is to reconstruct consequentialism in a way compatible with the LoA discipline and the evaluative–topological model developed so far. In particular, we are interested in how a consequentialist structure can be read as a \emph{gradient field} over outcomes that exerts normative pressure on action, and how such a field is liable to perturbation when the perceptual–social environment is modified by synthetic presence. This reconstruction will furnish one of the normative perspectives through which the experimental findings on moral displacement are interpreted.

\subsection{The Source of Normativity: Welfare, Impartiality, and the Structure of Reasons}

\noindent
Classical utilitarianism grounds moral authority in the promotion of welfare. In its canonical formulations---Bentham’s felicific calculus \cite{Bentham1789}, Mill’s qualitative hedonism \cite{Mill1861}, and Sidgwick’s systematic treatment of practical reason \cite{SidgwickMethods}---consequentialism maintains that what ultimately matters is the value of outcomes, impartially aggregated across persons. An action is right, in the strict sense, insofar as it maximises (or sufficiently promotes) overall good; wrong insofar as it fails to do so.

\noindent
From the standpoint of Levels of Abstraction, this locates consequentialist normativity at a \emph{reflective} LoA concerned with:

\begin{itemize}
	\item the evaluation and comparison of outcomes,
	\item the aggregation of welfare across individuals,
	\item and the impartial justification of action in light of such aggregation.
\end{itemize}

\noindent
As with deontology, these commitments are not descriptive claims about the mechanisms of moral cognition. Sidgwick is explicit that the “point of view of the universe” is \emph{not} the standpoint from which ordinary agents habitually deliberate; it is a standard of justification, not a psychological model of motivation \cite[Book~IV]{SidgwickMethods}. Consequentialism specifies a standard of rightness, not an algorithm that human agents actually implement.

\noindent
This distinction is crucial for our purposes. Classical Machine Ethics has often treated utilitarian or outcome-based formalisms as if they were \emph{psychologically generative}: reward functions, expected-utility maximisation, or cost–benefit optimisers are proposed not merely as normative ideals but as surrogates for moral cognition itself. Within the LoA framework, this is a category error. Consequentialism operates at the normative LoA; the evaluative machinery described in the Morality Primer (Chapter~\ref{chap:moral_primer}) operates at the cognitive LoA. Any mapping between the two must be justified rather than assumed.



\subsection{Mode of Evaluation: Consequences, Expected Value, and Scalar Normativity}

\noindent
Consequentialism evaluates actions in terms of the value of their (actual or expected) outcomes. Unlike deontological theories, which typically yield binary constraints (permissible/impermissible), consequentialism is \emph{scalar}: options can be better or worse to any degree. This scalar structure has direct topological expression.

\noindent
In the evaluative-topological model, a consequentialist landscape is characterised by:

\begin{itemize}
	\item \textbf{Gradience}: the moral field is continuous; small differences in expected welfare correspond to small differences in moral ranking.
	\item \textbf{Optimisation}: morally preferable actions correspond to local or global maxima along welfare gradients.
	\item \textbf{Context-sensitivity}: the shape of the field depends on empirical facts about consequences (who is helped, who is harmed, how much, under what conditions).
	\item \textbf{Impartiality}: regions of the field corresponding to welfare changes have equal moral standing irrespective of whose welfare is at stake.
\end{itemize}

\noindent
Because of these features, consequentialism lends itself naturally to computational representation: utility functions, cost–benefit analyses, and optimisation routines approximate the mathematical structure of value gradients. This explains its appeal in Machine Ethics and reinforcement-learning–based approaches, where “ethical” behaviour is often equated with maximising a suitably designed reward function.

\noindent
But again, computational tractability must not be confused with cognitive realism. Human moral cognition, as reviewed in Chapter~\ref{chap:moral_primer}, does not perform explicit global optimisation over expected outcomes; it operates through heuristic, affective, and context-sensitive processes that are only loosely correlated with the ideals of consequentialist reasoning \cite{Kahneman2011, Greene2001, Haidt2001, Slovic2007}. Treating human agents as if they literally implemented expected-utility maximisation is therefore another instance of LoA confusion.

\subsection{Action-Guidance Mechanism: From Value Gradients to Behavioural Pressure}

\noindent
How, then, does consequentialism guide action without collapsing into a psychologically implausible calculus? The answer, consistent with LoA discipline, is that consequentialism exerts its influence primarily through \emph{indirect modulation} of the evaluative topology rather than through direct computational implementation.

\noindent
At the reflective LoA, consequentialism states:

\begin{quote}
	An action is right insofar as it maximises (or sufficiently promotes) expected welfare.
\end{quote}

\noindent
At the cognitive LoA, however, moral behaviour is produced by the interaction of intuitive appraisal, affective resonance, social cues, and controlled regulation. Consequentialist considerations can shape this machinery over time via at least four pathways:

\begin{itemize}
	\item \textbf{Long-term shaping of dispositions}: education and moral reflection can increase sensitivity to outcomes, harm, and aggregate effects, thereby steepening certain evaluative gradients (e.g.\ aversion to needless suffering).
	\item \textbf{Local heuristics}: agents employ proxy rules (e.g.\ help when the cost is low; avoid imposing serious harm) that correlate, imperfectly, with welfare improvement.
	\item \textbf{Attentional modulation}: awareness of potential benefits or harms alters salience and intuitive appraisal; some features of a situation become more behaviourally weighty.
	\item \textbf{Regulatory control}: when intuitive impulses conflict with perceived consequences, deliberation may re-weight options in favour of outcome-based considerations.
\end{itemize}

\noindent
In topological terms, consequentialism does not “run” the cognitive system, but it can influence the \emph{shaping} of the evaluative field: steepening or flattening gradients, reorienting trajectories, and altering which outcome-dimensions become behaviourally decisive.

\subsection{Consequentialist Topology: Moral Action as Gradient Following}

\noindent
Within the topological framework of this thesis, we can now express the core consequentialist intuition succinctly: moral action is modelled as (approximate) \emph{gradient following} in a welfare-defined landscape. Behaviour is normatively preferred when it moves “uphill” along value gradients.

\noindent
This has several structural implications:

\begin{enumerate}
	\item \textbf{Smoothness}: unlike deontological boundaries, consequentialist fields permit smooth transitions. Moving from a slightly worse to a slightly better outcome traces a continuous path in evaluative space.
	\item \textbf{Directionality}: what matters is not merely where an agent is, but the direction of movement—toward or away from higher-welfare states.
	\item \textbf{Trade-offs}: multi-dimensional outcomes (e.g.\ helping one party while imposing small costs on another) are represented as interacting gradients over several axes.
	\item \textbf{Sensitivity to perturbation}: because evaluation tracks expected consequences, shifts in salience, attention, or perceived observer-interest directly reshape the gradient structure.
\end{enumerate}

\noindent
This final feature connects consequentialism to the experimental logic. If the perceived consequence structure of donation is altered by synthetic presence—because the social meaning of helping changes, or because the anticipated payoffs (reputational, affective, or interpersonal) are attenuated—then the agent’s trajectory through the evaluative field will shift accordingly.

\subsection{Why Consequentialism Matters for the Experimental Logic}

\noindent
Consequentialism is indispensable for one dimension of interpreting the behavioural perturbations observed in the experimental chapter. At the LoA relevant for our experiment, prosocial donation is simultaneously:

\begin{itemize}
	\item a \emph{behavioural output} of the moral cognitive architecture,
	\item and a \emph{welfare-relevant action} whose outcomes (for the beneficiary) can be straightforwardly ranked.
\end{itemize}

\noindent
Within this frame, the Watching-Eye prime and the robot’s synthetic presence can be understood as modulating the \emph{perceived consequence structure} of donating.

\begin{enumerate}
	\item \textbf{Watching-Eye cues reshape anticipated social consequences.} As discussed in Chapter~\ref{chap:experimental_methods}, visual cues suggesting observation are known to increase the perceived reputational or social-evaluative payoff of prosocial behaviour. In topological terms, they steepen the gradient pointing toward donation by enhancing the expected social value of helping.
	
	\item \textbf{Synthetic presence can interfere with or redirect this gradient.} The humanoid robot constitutes an ambiguous social agent whose presence may blunt, re-route, or partially occlude the evaluative pathways activated by the Watching-Eye cue. If the robot absorbs attention, disrupts affective resonance with the charity target, or is not integrated into the same social-evaluative schema as a human observer, the effective gradient from “keep the money” to “donate” may be flattened.
	
	\item \textbf{Consequentialism provides one axis of normative diagnosis.} If donation falls in the Robot condition, one interpretation---from a consequentialist perspective---is that synthetic presence has deformed the outcome-based evaluative field: the agent no longer experiences donating as sufficiently welfare-improving or socially valuable relative to alternatives. This differs from a purely deontic diagnosis (failure to track duty) or a purely virtue-theoretic diagnosis (shift in character-expressive patterns).
\end{enumerate}

\noindent
Consequentialism thus illuminates a specific facet of the moral displacement effect: the way in which synthetic presence can alter the perceived benefits, costs, and social meaning of helping, thereby reshaping the value gradients that normally support prosocial behaviour. Importantly, the thesis does \emph{not} treat this consequentialist structure as a blueprint for machine implementation, in contrast with classical Machine Ethics approaches that equate “ethical design” with encoding explicit utility functions. Instead, consequentialism is used here as a normative lens on how the evaluative topology is perturbed by synthetic agents.

\medskip

\noindent
The next section turns to virtue ethics, which locates normativity not primarily in constraints or consequences, but in the cultivated dispositions and perceptual sensitivities of the agent. This will allow us to examine a further dimension of the evaluative topology: how character, habituation, and moral perception shape the susceptibility of prosocial action to perturbation by robotic co-presence.

%%% Content 5 from lecce
\section{Virtue-Theoretic Structures: Dispositions, Character Topology, and Moral Sensitivity}
\label{sec:virtue_ethics}

\noindent
Deontological invariants and consequentialist gradients capture two important dimensions of the evaluative field, but they remain incomplete without a theory of the \emph{agent} who navigates that field. Virtue ethics---from Aristotle through modern neo-Aristotelian and psychological reconstructions \cite{Aristotle_nicomachean,Foot2001,Hursthouse1999,Annas2011}---locates normativity not primarily in constraints or outcomes, but in the \emph{perceptual and dispositional architecture} of the moral agent. This renders virtue ethics particularly well-suited for integration with the experimental findings of this thesis, which show systematic modulation of prosocial action by latent personality dimensions and cluster-level structure in trait space (see Chapter~\ref{chap:experimental_methods}).  

\noindent
Our task is therefore to reconstruct virtue ethics in a form that satisfies three conditions:

\begin{enumerate}
	\item It must preserve the philosophical distinctiveness of virtue theory as an account of normativity grounded in character and moral perception.
	\item It must be expressible in the evaluative-topological idiom developed across this thesis, allowing traits to modulate the curvature and attractor structure of the moral field.
	\item It must connect directly to the empirical results: latent trait configurations, cluster-dependent moral deformation, and the mathematically described perturbations induced by synthetic presence.
\end{enumerate}

\noindent
With these constraints in place, virtue theory becomes more than a catalogue of excellences: it becomes a theory of \emph{moral sensitivity as a topologically structured, personality-dependent field}, modulated both by long-term habituation and by local perturbations such as robotic co-presence.

\subsection{The Source of Normativity: Character, Practical Wisdom, and Moral Perception}

\noindent
In the virtue-theoretic tradition, normativity originates in the \emph{well-formed character} of the agent, rather than in rules or external valuations. Virtues are not propositional commitments but \emph{stable dispositional patterns} that structure moral perception: they determine what the agent notices, how she evaluates it, and which actions appear salient, fitting, or required \cite{McDowell1979,Foot2001}. Aristotle’s concept of \textit{phronesis}---practical wisdom---captures the idea that virtuous action arises from the \emph{fine-tuned sensitivity} to morally relevant features of a situation \cite{Aristotle_nicomachean}.

\noindent
This has a direct analogue in the evaluative topology introduced earlier. A virtuous agent is one whose evaluative field contains:

\begin{itemize}
	\item \textbf{stable attractors}: behavioural basins corresponding to courage, benevolence, honesty, fairness;
	\item \textbf{well-shaped gradients}: moral salience that shifts the system reliably toward prosocial trajectories;
	\item \textbf{robustness under perturbation}: resistance to minor contextual noise and situational fluctuation.
\end{itemize}

\noindent
Conversely, deficiencies in character appear as distortions or instabilities in the evaluative field: shallow attractors, flattened gradients, or poorly integrated response tendencies. 

\subsection{Mode of Evaluation: Dispositions as Topological Structure}

\noindent
Virtue ethics does not evaluate actions in isolation but assesses them as \emph{expressive of character}. The morally relevant unit is the dispositional pattern through which the agent perceives and structures her moral environment. This is where virtue theory intersects most naturally with the experimental findings.

\subsubsection*{(i) Mathematical and Topological Interpretation}

\noindent
Let the agent’s dispositional profile be represented by a vector 
\[
\beta_C \in \mathbb{R}^k,
\]
where \(k\) indexes latent psychological traits (e.g.\ agreeableness, empathy, conscientiousness). The experimental analyses in Chapter~\ref{chap:experimental_methods} demonstrate that participants form coherent clusters \(C_1, C_2, \dots, C_m\) in this trait space, each with characteristic dispositions.

\noindent
We can therefore interpret virtue-theoretic structure as a topological mapping
\[
\mathcal{T}: \mathbb{R}^k \rightarrow \mathcal{F},
\]
where \(\mathcal{F}\) is the space of evaluative fields. Under this model:

- high-agreeableness clusters exhibit deeper prosocial attractors;  
- low-empathy clusters exhibit shallower or displaced prosocial basins;  
- high-conscientiousness clusters show increased boundary rigidity for deontic constraints;  
- neuroticism modulates sensitivity to evaluation cues (including the Watching-Eye effect).

\noindent
In virtue-theoretic terms, \(\beta_C\) approximates a parametric description of the agent’s \emph{character topology}. This mapping was borne out empirically: different clusters showed markedly different susceptibility to moral deformation under synthetic presence, precisely as a virtue-ethical model predicts.

\subsubsection*{(ii) Connection to Moral Psychology}

\noindent
Modern moral psychology (e.g.\ the \emph{moral foundations} approach \cite{Haidt2012}, the \emph{character-based} models of Snow \cite{Snow2010}, and the \emph{sensitivity-based} accounts of Dancy \cite{Dancy2004}) emphasises that moral responsiveness is a function of dispositional configuration. Trait-dependent modulation of salience, empathy, and social attentiveness mirrors the classical virtue-theoretic notion that moral judgment depends on habituated perception.

\noindent
Our empirical data confirm this: the presence of the robot altered prosocial behaviour differentially across personality clusters, demonstrating that the moral field is not homogenous but \emph{character-structured}.

\subsection{Action-Guidance Mechanism: Habituation, Stability, and Situated Sensitivity}

\noindent
Virtue ethics explains action not by invoking explicit principles or value calculations but through the \emph{habituated, stabilised patterns of salience and response} characteristic of a well-formed agent. This aligns neatly with the dual-process architecture established in Chapter~\ref{chap:moral_primer}:

\begin{itemize}
	\item intuitive processes are shaped by long-term habituation into affective–perceptual sensitivities,
	\item controlled processes integrate commitments and identities developed over time,
	\item behavioural output reflects the stability or fragility of dispositional attractors.
\end{itemize}

\noindent
In topological terms, virtues correspond to \emph{deep attractor basins} resistant to perturbation; vices or deficiencies correspond to \emph{shallow or unstable attractors}. This interpretation is supported by both computational models of habit formation \cite{Wood2016} and empirical studies of moral perception \cite{Reynolds2006}.

\subsection{Virtue-Theoretic Topology: Stability, Curvature, and Susceptibility to Perturbation}

\noindent
Within the evaluative-topological framework, virtue ethics can be modelled using dynamical systems language:

\[
\dot{x} = f(x;\beta_C),
\]
where \(x\) is the agent’s state in evaluative space and \(\beta_C\) parametrises dispositional curvature. The presence of a synthetic agent introduces a perturbation \(\delta f\) such that

\[
\dot{x}' = f(x;\beta_C) + \delta f(x;\mathscr{R}),
\]

where \(\mathscr{R}\) denotes robotic co-presence.

\noindent
Crucially:

- for some clusters, \(\delta f\) shifts the trajectory away from the prosocial attractor basin (attenuation of donation);  
- for others, the attractor curvature remains sufficiently deep that the perturbation is absorbed;  
- for exceptionally prosocial configurations, synthetic presence may even sharpen evaluative focus (rare, but consistent with the upper-tail donors observed).

\noindent
This constitutes a clear virtue-theoretic phenomenon: moral sensitivity is \emph{trait-dependent}, and synthetic perturbation reveals structural differences in the stability of character.

\subsection{Why Virtue Ethics Matters for the Experimental Logic}

\noindent
Virtue ethics is indispensable for interpreting the experimental results for three interconnected reasons.

\paragraph{1.\ Latent Trait Modulation}
The experiment confirms that moral perturbation is not uniform: clusters in personality space exhibit distinct patterns of deformation. Virtue theory provides the conceptual vocabulary for understanding these effects as differences in character topology. Prosocial action is more fragile in agents with shallow attractors; synthetic presence perturbs these evaluative structures disproportionately.

\paragraph{2.\ Moral Topology Over Trait Space}
The mapping
\[
\beta_C \mapsto \mathcal{T}(\beta_C)
\]
establishes that moral responsiveness is a \emph{function of trait geometry}. This is a virtue-theoretic insight: character is the medium through which the environment’s moral affordances are processed.

\paragraph{3.\ Machine Ethics Ignores Character Entirely}
Classical Machine Ethics frameworks assume that ethical behaviour can be engineered through top-down rules or utility functions. They contain no representation of dispositional structure, no equivalent of \(\beta_C\), no account of habituation, and no model of trait-dependent sensitivity to perturbation. This makes them incapable of predicting---or even recognising---the character-mediated moral displacement observed in our experiment.

\noindent
Virtue ethics therefore reveals the deepest limitation of rule-based or utility-based Machine Ethics: moral agency is fundamentally \emph{dispositional}, and no architecture that ignores habituated sensitivity, perceptual tuning, and trait-level topology can claim to model it.

\medskip

\noindent
In sum, virtue ethics interprets the experimental findings as a demonstration that synthetic agents perturb moral action by interacting with the agent-specific topology shaped by habituation, character, and perceptual attunement. Where deontology contributes boundary conditions and consequentialism contributes gradient structure, virtue ethics contributes the \emph{curvature of the evaluative manifold itself}: the dispositional geometry that determines how agents absorb, refract, or amplify perturbation.

\subsection*{Interim Synthesis: How the Three Normative Frameworks Illuminate the Experimental Findings}

\noindent
With deontology, consequentialism, and virtue ethics reconstructed through the discipline of Levels of Abstraction and embedded within the evaluative-topological architecture developed across this thesis, we can now articulate their practical significance for the experimental results. 

The purpose of this synthesis is not merely classificatory. It is to demonstrate why an empirical study of synthetic social influence \emph{requires} a multi-framework normative lens, and why no single classical theory is sufficient to interpret the perturbations observed in prosocial donation.

\bigskip

\noindent
\textbf{1.\ Deontology: Structural Invariants and the Integrity of Moral Expectation}

\noindent
In the deontological reconstruction, duties appear as \emph{invariant boundaries} of the evaluative field. The Watching-Eye cue---as developed in Chapter~\ref{chap:experimental_methods}---implicitly invokes precisely these invariants: reciprocity, fairness, honesty, and the demand to act as if one’s behaviour were publicly accountable.

\begin{itemize}
	\item When donation decreases in the Robot condition, the key normative question is whether the perturbation reflects a weakening of sensitivity to these invariants.
	\item If synthetic presence “flattens” the deontic landscape---attenuating the felt pull of duty---then the perturbation carries ethical weight beyond behavioural variation.
	\item The deontological analysis therefore provides the vocabulary to distinguish between a mere preference shift and a disruption in the \emph{structural preconditions} of rightful agency.
\end{itemize}

\noindent
Empirically, this interpretation is strengthened by the fact that deontic cues (the child’s face, the moral framing of donation) remain constant across conditions. The only structural change is the presence of the synthetic observer. This isolates the robot as a potential \emph{interference with deontic uptake}. A purely psychological description would register the attenuation as behavioural variance; a deontological analysis reveals it as a possible distortion of moral accountability.

\bigskip

\noindent
\textbf{2.\ Consequentialism: Gradient Deformation and the Perceived Structure of Outcomes}

\noindent
From a consequentialist standpoint, moral orientation depends on the perceived gradient of expected value. Watching-Eye cues work partly because they shift the perceived payoff structure: being observed increases reputational benefit, reduces social cost, or reinforces anticipated approval.

\noindent
The robot’s presence perturbs this gradient in three ways:

\begin{enumerate}
	\item It introduces an \emph{ambiguous observer} whose evaluative stance is unclear, flattening or redirecting the perceived payoff of donation.
	\item It may compete with, divert attention from, or overshadow the reputational signal emitted by the Watching-Eye stimulus.
	\item It may shift the perceived “social meaning” of the interaction, transforming a dyadic human–charity cue environment into a triadic human–robot–cue environment.
\end{enumerate}

\noindent
In topological terms, the synthetic presence deforms the gradient field: it alters the local slope of the utility landscape surrounding prosocial action. This consequentialist diagnosis captures aspects of the perturbation that the deontological analysis cannot. Whereas deontology cares about the structural integrity of duties, consequentialism cares about the \emph{direction and magnitude of evaluative flow}. The empirical attenuation fits naturally into this model: synthetic presence recalibrates anticipated outcomes, producing a shallower gradient toward the prosocial basin.

%% check sectioning

\noindent
\textbf{3.\ Virtue Ethics: Dispositional Curvature and Cluster-Dependent Sensitivity}

\noindent
The virtue-theoretic reconstruction offers yet another lens—one that matches the empirical findings with remarkable precision. Virtue ethics treats moral responsiveness as a function of dispositional structure: the shape, depth, and stability of an agent’s evaluative attractors.

\subsection{Virtue-Ethical Interpretation of Latent Ecologies}
\noindent  
The experiment revealed this pattern with striking clarity when analysed through the semantic ecology of the latent trait clusters:
	
	\begin{itemize}
		\item \textbf{Prosocial--Empathic / Warm--Sociable Ecology}: stable, deep prosocial attractors; moral trajectories remained largely invariant under synthetic perturbation. Donation behaviour persisted despite the introduction of the robot, indicating a robust evaluative surface anchored in empathic resonance and interpersonal sensitivity.
		
		\item \textbf{Emotionally Reactive / Low-Structure Ecology}: shallow, volatile, or displaced attractors; this ecology exhibited the \emph{strongest attenuation} under robotic presence. Their evaluative field displays low structural coherence and heightened responsiveness to contextual cues; the robot’s ontological ambiguity therefore diffuses or refracts moral salience at precisely the stage where affective anchoring would normally stabilise action.
		
		\item \textbf{Analytical--Structured / High-Systemizing Ecology}: intermediate curvature; these participants showed partial but not catastrophic displacement. Their evaluative architecture privileges clarity and rule-structure over affective immediacy, making them comparatively resistant to affective perturbation, but sensitive to disruptions of interpretive coherence.
	\end{itemize}
	
	\noindent  
	This ecological differentiation is \emph{not a behavioural epiphenomenon}: it is the virtue-ethical signature of the data. The robot does not act as a uniformly applied suppressor $(\gamma_R)$; rather, it functions as a \emph{contextually instantiated perturbator} whose behavioural impact depends on the dispositional topology encoded in $\beta_C$.
	
	\[
	\dot{x}' = f(x;\beta_C) + \delta f(x;\mathscr{R})
	\]
	
	\noindent  
	where $f(x;\beta_C)$ is the endogenous evaluative drift governing each ecological type’s baseline moral trajectory, and $\delta f(x;\mathscr{R})$ is the deformation induced by synthetic presence.
	
	\noindent  
	Crucially, $\delta f$ is \emph{not} constant. Its sign, magnitude, and functional shape vary across ecologies:
	
	\begin{itemize}
		\item In the \textbf{Prosocial--Empathic} ecology, $\delta f$ attenuates the empathic--affiliative attractor, flattening the gradient that normally drives prosocial donation.
		\item In the \textbf{Emotionally Reactive} ecology, $\delta f$ interacts with an already unstable evaluative surface, amplifying volatility and producing the sharpest behavioural displacement.
		\item In the \textbf{Analytical--Structured} ecology, $\delta f$ perturbs coherence rather than affect, leading to partial reconfiguration but not collapse.
	\end{itemize}
	
	\noindent  
	This is precisely the prediction of virtue ethics: the moral perturbation induced by $\mathscr{R}$ is mediated not by rule-following or outcome-calculation, but by the dispositional configuration of the agent---their stable tendencies of attention, valuation, and motivational salience.
	
	\medskip
	
	\noindent  
	Viewed through Floridi's Levels of Abstraction, the latent ecologies constitute \textbf{distinct semantic filters}:
	
	\begin{itemize}
		\item The \textbf{Prosocial--Empathic LoA} foregrounds affective and interpersonal cues.
		\item The \textbf{Emotionally Reactive LoA} foregrounds volatility, ambiguity, and contextual instability.
		\item The \textbf{Analytical--Structured LoA} foregrounds coherence, formal clarity, and normative intelligibility.
	\end{itemize}
	
	\noindent  
	The robot’s ambiguous ontology---neither fully social nor fully inert---is refracted through these LoAs differently, producing \emph{topologically distinct perturbations}. This explains why synthetic presence yields neither a uniform nor a homogeneous effect, but one that is \emph{contingent upon the semantic architecture} that each ecological profile brings to the interaction.
	
	\noindent  
	Thus, the virtue-ethical reconstruction, the latent-trait analysis, and the topological model converge: the robot reveals, with unusual diagnostic precision, the dispositional geometry of each ecological type. Moral displacement is not merely a behavioural effect; it is a principled probe into the internal architecture of moral cognition.


\bigskip

\noindent
\textbf{5.\ What Machine Ethics Misses}

\noindent
This synthesis also exposes the limitations of classical Machine Ethics:

\begin{enumerate}
	\item It assumes that behaviour can be derived from explicit rules (deontic codification), ignoring the psychological mechanisms through which duties gain behavioural force.
	\item It assumes that welfare optimisation can be implemented directly through utility functions, ignoring the fact that humans do not compute value gradients explicitly and are sensitive to subtle perturbations.
	\item It ignores dispositional topology entirely; it has no representation for character, habituation, sensitivity, or cluster-dependent variation.
\end{enumerate}

\noindent
Thus, Machine Ethics repeatedly commits the LoA mistake: treating normative abstractions as if they were cognitive operators. The experiment demonstrates why this is untenable: moral behaviour emerges from topological dynamics that Machine Ethics has no resources to model.

\bigskip

\noindent
\textbf{6.\ Concluding Perspective: Why This Matters Now}

\noindent
The virtue-theoretic, deontological, and consequentialist reconstructions converge on a single insight: the moral significance of synthetic presence cannot be captured by any one normative theory alone, nor can it be reduced to behaviourist regularities. It must be understood as a deformation of the evaluative topology through which agents convert moral salience into action.  

\noindent
The experiment does not merely show that robots change behaviour. It shows \emph{how} they do so: by reshaping deontic sensitivity, altering perceived consequence gradients, and interacting with deep dispositional structures. This threefold interpretation is the normative analogue of the empirical results—and it furnishes the philosophical scaffolding for the sentimentalist, affect-based account developed next.

\noindent
The next section introduces sentimentalist and affect-based accounts, which complement the dispositional framework by modelling the affective vectors that shape the immediate moral landscape and interact with the latent trait structure identified above.

\section{Sentimentalism and Emotion-Based Normativity: Affective Vector Fields in Moral Topology}
\label{sec:sentimentalism}

\noindent
Having reconstructed deontology as topological invariance and consequentialism as value-gradient optimisation, we now turn to the normative framework most directly implicated in the experimental results: \emph{sentimentalism}. In the sentimentalist tradition—Hume, Smith, and their contemporary heirs—\emph{moral evaluation arises from patterns of affective resonance}. Moral judgment is not primarily the deliverance of reason nor the outcome of consequence-calculation, but the structured responsiveness of an agent’s affective system to features of the social world \cite{HumeTreatise, Smith1759, Slote2010, Nichols2004}. 

\noindent
Within the evaluative-topological framework developed in this thesis, sentimentalism can be reconstructed as an \textbf{affective vector field}:
\[
\mathbf{A}(x) : \mathcal{X} \to \mathbb{R}^n
\]
where $\mathcal{X}$ is the space of perceived states and $\mathbf{A}(x)$ encodes the direction and magnitude of affective forces—empathic pull, aversive push, compassion, indignation, warmth, or distress. Moral trajectories emerge from the integration of these affective vectors with attentional, inferential, and regulatory processes.

\noindent
This reconstruction is not metaphorical. It is empirically realised in the experiment: the robot’s presence attenuates donation behaviour \emph{by dampening the affective vector field}, especially within ecological profiles where empathy, warmth, or affective sensitivity ordinarily serve as the primary drivers of moral salience.

\subsection{The Source of Normativity: Sentiment as the Basis of Moral Appraisal}

\noindent
For sentimentalists, normativity originates in the \emph{patterns of affective response} that constitute the human capacity for moral perception. Hume’s claim that moral distinctions are “more properly felt than judged” \cite{HumeTreatise} is often caricatured; yet properly interpreted, it captures a structural truth about moral cognition: affective resonance is the primary medium through which agents register the moral significance of others.

\noindent
This maps directly onto the cognitive LoA articulated in the Morality Primer:  
affective tagging (amygdala, insula), empathic resonance (mPFC–TPJ circuit), and rapid harm appraisal provide the initial topological curvature from which moral trajectories originate.

\noindent
Where deontology imposes constraints and consequentialism imposes gradients, sentimentalism specifies the \emph{affective geometry} of the evaluative field: how warmth draws the agent toward prosocial action, how distress aversion or fear repel them, and how empathic concern shapes the felt moral landscape.

\subsection{Mode of Evaluation: Affective Resonance as Moral Metric}

\noindent
In the sentimentalist reconstruction, the mode of evaluation is grounded in:
\begin{itemize}
	\item \textbf{empathic responsiveness} to others’ welfare,
	\item \textbf{reactive attitudes} such as guilt, indignation, gratitude, and resentment,
	\item \textbf{interpersonal attunement} through shared affective states,
	\item \textbf{warmth, sociability, and affiliative motivation}.
\end{itemize}

\noindent
These components map precisely onto the \textbf{Prosocial--Empathic / Warm--Sociable ecology}. For individuals in this cluster, moral relevance is primarily affective: moral cues are not merely recognised but \emph{felt}, and prosocial donation emerges from empathic attunement to the beneficiary.

\noindent
Thus, sentimentalist normativity aligns almost point-for-point with the evaluative topology of Cluster~\emph{Prosocial--Empathic}. If moral action is the integral of affective forces across the evaluative field, then anything that diminishes the amplitude of $\mathbf{A}(x)$ will proportionally diminish prosocial behaviour.

\subsection{Action Guidance: Affective Vector Fields and Behavioural Dynamics}

\noindent
The sentimentalist picture becomes formally precise when expressed as a dynamical system:
\[
\dot{x} = f(x) + \mathbf{A}(x),
\]
where $f(x)$ captures neutral evaluative drift and $\mathbf{A}(x)$ represents affective forces.

\noindent
Synthetic presence enters the system as a deformation operator:
\[
\dot{x}' = f(x) + \mathbf{A}(x) + \delta \mathbf{A}(x;\mathscr{R}),
\]
where $\delta \mathbf{A}(x;\mathscr{R})$ is a vector field that attenuates, displaces, or reorients affective flow.

\noindent
This model captures the experimental results with exceptional fidelity:
\begin{itemize}
	\item In the \textbf{Prosocial--Empathic ecology}, $\delta \mathbf{A}$ significantly dampens empathic activation, flattening the trajectory toward donation.
	\item In the \textbf{Emotionally Reactive ecology}, $\delta \mathbf{A}$ destabilises an already volatile field, producing the strongest behavioural perturbation.
	\item In the \textbf{Analytical--Structured ecology}, $\delta \mathbf{A}$ is comparatively weak; affective forces are not the dominant drivers of action, so the robot’s dampening effect is limited.
\end{itemize}

\noindent
In short, the robot modulates the moral field by \emph{reducing the affective curvature} that ordinarily drives prosocial behaviour—a textbook sentimentalist effect.

\subsection{Contrast with Machine Ethics: The Blind Spot of Affective Architecture}

\noindent
Classical Machine Ethics commits its deepest conceptual error here.  
It systematically ignores affective architecture, attempting to:

\begin{itemize}
	\item replace empathic resonance with rule sets,
	\item replace moral perception with logical inference,
	\item replace affective appraisal with propositional justification.
\end{itemize}

\noindent
No sentimentalist could make this mistake, because for sentimentalism, affect is neither optional nor ornamental: it is the \emph{substrate} of moral cognition.

\noindent
Our experiment demonstrates precisely what Machine Ethics ignores: a silent, non-interactive robot can alter human moral behaviour not by violating rules or changing utilities, but by shifting the structure of \emph{affective vectors} that underwrite prosocial responsiveness.

\noindent
Machine Ethics has no conceptual resources to model this effect.  
A sentimentalist topology does.

\subsection{Experimental Realisation: Synthetic Dampening of Empathic Resonance}

\noindent
The key empirical finding of the experiment is that robotic co-presence attenuates donation behaviour even in the presence of a strong empathic cue (the Watching-Eye stimulus). From a sentimentalist perspective, this is best understood as:

\[
\delta \mathbf{A}(x;\mathscr{R}) < 0
\]
for affectively weighted regions of the evaluative field, \emph{where}:
\begin{itemize}
	\item $x$ denotes the agent’s current evaluative state within the moral field;
	\item $\mathbf{A}(x)$ is the baseline affective vector field that encodes empathic pull, aversive push, warmth, distress, and related affective forces;
	\item $\mathscr{R}$ represents the presence of the humanoid robot as an environmental perturbator;
	\item $\delta \mathbf{A}(x;\mathscr{R})$ is the deformation operator modelling how $\mathscr{R}$ alters the magnitude and direction of affective vectors at $x$.
\end{itemize}

\noindent
In plain terms, the inequality $\delta \mathbf{A}(x;\mathscr{R}) < 0$ states that the robot’s co-presence \emph{reduces the strength of the affective forces} (especially empathic resonance) that normally propel the agent toward prosocial action. The perturbation does not reverse moral direction; it \emph{dampens} the affective momentum that would otherwise guide the agent toward donation.

for affectively weighted regions of the evaluative field.

\noindent
The robot introduces ontological ambiguity—neither fully agentic nor wholly inert—which disrupts affective attunement in two ways:

\begin{enumerate}
	\item \textbf{Affective dilution}: the presence of an ambiguous social other diverts empathic focus away from the child-beneficiary.
	\item \textbf{Affective deflection}: the robot introduces uncertainty about social meaning, reducing the clarity of empathic pathways.
\end{enumerate}

\noindent
Both phenomena manifest as measurable differences in the experimental clusters:

\begin{itemize}
	\item \textbf{Prosocial--Empathic}: attenuation is diagnostic of diluted empathic resonance.
	\item \textbf{Emotionally Reactive}: attenuation reflects increased volatility of affective vectors.
	\item \textbf{Analytical--Structured}: attenuation is weaker, because affect is not the primary moral driver.
\end{itemize}

\noindent
Thus, sentimentalism provides the most \emph{mechanistically precise} explanation of the perturbation: synthetic presence alters the affective landscape through which moral salience becomes moral action.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,title={Interpretive Synthesis: Sentimentalism and Synthetic Moral Perturbation}]
		\noindent
		The experimental attenuation of prosocial behaviour under robotic co-presence is a paradigmatic sentimentalist phenomenon. Moral action in the Prosocial--Empathic ecology is driven by affective vector fields whose magnitude is reduced by the robot’s ambiguous ontology; in the Emotionally Reactive ecology, the same perturbation destabilises an already volatile field; and in the Analytical--Structured ecology, affective dampening has limited influence because the evaluative surface is dominated by structural rather than affective curvature.
		
		\noindent
		This tripartite pattern cannot be captured by rule-based models, logical deduction, or utility maximisation. It requires a framework in which \emph{affective forces are constitutive of moral cognition}. Sentimentalism, reconstructed as a vector-field theory of affective appraisal, therefore provides the most illuminating normative interpretation of the experiment.
		
		\noindent
		By revealing how synthetic presence modulates affective resonance across latent evaluative ecologies, the experiment demonstrates that moral displacement is not a failure of principles, nor a miscalculation of outcomes, but a deformation of the affective topology through which moral meaning is experienced. This establishes sentimentalist normativity as an indispensable component of any adequate ethical or computational treatment of artificial agents.
	\end{tcolorbox}
\end{center}

\section{Contractualism, Particularism, and Hybrid Normative Models}
\label{sec:contractualism_particularism_hybrid}

\noindent
The preceding sections developed deontological, consequentialist, and virtue-theoretic structures as topological configurations within the evaluative field. To complete the normative landscape relevant to this thesis, we now introduce three additional frameworks—\emph{contractualism}, \emph{particularism}, and \emph{hybrid or pluralist models}. These theories are reconstructed briefly but precisely, preserving their philosophical integrity while integrating them into the LoA discipline and the evaluative-topological architecture that anchors both the theory and the experiment.

The motivation for introducing these additional models is twofold. 

First, they represent influential alternatives to the classical triad of deontology, consequentialism, and virtue ethics. Contractualist theories such as Scanlon’s place justificatory relations at the centre of moral evaluation \cite{Scanlon1998}; particularist and perceptual approaches emphasise context-sensitive moral salience rather than rule-governed invariants \cite{McDowell1979,Audi2015}; and pluralist or hybrid accounts highlight the inherently multidimensional structure of practical reason \cite{Doris2002}. 

Second, these frameworks illuminate aspects of the experimental data that are not recoverable from topological invariants, value gradients, or dispositional attractors alone. Deontological rules struggle to accommodate dilemmatic or context-dependent cases \cite{Morscher2002}, outcome-based models fail to capture the intuitive and affective dynamics documented in empirical moral psychology \cite{Greene2001}, and virtue-theoretic attractors are limited by the instability of global traits \cite{Doris2002}. By contrast, theories grounded in justifiability, contextual salience, and multidimensional normative interaction provide precisely the structural resources needed to interpret how synthetic presence modulates prosocial behaviour. Empirical studies show that minimal cues of social evaluation—including robotic presence, perceived agency, or merely the appearance of watching eyes—systematically shift cooperative and moral behaviour \cite{Bremner2022,Francey2012,Kawamura2017,Malle2016}. These phenomena demand a normative-cognitive model capable of accommodating justification pressures, situational salience, and relational moral dynamics—dimensions captured by these alternative frameworks.

\noindent
\textit{A further reason for reconstructing these theories is philosophical and pedagogical rather than merely instrumental.} Any comprehensive treatment of normative foundations—particularly one that aims to integrate ethics with empirical findings and computational modelling—must follow the established structure of the discipline. Contractualism, particularism, and pluralist models represent canonical branches of ethical theory, and omitting them would not only break with the methodological tradition of moral philosophy but would deprive the reader of the conceptual resources required to situate the thesis within the broader normative landscape. Their inclusion therefore serves a dual purpose: it preserves continuity with the philosophical canon, and it ensures that the interpretive tools deployed in analysing the experiment are grounded in a complete and pedagogically robust reconstruction of the field. In short, without these frameworks, the chapter would lack both scholarly completeness and exegetical depth; with them, the reader is equipped to understand how the experimental findings resonate across the full range of contemporary normative theory.


\subsection{Contractualism: Moral Claims as Justification-Equilibria}

\noindent
Contractualism, most prominently articulated by Scanlon~\cite{Scanlon1998}, grounds moral rightness in the principle that actions must be justifiable to others on grounds that no one could reasonably reject. This account locates the \emph{source of normativity} not in rules, consequences, or character, but in the structure of interpersonal justification.

Within the LoA structure adopted earlier, contractualism operates at the reflective normative level. It specifies the conditions under which agents can regard themselves as mutually accountable. However, it also has cognitive implications: establishing justifiability requires a sensitivity to others’ claims, expectations, and burdens, which in turn depends on social perception and empathic attunement.

\noindent
\textbf{Topological Interpretation.}  
Contractualism can be conceptualised as defining regions of justificatory equilibrium within the evaluative field—zones in which an action can withstand the test of mutual recognisability and reasonable non-rejection. On Scanlon’s account, moral principles are valid only insofar as they can be justified to others as part of a shared moral relationship \cite{Scanlon1998}; similarly, Strawson’s analysis of reactive attitudes shows that moral assessment presupposes an interpersonal standpoint in which agents acknowledge one another as answerable participants \cite{Strawson1962}. These equilibria remain stable only when agents register the presence and perspective of others, since the very structure of contractualist judgment requires a perceived field of accountability.

Synthetic presence therefore interacts with contractualist structure in a distinctive way. A minimal cue of observation—such as a watching-eye stimulus—typically increases the salience of interpersonal accountability and strengthens cooperative norms \cite{Francey2012,Kawamura2017}. However, a humanoid robot, being perceptually social yet ontologically ambiguous, perturbs this social-evaluative field. Empirical work shows that robots can elicit social facilitation effects \cite{Bremner2022} while simultaneously failing to stably occupy the interpersonal roles through which moral demands are ordinarily mediated \cite{Malle2016}. The result is a displacement or dilution of the implicit sense of being under another’s evaluative regard, thereby disrupting the justificatory equilibrium that contractualism presupposes.

\noindent
\textbf{Relevance to Experimental Findings.}  
Contractualism helps explain why the Prosocial–Empathic cluster exhibited the strongest attenuation in the presence of the humanoid robot. Contractualist moral cognition is grounded in the demand that one’s actions be justifiable to others under conditions of mutual recognisability \cite{Scanlon1998,Strawson1962}. Individuals high in prosociality and empathy are especially sensitive to this interpersonal dimension: their behaviour is strongly modulated by cues of accountability and evaluative regard \cite{Cialdini2007}. Under normal circumstances, the Watching-Eye stimulus enhances this perceived mutual accountability, consistent with findings that minimal social-evaluative cues increase cooperation and generosity \cite{Francey2012,Kawamura2017}.

The humanoid robot, however, introduces a distinctive perturbation to the justificatory field. Robots can trigger social cognition and elicit affective responses, yet they occupy an ambiguous interpersonal category—they are perceptually social but not reliably recognised as members of the moral community \cite{Malle2016,Carpenter2016}. Empirical studies show that such synthetic presence can both facilitate and destabilise social behaviour \cite{Bremner2022}. In this context, the robot displaces the implicit sense of being under the evaluative regard of others, thereby weakening justificatory resonance and reducing donation.

Contractualism therefore interprets the observed displacement effect not as a change in underlying preference or a failure of duty, but as a deformation of the justificatory field: a disruption of the interpersonal conditions under which reasons become mutually recognisable and moral motivations are sustained.

\subsection{Moral Particularism: Contextual Salience and the Fragmented Topology of Reasons}

\noindent
Moral particularism rejects the idea that morality is governed by fixed principles, boundaries, or stable evaluative gradients. On the particularist view, the moral relevance of a consideration is wholly context-dependent: a feature that counts in favour of an action in one case may count against it in another, and reasons possess no invariant valence \cite{Dancy2004}. This holism of reasons is closely aligned with McDowell’s account of moral perception, in which the salience of a consideration emerges from its role within a concrete situation rather than from any codifiable general rule \cite{McDowell1979}. Related work in moral epistemology likewise emphasises that the moral field is shaped by context-sensitive patterns of attention and evaluative uptake \cite{Audi2015}.

Within an evaluative-topological framework, particularism corresponds to a landscape devoid of global structure. Instead of stable invariants or fixed gradients, the field consists solely of local salience contours whose shape shifts with variations in context, attention, or affect. Empirical work in moral psychology supports this characterisation: affective intuitions, perceptual cues, and distributed cognitive processes dynamically modulate which features of a situation are experienced as morally salient \cite{Haidt2001,Greene2001,Narvaez2005}. On this view, the evaluative field is fragmented and constantly reconfigured by situational parameters, making moral appraisal an exercise in context-sensitive responsiveness rather than rule-governed inference.

\noindent
\textbf{Synthetic Perturbation Under Particularism.}  
If moral salience is locally determined, then synthetic presence need not override a stable evaluative map—there may be no stable map to override. Instead, the robot alters the immediate pattern of salience in the environment.

Moral relevance shifts with contextual detail, perceptual attention, and affective orientation; reasons have no invariant valence \cite{Dancy2004,McDowell1979,Audi2015,Haidt2001}. On this view, the evaluative field is not globally structured but dynamically reconstructed from moment to moment as agents engage with their environment.

Synthetic presence therefore alters moral appraisal not by displacing a fixed evaluative configuration but by reshaping the local pattern of salience. Watching-eye cues, for example, immediately increase the accessibility of accountability norms \cite{Francey2012}, while the presence of a humanoid robot modifies attention, affect, and perceived social agency in more ambiguous ways \cite{Bremner2022,Malle2016,Carpenter2016}. What changes is not a stable moral map but the salience geometry that determines which features of the situation come to the fore. In a locally structured evaluative landscape, such perturbations directly influence moral appraisal by shifting which considerations are taken to matter.

This explains why the Emotionally Reactive cluster remained largely invariant in the experiment: their evaluative field is already highly sensitive to situational micro-variations; the robot adds noise, but not disruption relative to their already-fluid topology.

For the Prosocial–Empathic cluster, particularism illuminates a distinct mechanism. Because moral salience is locally assembled rather than globally fixed, the introduction of a humanoid robot reorganises the initial salience hierarchy in the scene. Findings from Social Signal Processing demonstrate that socially meaningful agents exert strong bottom-up pressure on attentional allocation, reshaping which cues are processed first and with what priority \cite{Pentland2007,Vinciarelli2012}. In HRI, even minimal humanoid cues have been shown to redirect gaze, amplify social relevance, and restructure the perceptual field through which subsequent evaluation occurs \cite{Mutlu2009,Admoni2017,Krach2008}. Psychological studies similarly show that agentive or emotionally charged stimuli modulate attentional capture and suppress competing social cues \cite{Bargh1999,Phelps2006,Zaki2012}.

For individuals high in prosociality and empathy, the Watching-Eye stimulus typically heightens interpersonal accountability and enhances empathic attunement. However, the robot’s ambiguous interpersonal status—neither fully social nor fully non-social—introduces a conflict in salience that overshadows the eye cue. The result is a weakening of empathic resonance with the expected evaluative signal, producing the attenuated prosocial output observed in the experiments. This interpretation aligns with philosophical accounts of moral perception in which what becomes salient first, and how long it remains salient, is constitutive of the evaluative episode itself \cite{McDowell1979,Slote2010}.

\subsection{Hybrid and Pluralist Models: Multidimensional Topologies}

Hybrid or pluralist normative theories—from Ross’s account of irreducible prima facie duties \cite{Ross2002} to contemporary value pluralism \cite{Chang2013}—maintain that normativity is generated by multiple independent evaluative sources. On this view, moral assessment is not grounded solely in duty, utility, or virtue, but arises from an interplay among distinct kinds of considerations: deontic constraints, outcome-based reasons, character-based appraisals, relational obligations, and contextual factors all exert normative force \cite{Griffin1986,Stocker1990,Korsgaard2009,Scanlon1998}.

In topological terms, pluralism corresponds to a multi-dimensional evaluative manifold. Rather than a single moral axis, the evaluative space contains intersecting gradients, constraints, and dispositional attractors that jointly shape moral judgment. Psychological and neurocognitive models of moral cognition reinforce this interpretation: affective intuitions, rule-based processes, and outcome-tracking mechanisms operate semi-independently and interact dynamically \cite{Haidt2001,Greene2001,Churchland2011}. Moral judgment, on this pluralist understanding, involves navigating a field whose geometry reflects the heterogeneity of moral reasons, none of which dominates the space entirely.

\noindent
\textbf{Why Pluralism Fits the Experiment.}  
The experimental findings align naturally with a pluralist topology:

\begin{itemize}
	\item The Watching-Eye cue activates deontic expectations (being observed).  
	\item Prosocial donation expresses consequentialist gradients (benefit to others).  
	\item Cluster differences reflect dispositional factors (virtue-theoretic structure).  
	\item The robot’s ontology refracts social meaning (contractualist relevance).  
	\item Synthetic perturbation shifts local salience (particularist sensitivity).  
\end{itemize}

No single normative theory fully explains the displacement effect observed in the experiment; the phenomenon does not map cleanly onto duty-based invariants, outcome gradients, virtue-theoretic dispositions, or empathy-driven models alone \cite{Foot1978,Morscher2002,Greene2001,Doris2002,Zaki2012}. Instead, the attenuation of prosocial behaviour in the presence of a humanoid robot appears to arise from a reweighting across multiple normative dimensions simultaneously. This is precisely what a pluralist topological model predicts. If moral judgment is guided by a manifold of intersecting evaluative gradients—deontic constraints, empathic pull, reputational expectations, contextual norms, and outcome-based considerations—then perturbing the structure of the environment can alter the geometry of this manifold as a whole \cite{Ross2002,Chang2013,Churchland2011}.

The experimental findings provide empirical support for this view. The robot’s mere presence displaced prosocial action across participants irrespective of dispositional differences: personality traits, empathizing and systemizing profiles, and even latent psychometric clusters failed to moderate the effect. This indicates that the perturbation operates not at the level of individual evaluative tendencies but at the level of the evaluative field itself. The robot’s perceptual salience and ontological ambiguity modulate several normative gradients at once—attenuating empathic resonance, altering implicit social expectations, and shifting the perceived normative demand of the situation \cite{Malle2016,Komatsu2016,Krach2008,Carpenter2016,Bremner2022,Groom2010}. In particular, the Watching-Eye cue’s typical facilitation of prosocial behaviour is dampened by competing or ambiguous social cues, consistent with findings on accountability cues, attentional capture, and salience competition in social signal processing and psychology \cite{Francey2012,Kawamura2017,Phelps2006,Zaki2012,Pentland2007,Vinciarelli2012}. Rather than reinforcing or suppressing any single source of moral motivation, the robot reconfigures the topology within which diverse moral reasons are weighed and integrated.

In this respect, the experiment does more than illustrate a behavioural effect: it offers empirical evidence for the central insight of normative pluralism—that moral judgment is sensitive to the configuration of multiple evaluative dimensions, any of which may be displaced by contextual perturbation \cite{Ross2002,Chang2013,Scanlon1998}. The displacement effect observed here thus constitutes a concrete instantiation of pluralist topology: an environmental shift that alters the manifold of moral reasons as a whole rather than modulating a single axis of moral evaluation.

It is important to emphasise that the field-level displacement effect demonstrated in 
the experiment does not contradict the presence of stable dispositional differences 
identified through our clustering analysis. The three psychometric clusters reflect 
distinct starting positions within the evaluative manifold—different dispositional 
orientations that shape how individuals ordinarily navigate moral contexts. However, 
the robotic perturbation operated not on these dispositional baselines but on the 
shared topological structure of the evaluative field itself. This is why all clusters, 
despite their psychological differences, exhibited the same directional attenuation in 
prosocial action. In pluralist topological terms, the robot alters the geometry of the 
manifold as a whole rather than modulating any single dispositional gradient. The 
cluster analysis and the displacement effect thus describe two complementary layers of 
moral cognition: stable trait-like orientations, and a context-sensitive evaluative 
field capable of being globally reshaped by environmental factors such as synthetic 
social presence.



\subsection{Integrative Ethical Interpretation of the Experimental Findings}

Bringing the reconstructed frameworks together, we can now articulate the ethical 
significance of the experimental results in a way that reflects both the normative 
pluralism developed earlier and the dual-layer structure of moral cognition revealed by 
the empirical findings. The donation attenuation produced by robotic presence does not 
reflect the modulation of a single moral principle, evaluative dimension, or 
dispositional trait. Rather, it arises from a global perturbation of the evaluative 
field in which diverse moral reasons are ordinarily weighed and integrated.

\begin{enumerate}
	\item \textbf{From a deontological perspective}, the robot weakens the felt presence of a 
	morally relevant observer and thereby attenuates the sense of duty-oriented 
	accountability that the Watching-Eye cue is designed to amplify. The displacement 
	effect represents a disruption of implicit normative expectations rather than a 
	violation of explicit moral rules.
	
	\item \textbf{From a consequentialist perspective}, the robot alters the perceived payoff 
	structure of helping behaviour by flattening the social-evaluative gradient. The 
	expected ``return'' of prosocial action—whether reputational, emotional, or 
	anticipatory—becomes less sharply defined, shifting the cost–benefit landscape in a 
	way that depresses altruistic output.
	
	\item \textbf{From a virtue-ethical perspective}, the perturbation does not target 
	trait-dependent motivational tendencies directly. Rather, it reveals that even 
	robust dispositional architectures (as captured in the three psychometric clusters) 
	can be globally displaced by contextual features that reshape the evaluative field 
	within which character expresses itself. The fact that all clusters show the same 
	behavioural shift indicates that virtue is not a self-contained driver of action, 
	but a gradient subject to field-level modulation.
	
	\item \textbf{From a contractualist perspective}, the robot disrupts the local 
	justificatory equilibrium by diminishing the perceived presence of agents to whom 
	reasons are owed. The justificatory landscape becomes noisier and less structured, 
	thereby reducing the motivational force of the requirement to ``act in ways that 
	others could not reasonably reject.''
	
	\item \textbf{From a particularist perspective}, the robot modifies the fine-grained 
	salience structure of the environment, reconfiguring which contextual features 
	become normatively operative. The eyes cue remains physically present, but its 
	moral traction is displaced by a new source of salience—an ambiguous agent whose 
	social meaning is not yet assimilated into the participant’s normative schema.
	
	\item \textbf{From a pluralist-topological perspective}, the findings are precisely what 
	we should expect when multiple normative gradients interact with a global 
	perturbation to social meaning. The donation attenuation is not the suppression of a 
	single moral principle; it is the displacement of the evaluative manifold itself. 
	This explains why no single theory—deontological, consequentialist, virtue-based, 
	contractualist, or particularist—captures the full phenomenon, and why the effect 
	persists across dispositional clusters.
\end{enumerate}

\noindent
Taken together, these interpretations converge on a unified thesis:

\begin{center}
	\begin{tcolorbox}[colback=white, colframe=black!60,
		title=Integrative Conclusion: The Ethical Signature of Moral Displacement]
		The presence of a humanoid robot reshapes the multi-dimensional evaluative 
		topology through which moral salience becomes action. This perturbation operates 
		at the level of the evaluative field, modulating deontic expectations, 
		consequentialist gradients, dispositional attractors, justificatory relations, 
		and contextual salience structures simultaneously. No monolithic ethical 
		framework captures the phenomenon. The experimental results therefore vindicate a 
		pluralist, topological, empirically grounded account of moral cognition—one that 
		reveals how synthetic agents can globally displace moral evaluation in ways 
		systematically overlooked by classical Machine Ethics.
	\end{tcolorbox}
\end{center}

\noindent
By reconstructing the major normative theories through LoA discipline and embedding 
them within a topologically structured model of moral cognition, this chapter provides 
the conceptual architecture required to understand the ethical significance of 
synthetic moral perturbation. The experiment that follows empirically demonstrates how 
such perturbation manifests as a field-level displacement effect, thereby linking the 
normative, psychological, and computational analyses into a unified account of how 
synthetic agents influence moral behaviour.

%%%THE END!