\chapter{ETHICAL COGNITION AND NORMATIVE FOUNDATIONS}
\label{chap:ethics_s}

\section{From Moral Cognition to Ethical Theory}
\addcontentsline{toc}{section}{Bridging Note: From Moral Cognition to Ethical Theory}

\noindent
The preceding chapter established three claims that structure the transition to the present discussion. 

First, moral judgments were analysed as \emph{first-order evaluative outputs}: context-sensitive assessments generated by the cognitive--affective architecture through which agents register morally salient features of their environment. These judgments are psychologically real, behaviourally tractable, and empirically measurable, but they are neither required to be internally consistent nor grounded in articulated principles. 

Second, we showed that such judgments arise from distributed processes---intuitive, affective, inferential, and regulatory---whose integration is sensitive to perturbations in the social and perceptual field. 

Third, the experimental work that follows relies on this architecture: what we measure are not abstract commitments but the \emph{practical expression} of moral cognition within environments made ambiguous by synthetic presence.

\noindent
The present chapter moves from these \emph{first-order phenomena} to the \emph{second-order frameworks} through which philosophers and psychologists, attempt to explain, justify, or discipline them. Whereas moral judgments are the data of moral life, \emph{ethics} is the systematic attempt to interpret that data: to uncover the principles, norms, and justificatory structures that purport to govern moral reasoning. Ethical theory is therefore reflexive in a way that moral cognition is not. It asks not merely \emph{What do agents judge?} but:

 \emph{What should count as a reason? How are obligations justified? What is the normative architecture that makes moral claims intelligible?} 
 
These questions operate at a different Level of Abstraction, and they require a different methodological apparatus.

\noindent
Seen from this perspective, the opening claim of this chapter---that classical ethical theory treats moral judgment as the outcome of structured deliberation---is not an empirical hypothesis but a \emph{second-order commitment}. It reflects the aspiration that normative authority arises from principled reasoning: the articulation of justifiable rules, duties, or values. Yet the Morality Primer revealed a systematic tension between this normative ideal and the empirical reality of moral cognition. Human agents rarely deliberate in the manner ethical theories presuppose; instead, their judgments emerge from perceptual salience, affective valuation, heuristics of social meaning, and dynamic integration across intuitive and deliberative systems. 

\noindent
The central task of this chapter, therefore, is to reconcile these levels: to examine whether, and under what constraints, ethical theory can remain normatively meaningful while respecting the psychological mechanisms through which moral judgments actually arise. 

Computing science, especially in domains such as Machine Ethics, Social Signal Processing, and Affective Computing, faces this tension acutely. It must model behaviour that is empirically grounded yet normatively interpretable, avoiding both the error of treating first-order outputs as if they were principled ethical commitments and the converse error of designing artificial agents around abstract principles that human agents do not in practice instantiate.  

\noindent
This dual demand---empirical fidelity and normative coherence---is the point of departure for what follows.


\section{Introduction: Why Ethics Needs Psychology (and Why Computing Science Needs Both)}

\noindent
Ethical theory, in its classical formulation, treats moral judgment as the outcome of structured deliberation: a process mediated by reasons, principles, and the articulation of normatively defensible positions. Yet this picture has long been recognised as descriptively incomplete. Human moral behaviour rarely emerges from extended reflection; rather, it unfolds through rapid, affectively mediated evaluations shaped by perception, context, and embodied interaction (see discussion in Chapter~\ref{chap:moral_primer}). The distance between what people \emph{ought} to do, what they \emph{think} they do, and what they \emph{actually} do is substantial. To understand moral action in practice—particularly in technologically saturated environments—ethical inquiry must therefore be coupled with the empirical machinery of moral psychology.

%%%

\noindent
For computing science, this coupling is not optional. Artificial agents are increasingly situated in social contexts where their presence, form, and behaviour modulate human inference, expectation, and decision-making. Fields such as \emph{Social Signal Processing}~\cite{Vinciarelli2009} and \emph{Affective Computing}~\cite{Picard1997} have already demonstrated that human social cognition is deeply sensitive to subtle cues: gaze, posture, micro-expressions, spatial orientation, and embodied co-presence. These cues structure the “interaction order”~\cite{Goffman1967} within which humans interpret intention, assign agency, and evaluate normatively significant behaviour. When synthetic systems enter this order, they perturb it—not through explicit commands, but by altering the informational and affective landscape in which human cognition operates.

\noindent
This thesis proceeds from the premise that \emph{ethical behaviour cannot be understood without moral psychology}, and that \emph{moral psychology cannot be operationalised within computing science without an account of social signals and affective processes}. Moral action is not reducible to computation over explicit propositions; it is embedded in a situated cognitive ecology shaped by embodied agents, environmental cues, and rapidly deployed intuitive processes.

\noindent
The central claim developed across the thesis is that \emph{moral behaviour is systematically sensitive to the structure of the immediate perceptual–social environment}. This is not merely a theoretical commitment but the empirical hypothesis that the experimental chapter will interrogate: if moral cognition is dynamically shaped by intuitive appraisals, attentional salience, and affective resonance, then even a silent, behaviourally neutral synthetic presence can modulate the trajectory from moral perception to moral action. The results previewed later in the thesis provide convergent evidence for this claim, showing that robotic co-presence can \emph{attenuate} prosocial donation despite the presence of a strong moral cue (the Watching-Eye stimulus).

\noindent
Framed through the lens of ethical theory, the foregoing claim has deeper implications. Ethics, as understood in contemporary philosophy, is a \textit{second-order discipline}: it does not produce moral judgments, but seeks to analyse, justify, or critique them \cite{Scanlon1998, Darwall2006, Audi2015}. It examines the \emph{structure} of reasons, obligations, and values, not the psychological mechanisms that generate first-order moral appraisals. The field of Machine Ethics has historically blurred this distinction. By attempting to \textbf{engineer} “ethical agents” directly at the level of second-order principles—rule sets, deontic logics, utility functions—it tacitly presumes that moral behaviour can be derived from explicit normative propositions \cite{Moor2006, Anderson2011}. This presumption is philosophically naïve and empirically untenable. It treats ethics as if it were a generative model of behaviour, rather than a reflective framework that presupposes the very psychological capacities it seeks to evaluate. In doing so, classical Machine Ethics mistakes the normative \emph{grammar} of moral theory for the mechanistic \emph{causality} of moral cognition.

\noindent
The argument developed in this thesis directly challenges this assumption. If moral action is shaped primarily by perceptual salience, intuitive appraisal, affective resonance, and the dynamics of social attention—as the experimental results later confirm—then second-order normative structures cannot be treated as the proximate drivers of behaviour. They are interpretive and justificatory, \textit{not computationally generative}. 

This insight reframes the goal of what I call \textit{Computational Morality}: rather than embedding ethical theories into machines, we must first understand the cognitive–affective machinery that underwrites human moral responsiveness, and only then determine what ethical oversight or normative constraints are appropriate. Classical Machine Ethics inverted this order; the empirical findings of this thesis re-establish it.

\noindent
At the same time, the scope of this chapter is deliberately circumscribed. It does not attempt a comprehensive reconstruction of moral philosophy, nor does it pursue the full normative debates surrounding moral realism, contractualism, utilitarianism, or virtue theory. Such an undertaking would exceed the remit of an empirical thesis. Instead, the chapter isolates the conceptual and mechanistic structures necessary for the remainder of the work: how ethical theory relies on assumptions about moral judgment, how moral judgment is psychologically realised, and why any account of ethical behaviour in computational settings must be anchored in the empirical architecture of moral cognition. The goal is thus foundational rather than encyclopaedic: to articulate the theoretical substrate that motivates, constrains, and ultimately validates the experimental investigation that follows.

As such, the integration of ethical theory, psychological insight, and computational modelling is not merely interdisciplinary ambition—it is a methodological necessity.

\noindent
In the chapters that follow, we develop this integration along three axes. First, we introduce foundational ethical concepts—deontic, consequentialist, and virtue-theoretic—that define the normative landscape in which moral behaviour is interpreted. Second, we examine the empirical architecture of moral cognition, with emphasis on intuitionist and dual-process models~\cite{Haidt2001, Greene2001, Cushman2013} that capture the rapid, affectively-driven nature of everyday moral judgment. Third, we link these philosophical and psychological constructs to the computational disciplines that analyse social behaviour—most notably Social Signal Processing and Affective Computing—thereby establishing a unified framework for studying ethical decision-making in environments populated by artificial agents.

\noindent
This synthesis prepares the conceptual ground for the experimental investigation at the heart of this thesis. The manipulation of robotic co-presence, the use of moral primes such as the Watching Eye stimulus, and the measurement of prosocial donation are not methodological curiosities: they are principled probes into the cognitive machinery through which moral cues acquire behavioural force. By integrating ethics, psychology, and computational social science, this chapter equips the reader with the normative and conceptual tools required to understand how—and why—synthetic presence can reshape the moral topology of human decision-making.

\label{sec:test}

%%% CHUNCK 2

\section{Ethical Theory as Second-Order Analysis}
\label{sec:second_order_ethics}

\noindent
If the introductory sections of this chapter establish the transition from first-order moral cognition to second-order normative reflection, the next task is to make explicit the methodological consequences of this shift. The distinction is not merely terminological. It determines which claims are explanatory, which are justificatory, and which are subject to empirical constraint. Failure to maintain this distinction has led to recurring conceptual errors in both philosophical ethics and computational modelling. This section therefore articulates a principled account of what second-order ethical theory \emph{is}, what it \emph{explains}, and what it \emph{cannot} plausibly do.

\subsection{Ethical Reflection and the Second-Order Stance}

\noindent
First-order moral judgments arise from the cognitive--affective processes analysed in the Morality Primer. They are psychologically realised, context-sensitive, and behaviourally measurable. Their structure reflects the architecture of moral cognition: operations on perceptual salience, affective intuitions, social meaning, and regulated deliberation. These are the \emph{phenomena} that ethical theory seeks to interpret.

Second-order ethical theory is structurally different. It is reflexive rather than generative. It asks: What counts as a reason? What makes an obligation binding? What is the source of justificatory authority? These questions presuppose capacities for abstraction, generalisation, and rational evaluation that are not themselves the proximate causal mechanisms of moral behaviour. Sidgwick already insisted on this point in \emph{The Methods of Ethics}, where he distinguished between the psychology of moral sentiments and the ``\emph{method} of determining right conduct'' \cite[Book~I]{SidgwickMethods}. Lemos's treatment of epistemic justification exhibits a similar structural separation between doxastic psychology and the normative assessment of belief \cite{Lemos2007}. The parallel here is instructive: ethics stands to moral judgment as epistemology stands to belief-formation.

Seen from this perspective, second-order theory is not a set of instructions that moral agents follow in producing judgments. It is a framework for articulating the standards by which judgments are evaluated. It makes explicit the \emph{normative architecture} that is only tacitly present in first-order moral life. Its success therefore depends on conceptual clarity and justificatory coherence, not on behavioural predictiveness.

\subsection{Levels of Abstraction and the Proper Location of Ethical Explanation}

\noindent
The preceding distinction can be clarified using Floridi's notion of \emph{Levels of Abstraction} (LoA) \cite{Floridi2011}. Every description of a phenomenon implicitly selects a vantage point: a set of observables, a resolution, and a granularity. Moral cognition and ethical theory operate at different LoAs.

At the \textbf{cognitive LoA}, the relevant variables include:
\begin{itemize}
	\item perceptual salience,
	\item affective valuation,
	\item attentional dynamics,
	\item intuitive heuristics,
	\item controlled modulation.
\end{itemize}

At the \textbf{normative LoA}, the relevant variables include:
\begin{itemize}
	\item principles of justification,
	\item conceptions of duty and value,
	\item constraints on admissible reasons,
	\item structural norms governing deliberation.
\end{itemize}

The methodological error of classical Machine Ethics was an LoA confusion: normative concepts were implemented as if they directly generated behaviour. This amounts to treating the normative LoA as if it were a computational or implementational LoA. The resulting systems operationalised deontic rules, utility functions, or virtue labels under the assumption that these abstractions could causally determine action. Yet, as the empirical architecture of moral cognition reveals, such concepts do not function as behavioural operators.

Thus, LoA discipline is essential: explanations must occur at the LoA appropriate to their aims. Ethical theory must remain a second-order reflective enterprise; computational models of behaviour must operate at the first-order cognitive LoA. The points of interaction between these layers require careful analysis, not naïve reduction.

\subsection{Evaluative Topology as a Bridge Between Orders}

\noindent
The challenge, then, is not to collapse first-order cognition into second-order theory, but to articulate a structure that allows principled interaction between them. \emph{Evaluative topology}, introduced in the Morality Primer and developed in subsequent chapters, provides such a structure.

Evaluative topology treats the moral field as a dynamic configuration of:
\begin{itemize}
	\item salience gradients,
	\item affective attractors,
	\item attentional pathways,
	\item normative deformations,
	\item and perturbations induced by social or synthetic presence.
\end{itemize}

Unlike traditional ethical theory, which specifies norms abstractly, evaluative topology describes how evaluative forces shape the trajectory from perception to action. Unlike psychological models, which emphasise mechanism, topology captures the relational and structural properties of moral appraisal.

This is precisely the level at which first- and second-order analyses can be reconciled:
\begin{enumerate}
	\item Ethical theory identifies which evaluative configurations \emph{ought} to have normative authority.
	\item Moral psychology identifies which configurations actually \emph{govern} behaviour.
	\item Evaluative topology identifies how these structures interact and when they diverge.
\end{enumerate}

This tripartite structure enables the central thesis of this chapter: ethical theory remains normatively meaningful only if it respects the psychological architecture through which moral judgments arise and the topological constraints that shape their development. Conversely, psychological models become ethically interpretable only when situated within a justified evaluative topology.

\bigskip

\section{The Normative Landscape: Structuring Ethical Theories Through LoA and Topology}
\label{sec:normative_landscape}

\noindent
With the methodological groundwork established, we can now introduce the main normative frameworks that structure the philosophical landscape. This section does not attempt a comprehensive exposition of each theory. Instead, it reconstructs them at a level appropriate to the aims of the thesis: identifying how each theory positions the source of normativity, the mode of evaluation, and the mechanism of action-guidance. This reconstruction is constrained by two methodological requirements:

\begin{enumerate}
	\item It must preserve the conceptual integrity of the theories as they appear in the philosophical literature.
	\item It must express them in a form that allows integration with the architecture of moral cognition and evaluative topology.
\end{enumerate}

The following subsections introduce this framework. In later sections, each theory is examined in depth.

\subsection{The Three Dimensions of Normative Analysis}

\noindent
Normative theories differ not merely in their prescriptions but in the \emph{structure} of normativity they posit. For analytical clarity, we distinguish three dimensions, each corresponding to a distinct aspect of evaluative topology and LoA:

\begin{enumerate}
	\item \textbf{Source of Normativity}: where justificatory authority originates.\\
	Examples include rational agency (Kant), human flourishing (Aristotle), aggregated welfare (Mill, Sidgwick), and affective sentiment (Hume).
	
	\item \textbf{Mode of Evaluation}: what aspects of action or character are morally relevant.\\
	These include maxims, consequences, virtues, motives, or relational duties.
	
	\item \textbf{Action-Guidance Mechanism}: how evaluations translate into behaviour.\\
	Mechanisms include categorical imperatives, utilitarian calculation, perceptual sensitivity to salience, or contract-based justification.
\end{enumerate}

Mapping classical theories onto these axes allows us to see how each defines a distinct \emph{evaluative topology}:
\begin{itemize}
	\item Kantian ethics imposes strict deontic invariants that constrain permissible trajectories.
	\item Consequentialism defines a gradient field over outcomes, where action follows steepest ascent.
	\item Virtue ethics defines attractors corresponding to stable dispositional patterns.
	\item Sentimentalism defines affective resonance networks that modulate evaluative flow.
	\item Contractualism defines justificatory equilibria among mutually recognisable claims.
	\item Particularism rejects fixed evaluative structures, treating topology as fully context-dependent.
\end{itemize}

\subsection{Why This Framework Matters for the Experimental Chapter}

\noindent
This structured taxonomy is not an intellectual exercise. It is the conceptual apparatus that connects ethical theory to the empirical investigation of synthetic presence. The experiment relies on three claims derived from this framework:

\begin{enumerate}
	\item Moral action depends on the topology of salience, affect, and social meaning.
	\item Synthetic presence---silent, behaviourally neutral, ontologically ambiguous---modulates this topology by perturbing social attention and perceived evaluation.
	\item Classical ethical theories must be reinterpreted in topological and cognitive terms if they are to illuminate these modulations.
\end{enumerate}

This sets the stage for the next phase of the chapter: a reconstruction of deontology, consequentialism, virtue ethics, sentimentalism, contractualism, and particularism as \emph{evaluative topologies} embedded within the psychological architecture of moral cognition.

\bigskip

\noindent
With these foundations in place, the chapter now turns to the first major normative framework: deontological ethics and the architecture of practical reason.

