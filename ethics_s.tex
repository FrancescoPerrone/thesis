\chapter{ETHICAL COGNITION AND NORMATIVE FOUNDATIONS}
\label{chap:ethics_s}

\section{From Moral Cognition to Ethical Theory}
\addcontentsline{toc}{section}{Bridging Note: From Moral Cognition to Ethical Theory}

\noindent
The preceding chapter established three claims that structure the transition to the present discussion. 

First, moral judgments were analysed as \emph{first-order evaluative outputs}: context-sensitive assessments generated by the cognitive--affective architecture through which agents register morally salient features of their environment. These judgments are psychologically real, behaviourally tractable, and empirically measurable, but they are neither required to be internally consistent nor grounded in articulated principles. 

Second, we showed that such judgments arise from distributed processes---intuitive, affective, inferential, and regulatory---whose integration is sensitive to perturbations in the social and perceptual field. 

Third, the experimental work that follows relies on this architecture: what we measure are not abstract commitments but the \emph{practical expression} of moral cognition within environments made ambiguous by synthetic presence.

\noindent
The present chapter moves from these \emph{first-order phenomena} to the \emph{second-order frameworks} through which philosophers and psychologists, attempt to explain, justify, or discipline them. Whereas moral judgments are the data of moral life, \emph{ethics} is the systematic attempt to interpret that data: to uncover the principles, norms, and justificatory structures that purport to govern moral reasoning. Ethical theory is therefore reflexive in a way that moral cognition is not. It asks not merely \emph{What do agents judge?} but:

 \emph{What should count as a reason? How are obligations justified? What is the normative architecture that makes moral claims intelligible?} 
 
These questions operate at a different Level of Abstraction, and they require a different methodological apparatus.

\noindent
Seen from this perspective, the opening claim of this chapter---that classical ethical theory treats moral judgment as the outcome of structured deliberation---is not an empirical hypothesis but a \emph{second-order commitment}. It reflects the aspiration that normative authority arises from principled reasoning: the articulation of justifiable rules, duties, or values. Yet the Morality Primer revealed a systematic tension between this normative ideal and the empirical reality of moral cognition. Human agents rarely deliberate in the manner ethical theories presuppose; instead, their judgments emerge from perceptual salience, affective valuation, heuristics of social meaning, and dynamic integration across intuitive and deliberative systems. 

\noindent
The central task of this chapter, therefore, is to reconcile these levels: to examine whether, and under what constraints, ethical theory can remain normatively meaningful while respecting the psychological mechanisms through which moral judgments actually arise. 

Computing science, especially in domains such as Machine Ethics, Social Signal Processing, and Affective Computing, faces this tension acutely. It must model behaviour that is empirically grounded yet normatively interpretable, avoiding both the error of treating first-order outputs as if they were principled ethical commitments and the converse error of designing artificial agents around abstract principles that human agents do not in practice instantiate.  

\noindent
This dual demand---empirical fidelity and normative coherence---is the point of departure for what follows.


\section{Introduction: Why Ethics Needs Psychology (and Why Computing Science Needs Both)}

\noindent
Ethical theory, in its classical formulation, treats moral judgment as the outcome of structured deliberation: a process mediated by reasons, principles, and the articulation of normatively defensible positions. Yet this picture has long been recognised as descriptively incomplete. Human moral behaviour rarely emerges from extended reflection; rather, it unfolds through rapid, affectively mediated evaluations shaped by perception, context, and embodied interaction (see discussion in Chapter~\ref{chap:moral_primer}). The distance between what people \emph{ought} to do, what they \emph{think} they do, and what they \emph{actually} do is substantial. To understand moral action in practice—particularly in technologically saturated environments—ethical inquiry must therefore be coupled with the empirical machinery of moral psychology.

%%%

\noindent
For computing science, this coupling is not optional. Artificial agents are increasingly situated in social contexts where their presence, form, and behaviour modulate human inference, expectation, and decision-making. Fields such as \emph{Social Signal Processing}~\cite{Vinciarelli2009} and \emph{Affective Computing}~\cite{Picard1997} have already demonstrated that human social cognition is deeply sensitive to subtle cues: gaze, posture, micro-expressions, spatial orientation, and embodied co-presence. These cues structure the “interaction order”~\cite{Goffman1967} within which humans interpret intention, assign agency, and evaluate normatively significant behaviour. When synthetic systems enter this order, they perturb it—not through explicit commands, but by altering the informational and affective landscape in which human cognition operates.

\noindent
This thesis proceeds from the premise that \emph{ethical behaviour cannot be understood without moral psychology}, and that \emph{moral psychology cannot be operationalised within computing science without an account of social signals and affective processes}. Moral action is not reducible to computation over explicit propositions; it is embedded in a situated cognitive ecology shaped by embodied agents, environmental cues, and rapidly deployed intuitive processes.

\noindent
The central claim developed across the thesis is that \emph{moral behaviour is systematically sensitive to the structure of the immediate perceptual–social environment}. This is not merely a theoretical commitment but the empirical hypothesis that the experimental chapter will interrogate: if moral cognition is dynamically shaped by intuitive appraisals, attentional salience, and affective resonance, then even a silent, behaviourally neutral synthetic presence can modulate the trajectory from moral perception to moral action. The results previewed later in the thesis provide convergent evidence for this claim, showing that robotic co-presence can \emph{attenuate} prosocial donation despite the presence of a strong moral cue (the Watching-Eye stimulus).

\noindent
Framed through the lens of ethical theory, the foregoing claim has deeper implications. Ethics, as understood in contemporary philosophy, is a \textit{second-order discipline}: it does not produce moral judgments, but seeks to analyse, justify, or critique them \cite{Scanlon1998, Darwall2006, Audi2015}. It examines the \emph{structure} of reasons, obligations, and values, not the psychological mechanisms that generate first-order moral appraisals. The field of Machine Ethics has historically blurred this distinction. By attempting to \textbf{engineer} “ethical agents” directly at the level of second-order principles—rule sets, deontic logics, utility functions—it tacitly presumes that moral behaviour can be derived from explicit normative propositions \cite{Moor2006, Anderson2011}. This presumption is philosophically naïve and empirically untenable. It treats ethics as if it were a generative model of behaviour, rather than a reflective framework that presupposes the very psychological capacities it seeks to evaluate. In doing so, classical Machine Ethics mistakes the normative \emph{grammar} of moral theory for the mechanistic \emph{causality} of moral cognition.

\noindent
The argument developed in this thesis directly challenges this assumption. If moral action is shaped primarily by perceptual salience, intuitive appraisal, affective resonance, and the dynamics of social attention—as the experimental results later confirm—then second-order normative structures cannot be treated as the proximate drivers of behaviour. They are interpretive and justificatory, \textit{not computationally generative}. 

This insight reframes the goal of what I call \textit{Computational Morality}: rather than embedding ethical theories into machines, we must first understand the cognitive–affective machinery that underwrites human moral responsiveness, and only then determine what ethical oversight or normative constraints are appropriate. Classical Machine Ethics inverted this order; the empirical findings of this thesis re-establish it.

\noindent
At the same time, the scope of this chapter is deliberately circumscribed. It does not attempt a comprehensive reconstruction of moral philosophy, nor does it pursue the full normative debates surrounding moral realism, contractualism, utilitarianism, or virtue theory. Such an undertaking would exceed the remit of an empirical thesis. Instead, the chapter isolates the conceptual and mechanistic structures necessary for the remainder of the work: how ethical theory relies on assumptions about moral judgment, how moral judgment is psychologically realised, and why any account of ethical behaviour in computational settings must be anchored in the empirical architecture of moral cognition. The goal is thus foundational rather than encyclopaedic: to articulate the theoretical substrate that motivates, constrains, and ultimately validates the experimental investigation that follows.

As such, the integration of ethical theory, psychological insight, and computational modelling is not merely interdisciplinary ambition—it is a methodological necessity.

\noindent
In the chapters that follow, we develop this integration along three axes. First, we introduce foundational ethical concepts—deontic, consequentialist, and virtue-theoretic—that define the normative landscape in which moral behaviour is interpreted. Second, we examine the empirical architecture of moral cognition, with emphasis on intuitionist and dual-process models~\cite{Haidt2001, Greene2001, Cushman2013} that capture the rapid, affectively-driven nature of everyday moral judgment. Third, we link these philosophical and psychological constructs to the computational disciplines that analyse social behaviour—most notably Social Signal Processing and Affective Computing—thereby establishing a unified framework for studying ethical decision-making in environments populated by artificial agents.

\noindent
This synthesis prepares the conceptual ground for the experimental investigation at the heart of this thesis. The manipulation of robotic co-presence, the use of moral primes such as the Watching Eye stimulus, and the measurement of prosocial donation are not methodological curiosities: they are principled probes into the cognitive machinery through which moral cues acquire behavioural force. By integrating ethics, psychology, and computational social science, this chapter equips the reader with the normative and conceptual tools required to understand how—and why—synthetic presence can reshape the moral topology of human decision-making.

\label{sec:test}

%%% CHUNCK 2

\section{Ethical Theory as Second-Order Analysis}
\label{sec:second_order_ethics}

\noindent
If the introductory sections of this chapter establish the transition from first-order moral cognition to second-order normative reflection, the next task is to make explicit the methodological consequences of this shift. The distinction is not merely terminological. It determines which claims are explanatory, which are justificatory, and which are subject to empirical constraint. Failure to maintain this distinction has led to recurring conceptual errors in both philosophical ethics and computational modelling~\cite{Black1972,Hare1981,Hempel1965,Floridi2008,Moor2006,FloridiSanders2004,McLaren2006,Coeckelbergh2023}. This section therefore articulates a principled account of what second-order ethical theory \emph{is}, what it \emph{explains}, and what it \emph{cannot} plausibly do.

\subsection{Ethical Reflection and the Second-Order Stance}

\noindent
First-order moral judgments arise from the cognitive--affective processes analysed in the Morality Primer. They are psychologically realised, context-sensitive, and behaviourally measurable. Their structure reflects the architecture of moral cognition: operations on perceptual salience, affective intuitions, social meaning, and regulated deliberation. These are the \emph{phenomena} that ethical theory seeks to interpret.

Second-order ethical theory is structurally different. It is reflexive rather than generative. It asks: What counts as a reason? What makes an obligation binding? What is the source of justificatory authority? These questions presuppose capacities for abstraction, generalisation, and rational evaluation that are not themselves the proximate causal mechanisms of moral behaviour~\cite{Haidt2001,Greene2001,Young2012,Kohlberg1969,Narvaez2005,Kahneman2011,Baumeister2010}. Sidgwick already insisted on this point in \emph{The Methods of Ethics}, where he distinguished between the psychology of moral sentiments and the ``\emph{method} of determining right conduct'' \cite[Book~I]{SidgwickMethods}. Lemos's treatment of epistemic justification exhibits a similar structural separation between doxastic psychology and the normative assessment of belief \cite{Lemos2020}. The parallel here is instructive: ethics stands to moral judgment as epistemology stands to belief-formation.

Seen from this perspective, second-order theory is not a set of instructions that moral agents follow in producing judgments. It is a framework for articulating the standards by which judgments are evaluated. It makes explicit the \emph{normative architecture} that is only tacitly present in first-order moral life. Its success therefore depends on conceptual clarity and justificatory coherence, not on behavioural predictiveness.

\subsection{Levels of Abstraction and the Proper Location of Ethical Explanation}

\noindent
The distinction between first-order moral cognition and second-order ethical theory can be sharpened through Floridi’s framework of \emph{Levels of Abstraction} (LoA) \cite{Floridi2008, Floridi2010}. On this account, every explanatory enterprise selects a perspective defined by its observables, its conceptual resolution, and the class of questions it is equipped to answer. Moral cognition and ethical theory do not merely operate at different LoAs—they answer \emph{different kinds of questions} and employ \emph{different explanatory primitives}.

\medskip

At the \textbf{cognitive LoA}, the relevant variables are those that govern the generation of moral judgments in real time:
\begin{itemize}
	\item perceptual salience and attentional capture,
	\item affective appraisal and embodied valuation,
	\item intuitive heuristics and rapid social inferences,
	\item controlled modulation under conflict or uncertainty,
	\item the temporal dynamics by which these processes integrate.
\end{itemize}
These are mechanistic, psychologically instantiated processes. They have causal influence on behaviour and can be perturbed by contextual or environmental changes. \emph{This is the LoA at which the experimental work of this thesis operates.}

\medskip

At the \textbf{normative LoA}, by contrast, the objects of analysis are:
\begin{itemize}
	\item principles of justification,
	\item conceptions of duty, value, and obligation,
	\item standards of admissible reasons,
	\item structural norms governing deliberation, agency, and responsibility.
\end{itemize}
These are not causal operators but \emph{interpretive} and \emph{justificatory} constructs. They evaluate, discipline, or systematise moral claims but do not themselves generate behaviour. Ethical theory is reflexive: it examines the grammar of reasons, not the mechanisms of cognition.

\medskip

\noindent
\textbf{Classical Machine Ethics collapsed these LoAs.}  
By treating principles, rules, or utility structures as if they were mechanistic generative elements, it implicitly assumed that normative constructs function like cognitive processes. This assumption is doubly mistaken:

\begin{enumerate}
	\item It attributes to normative concepts a causal role they do not possess: ethical duties do not operate like perceptual salience or affective appraisal.
	\item It ignores the empirical architecture of moral cognition, which shows that behaviour emerges from intuitive, affective, and situational dynamics long before explicit reasoning is engaged.
\end{enumerate}

From the perspective developed across this thesis, such an approach is not merely incomplete; it is methodologically incoherent. It attempts to engineer behaviour by manipulating abstractions at a LoA that is \emph{not behaviourally operative}.

\medskip

\noindent
\textbf{LoA discipline therefore becomes a philosophical and methodological necessity.}  
Explanations of behaviour must occur at the cognitive LoA; evaluations of reasons and principles must occur at the normative LoA. Neither can be reduced to the other. Crucially, however, the two LoAs are not independent: normative evaluation presupposes an underlying psychology capable of generating moral sensitivity and action, while psychological findings constrain the plausibility of normative theories.

\medskip

This interdependence is the key insight that links this chapter to the preceding Morality Primer and to the experimental chapter that follows. The Primer established that the cognitive LoA is \emph{topologically structured}: moral cognition involves the continual reshaping of an evaluative field whose gradients are determined by affective cues, attentional dynamics, and social interpretive processes. Perturbations to this field—whether by altering salience, modifying affective tone, or introducing ambiguous social presence—can shift the system’s behavioural trajectory even when normative commitments remain unchanged.

\medskip

\noindent
Seen through the LoA framework, the core question of this thesis can now be reformulated with greater precision:  
\emph{How do normative expectations, psychological mechanisms, and environmental structures jointly determine the transition from moral perception to moral action?}

\medskip

This question cannot be answered by ethical theory alone, nor by psychology in isolation. It requires a representational structure capable of linking the causal architecture of moral cognition (first-order) with the justificatory architecture of ethical evaluation (second-order). The remainder of this chapter argues that \textbf{evaluative topology}---introduced in the Morality Primer and returned to throughout the thesis---provides precisely such a bridge.

Classical Machine Ethics provides a clear illustration of the dangers of LoA confusion. A recurring methodological assumption in early systems was that normative concepts themselves—obligations, duties, utilities, or virtues—could be implemented at the computational LoA and thereby function as direct generators of behaviour. Early top-down approaches treated ethical theory as if its abstractions could be operationalised without remainder. For example, Arkin’s “ethical governor” encoded deontological constraints derived from Just War Theory as behavioural regulators \cite{Arkin2009}; Anderson and Anderson’s principlist architectures computationalised Rossian prima facie duties as decision rules \cite{Anderson2007,Anderson2011}; and logic-based approaches by Bringsjord and colleagues modelled deontic operators as executable action-selection mechanisms \cite{Bringsjord2006,Ganascia2007}. Parallel lines of work assumed that utility functions could serve as moral evaluators in consequentialist agents \cite{Abel2016,Arkin2009}, while virtue-theoretic systems attempted to reify character traits as algorithmic dispositions governing moral performance \cite{Powers2006,Thornton2013}. In all these cases, normative structures were treated as if they occupied the same LoA as the cognitive mechanisms responsible for actual moral behaviour. 

Floridi’s LoA framework clarifies why such reductions are unsustainable: normative categories belong to a reflective, second-order LoA concerned with justification, whereas computational models operate at an implementational LoA concerned with causal processes. Conflating the two not only mischaracterises the role of normative theory but also yields systems whose behavioural outputs are artefacts of representational choices rather than genuine ethical competence.

\subsection{Evaluative Topology as a Bridge Between Orders}

\noindent
The challenge, then, is not to collapse first-order cognition into second-order theory, but to articulate a structure that permits principled interaction between them without confusing their explanatory roles. \emph{Evaluative topology}, introduced in the Morality Primer (Chapter~\ref{chap:moral_primer}) and returned to throughout this thesis (see Chapter~\ref{chap:experimental_methods}), provides precisely such a structure.

%%%
Evaluative topology can be naturally situated within a long-standing tradition in computational cognitive science that conceptualises perception, valuation, and action as parts of continuous, dynamical systems rather than discrete symbolic modules. Research in moral psychology already demonstrates that moral cognition emerges from distributed interactions between perceptual salience, affective appraisal, attentional dynamics, and context-sensitive social meaning. Empirical models—from Haidt’s social intuitionism to Greene’s dual-process account—show that moral perception is shaped by multi-dimensional affective and social fields rather than rule-based computations \cite{Haidt2001,Greene2001,Young2012}. Neurocognitive analyses extend this point: Nussbaum’s and Churchland’s treatments of emotion as evaluative perception imply a graded, vector-like structure underlying moral appraisals \cite{Nussbaum2001,Churchland2011}. Likewise, work in social signal processing models interpersonal evaluation as a shifting landscape of cues that modulate behavioural trajectories in real time \cite{Pentland2007}.

Against this background, evaluative topology provides a computationally meaningful formalisation: it treats the moral landscape as a dynamic field that shapes the flow from perceptual input to action readiness. Instead of assuming that behavior results from the application of discrete maxims or utility scores, evaluative topology models moral cognition as continuous transformations across a structured state-space. This aligns with dynamical-systems approaches in cognitive science that explain action selection through attractors, gradients of salience, and field-like organisation rather than propositional inference. The topology encodes the shape of the evaluative field—the stability of certain trajectories, the resistance of others, and the way local variations in perceptual or affective input can redirect the subject toward different moral outcomes.

By locating moral appraisal within a dynamic state-space, evaluative topology offers a principled bridge between first-order moral cognition and second-order ethical theory. It is sensitive to the empirical architecture of human cognition—distributed, affectively grounded, context-responsive—while remaining compatible with the reflective, justificatory concerns of ethical theory. It thus becomes possible to characterise the points of interaction between descriptive and normative orders without reducing one to the other: normative theory shapes the global constraints and evaluative contours within which first-order processes operate, while first-order processes provide the empirical basis upon which second-order theorising must reflect.
%%%

\medskip
At its core, evaluative topology treats the moral landscape not as a set of discrete judgments or isolated principles, but as a \emph{dynamic field} whose configuration determines the pathways through which perception becomes moral action~\cite{Haidt2001,Greene2001,Churchland2011,Young2012,Nussbaum2001,Narvaez2005}
. Its explanatory primitives include:

\begin{itemize}
	\item \textbf{salience gradients}: patterns of perceptual and affective prominence,
	\item \textbf{affective attractors}: regions of the evaluative field toward which intuitive appraisal rapidly converges,
	\item \textbf{attentional pathways}: trajectories through which cognitive resources flow,
	\item \textbf{normative deformations}: structural constraints introduced by commitments, duties, or normative expectations,
	\item \textbf{social or synthetic perturbations}: distortions induced by the presence of other agents---including artificial ones.
\end{itemize}

\noindent
Unlike classical ethical theory, which specifies norms at an abstract and often idealised level~\cite{SidgwickMethods,Rawls2020,Mill1861,Korsgaard2009,Scanlon1998}
, evaluative topology is sensitive to the \emph{real-time architecture} of moral cognition. And unlike purely mechanistic models in psychology, which describe causal processes but lack normative structure, topology captures the relational, structural, and counterfactual properties of moral appraisal~\cite{Haidt2001,Greene2001,Young2012,Narvaez2005,SidgwickMethods,Scanlon1998,Korsgaard2009}
: how evaluative trajectories \emph{could} unfold under alternative configurations of salience, affect, or context.

\medskip

This topological approach thus identifies the precise level at which first-order and second-order analyses intersect. It supports the following alignment:

\begin{enumerate}
	\item \textbf{Ethical theory} identifies which evaluative configurations \emph{ought} to have normative authority.
	\item \textbf{Moral psychology} identifies which configurations \emph{do} govern actual behaviour.
	\item \textbf{Evaluative topology} identifies how these structures interact, when they diverge, and how they can be perturbed.
\end{enumerate}

\noindent
This tripartite structure yields both a diagnostic and a constructive insight. Diagnostically, it clarifies why many classical models in Machine Ethics failed: they attempted to engineer behaviour by manipulating abstractions at a normative LoA, ignoring the topological organisation of the cognitive LoA through which behaviour actually emerges. Constructively, it shows how normative analysis can be anchored in a psychologically realistic substrate without reducing ethics to psychology or cognition to normativity.

\medskip

\paragraph{Topological Consequences for Moral Perturbation.}
The Morality Primer established that moral behaviour emerges from the traversal of a dynamically shaped evaluative field. Within this framework, \emph{perturbation} has a precise and measurable meaning: any alteration that changes the curvature, gradients, or attractor structure of the field will shift the probability distribution over behavioural trajectories. This is true whether the perturbation arises from shifts in salience, affective modulation, attentional competition, or the introduction of a new agent into the interaction ecology.

A synthetic presence---perceptually social yet ontologically indeterminate---is therefore not merely an “observer” but a topological operator. It changes the field in which moral meaning becomes behaviourally operative. This was the central theoretical insight that shaped the experimental design: by embedding a morally charged cue (the Watching-Eye stimulus) within a field perturbed by a humanoid robot, we could test whether subtle topological deformation is sufficient to attenuate prosocial behaviour.

\medskip

\paragraph{Interim Synthesis: Where the Chapter Now Stands.}
The conceptual architecture developed thus far establishes the conditions for experimental design (Chapter~\ref{chap:experimental_methods}):

\begin{itemize}
	\item First, moral judgment operates at the cognitive LoA through dynamic, affectively responsive, socially sensitive processes.
	\item Second, ethical theory operates at the normative LoA, providing justificatory structures but not generative mechanisms.
	\item Third, evaluative topology provides the bridge between these orders by modelling the structural constraints and transformations that govern the transition from moral perception to moral action.
	\item Fourth, this bridge is indispensable for understanding how synthetic agents perturb human moral behaviour.
\end{itemize}

\noindent
We are therefore equipped to proceed. With the methodological scaffolding in place, we can now introduce the major normative theories not as abstract philosophical positions but as structured attempts to locate sources of normativity within the evaluative field. Their reconstruction in the next section is guided by the LoA discipline established above and constrained by the topological account of moral cognition developed throughout this thesis.

\noindent
Before turning to the main normative traditions, it is important to clarify \emph{why} this reconstruction is required within the architecture of the thesis. The experimental work developed later does not simply measure behavioural differences; it interrogates a deeper question concerning the \emph{normative interpretation} of those differences. If robotic co-presence reshapes the evaluative topology through which moral salience becomes action, then any claim about the ethical significance of this perturbation---whether it constitutes a moral cost, a distortion, or a benign behavioural shift---presupposes a framework for understanding how normativity itself is structured. Without situating the experiment within a landscape of ethical theories, one could describe \emph{what} changes but not \emph{what the change means}. 

\noindent
The purpose of the next section, therefore, is not to provide a survey of moral philosophy, but to identify the minimal normative scaffolding required to make sense of the empirical findings. Deontic, consequentialist, and virtue-theoretic perspectives articulate distinct accounts of (i) where normative authority resides, (ii) how moral relevance is determined, and (iii) how action-guidance is understood. These differences matter directly for the thesis: each theory yields a different interpretation of what it means for synthetic presence to attenuate prosocial behaviour. By reconstructing these normative architectures through the lens of Levels of Abstraction and evaluative topology, we prepare the conceptual ground for assessing the ethical significance of the perturbation demonstrated experimentally.

\noindent
What follows, then, is not philosophical ornamentation but a methodological necessity: establishing the normative coordinates that will allow the later empirical results to be interpreted, evaluated, and ultimately situated within a defensible ethical framework.



\section{The Normative Landscape: Structuring Ethical Theories Through LoA and Topology}
\label{sec:normative_landscape}

\noindent
With the methodological scaffolding now in place, we can introduce the major normative frameworks that constitute the philosophical backdrop against which the experimental findings must ultimately be interpreted. The aim here is not encyclopaedic exposition but conceptual reconstruction: each theory is presented in a form that preserves its philosophical integrity while situating it within the Levels of Abstraction (LoA) discipline and the evaluative-topological architecture developed in this thesis.

\noindent
This reconstruction is guided by two methodological constraints:

\begin{enumerate}
	\item \textbf{Philosophical fidelity}: the theories must be represented in a manner faithful to their canonical formulations in moral philosophy.
	\item \textbf{Integrative compatibility}: the theories must be articulated in a form that allows principled interaction with the psychological and topological models of moral cognition established in Chapter~\ref{chap:moral_primer}.
\end{enumerate}

\noindent
The purpose of this section, therefore, is not to catalogue doctrines, but to map the deep structure of normativity in a way that can later illuminate the ethical significance of the empirical perturbations induced by synthetic presence.

\subsection{The Three Dimensions of Normative Analysis}

\noindent
Normative theories differ not only in content, but in the \emph{architecture of normativity} they assume. To analyse them systematically, we distinguish three fundamental dimensions—each corresponding to an aspect of evaluative topology and LoA structure:

\begin{enumerate}
	\item \textbf{Source of Normativity}:
	the origin of justificatory authority. This may lie in rational agency (Kant), human flourishing (Aristotle), aggregated welfare (Mill, Sidgwick), affective sentiment (Hume), or interpersonal justification (Scanlon).
	
	\item \textbf{Mode of Evaluation}:
	the features of action or character deemed morally relevant—maxims, consequences, virtues, motives, relational duties, or context-sensitive particulars.
	
	\item \textbf{Action-Guidance Mechanism}:
	the process that connects evaluative judgments to behaviour—categorical imperatives, utilitarian optimisation, virtue-structured perception, affective resonance, or justificatory equilibrium.
\end{enumerate}

\noindent
These dimensions allow us to re-express classical theories as \emph{evaluative topologies}:

\begin{itemize}
	\item \textbf{Kantian ethics} imposes rigid deontic invariants: absolute constraints that carve the evaluative field into sharply bounded permissible and impermissible regions.
	\item \textbf{Consequentialism} defines a gradient field over outcomes: moral action follows the steepest ascent toward welfare-maximising states.
	\item \textbf{Virtue ethics} defines dispositional attractors: stable patterns of moral sensitivity that shape the agent’s perceptual and evaluative orientation.
	\item \textbf{Sentimentalism} defines networks of affective resonance: moral evaluation flows along affectively weighted pathways anchored in human sympathy or aversion.
	\item \textbf{Contractualism} defines justificatory equilibria: a topology structured by mutual recognisability of claims.
	\item \textbf{Particularism} dissolves fixed topologies altogether: normativity emerges from fully context-dependent patterns of salience and relation.
\end{itemize}

\noindent
This analytic framing is essential because it provides a common representational language in which ethical theory and moral psychology can be jointly expressed. Theories that differ profoundly in content can be compared in structural terms—how they sculpt the evaluative landscape, where they locate normative constraints, and how they understand the movement from judgment to action.

\subsection{Why This Framework Matters for the Experimental Chapter}

\noindent
This normative topology is not abstract machinery; it is the conceptual infrastructure that enables us to interpret what the experiment later reveals. The empirical question—whether synthetic presence attenuates prosocial behaviour—cannot be ethically assessed without first situating it within a framework for understanding how moral cues acquire force.

\noindent
Three claims follow directly from the preceding reconstruction:

\begin{enumerate}
	\item \textbf{Moral action depends on the configuration of the evaluative field.}  
	Normative theories specify different sources of authority and diverse mechanisms of action-guidance, but all agree that moral behaviour arises from structured evaluative relations, not arbitrary choice.
	
	\item \textbf{Synthetic presence modulates this field by perturbing salience, attention, and affective resonance.}  
	A humanoid robot does not supply new reasons; it reshapes the environment in which reasons become behaviourally operative.
	
	\item \textbf{Normative theories must therefore be reinterpreted through the joint lens of LoA and evaluative topology if they are to explain or critique the behavioural perturbations observed experimentally.}
\end{enumerate}

\noindent
This is the philosophical function of the section: to establish the normative coordinates that will allow the experimental findings to be understood not merely as statistical differences, but as shifts in the moral significance of an action within a structured evaluative landscape.

\noindent
The stage is now set for the substantive reconstruction. In the following sections, each major normative framework—deontological, consequentialist, virtue-theoretic, sentimentalist, contractualist, and particularist—is examined as a topology of normativity embedded within the cognitive–affective architecture of moral agents. These reconstructions will serve as the interpretive foundation for evaluating how, and why, synthetic presence can reshape the moral field in the experiment to come.

%%% Terza porzione di contenuto da Lecce
