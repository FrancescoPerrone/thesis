\chapter{Ethical Theory in a Cognitive–Topological Framework}
\label{chap:ethics_s}
\thispagestyle{pprintTitle}

\section{From Moral Cognition to Ethical Theory}
\addcontentsline{toc}{section}{Bridging Note: From Moral Cognition to Ethical Theory}

\noindent
The preceding chapters established three claims that now structure the transition to the present, more theoretical discussion.

\medskip

\noindent
\textbf{First}, moral judgements were analysed as \emph{first-order evaluative outputs}: context-sensitive assessments generated by the cognitive--affective architecture through which agents register morally salient features of their environment. These outputs are psychologically real and empirically tractable, but they are not required to exhibit internal coherence or principled justification.

\noindent
\textbf{Second}, these first-order judgements arise from distributed processes—intuitive, affective, regulatory, and inferential—whose integration is shaped by perturbations in the surrounding social and perceptual field.

\noindent
\textbf{Third}, the experimental work in this thesis depended on this architecture: what was measured are not articulated commitments but the \emph{practical expression} of moral cognition in environments made ambiguous by synthetic presence.

\medskip

\noindent
The present chapter shifts from these \emph{first-order phenomena} to the \emph{second-order frameworks} through which philosophers and cognitive scientists attempt to explain, justify, or discipline them. Whereas moral judgements supply the data of moral life, \emph{ethical theory} provides the systematic attempts to interpret that data: to identify the principles, norms, and justificatory structures purported to govern moral reasoning. These questions occupy a different Level of Abstraction, requiring a methodological apparatus distinct from that used to study intuitive evaluation.

\medskip

\noindent
Seen from this perspective, the opening claim of this chapter—that classical ethical theory treats moral judgement as the outcome of structured deliberation—is not an empirical hypothesis but a \emph{second-order commitment}. It reflects the normative aspiration that moral authority arises from principled reasoning. Yet the Morality Primer exposed a systematic tension between this commitment and the empirical reality of moral cognition: human agents rarely deliberate in the manner presupposed by rationalist models of ethics~\cite{Korsgaard1996,Scanlon1998}. Instead, their judgements emerge from perceptual salience, affective valuation, heuristics of social meaning, and rapid integration across intuitive and deliberative systems.

\medskip

\noindent
The central task of this chapter, therefore, is to reconcile these levels: to examine whether, and under what constraints, ethical theory can remain normatively meaningful while respecting the psychological mechanisms through which moral judgements actually arise. Computing science faces this tension acutely, particularly in Machine Ethics, Social Signal Processing, and Affective Computing, where the challenge is to model behaviour that is empirically grounded yet normatively interpretable. Designing artificial agents requires avoiding both errors: treating first-order outputs as if they were principled commitments, and designing systems around abstract principles that human agents do not in practice instantiate.

\medskip

\noindent
This dual demand—empirical fidelity and normative coherence—forms the point of departure for what follows.


\section{Introduction: Why Ethics Needs Psychology (and Why Computing Science Needs Both)}

\noindent
Classical ethical theory often treats moral judgement as the conclusion of structured deliberation: a process guided by reasons, principles, and normatively defensible commitments. As discussed in Chapter~\ref{chap:moral_primer}, this picture is descriptively incomplete. Human moral behaviour rarely emerges from extended reflection; instead, it unfolds through rapid, affectively mediated evaluations shaped by perception, context, and embodied interaction~\cite{Haidt2001,Greene2001,Greene2002,Cushman2013}. The distance between what agents \emph{ought} to do, what they \emph{report} doing, and what they \emph{actually} do is substantial~\cite{Nisbett1977,Wilson2002}. Understanding moral action in practice—particularly in environments populated by artificial systems—requires integrating ethical theory with the empirical machinery of moral psychology~\cite{Mikhail2007,Decety2011}.

\noindent
For computing science, this integration is indispensable. Artificial agents increasingly participate in human environments where their form, presence, and behaviour modulate attention, inference, and normative expectation. Research in \emph{Social Signal Processing}~\cite{Vinciarelli2009} and \emph{Affective Computing}~\cite{Picard1997} has shown that human social cognition is finely attuned to subtle cues—gaze, posture, micro-expressions, spatial orientation, and embodied co-presence. These cues structure the ``interaction order''~\cite{Goffman1967} that shapes how humans interpret intentions, assign agency, and evaluate normatively relevant behaviour. When synthetic entities enter this order, they perturb it—not by issuing commands, but by altering the informational and affective landscape in which human cognition operates~\cite{Breazeal2003,Lee2010,Fischer2011}.

\noindent
The thesis therefore proceeds from two linked premises:  
\begin{enumerate}[label=(\arabic*)]
	\item \emph{ethical behaviour cannot be understood without an accurate model of moral psychology}, and  
	\item \emph{moral psychology cannot be operationalised in computational settings without an account of social signals and affective processes}.  
\end{enumerate}
Moral action is not reducible to computation over explicit propositions; it is embedded in a situated cognitive ecology shaped by agents, affordances, and rapidly deployed intuitive processes~\cite{Gigerenzer2008,Kahneman2011}.

\noindent
From this perspective, the central claim motivating the experimental work becomes clear: \emph{moral behaviour is systematically sensitive to the structure of the immediate perceptual--social environment}. If moral cognition is dynamically shaped by intuitive appraisal, attentional salience, and affective resonance~\cite{Decety2004,Conty2016}, then even a silent, behaviourally neutral synthetic presence may modulate the trajectory from moral perception to moral action. The results developed later in the thesis confirm this hypothesis, demonstrating that robotic co-presence can attenuate prosocial donation even in the presence of a strong moral cue (the Watching-Eye stimulus)~\cite{Haley2005,Bateson2006,Dear2019,Zlotowski2015}.

\medskip

\noindent
When reframed through ethical theory, this empirical claim has deeper implications. Ethics, on contemporary accounts, is a \emph{second-order discipline}~\cite{Scanlon1998,Darwall2006,Audi2015}: it does not generate moral judgements, but seeks to analyse, justify, or critique them. It examines the structure of reasons, obligations, and values—not the psychological mechanisms that produce first-order moral appraisals~\cite{Korsgaard1996}. Machine Ethics has historically blurred this distinction. By attempting to engineer ``ethical agents'' directly at the level of principles—rule-sets, deontic logics, utility functions—it presumes that moral behaviour can be derived from explicit normative propositions~\cite{Moor2006,Anderson2011,Wallach2008}. This presumption is both philosophically and empirically untenable. It treats the normative \emph{grammar} of ethics as if it were the mechanistic \emph{causality} of moral cognition~\cite{Greene2014}.

\noindent
The argument developed throughout this thesis challenges this assumption directly. If moral action is shaped primarily by perceptual salience, intuitive appraisal, affective resonance, and the dynamics of social attention—as the subsequent experimental results show~\cite{Haidt2001,Cushman2013,Conty2016}—then second-order normative structures cannot be treated as generative drivers of behaviour. They are interpretive and justificatory, \emph{not computationally operative}. This reorientation motivates the notion of \textit{Computational Morality}: before ethical frameworks can be embedded into artificial systems, we must understand the cognitive--affective machinery that underwrites human moral responsiveness~\cite{Knobe2010,Young2011}. Classical Machine Ethics inverts this order; the empirical results of this thesis reinstate it.

\medskip

\noindent
The aim of this chapter, however, is narrower than a full reconstruction of moral philosophy. It does not adjudicate debates about moral realism, contractualism, utilitarianism, or virtue theory. Instead, it isolates the conceptual and mechanistic structures necessary for the thesis as a whole: how ethical theory presupposes psychological assumptions~\cite{Mikhail2007}, how moral judgements are cognitively realised~\cite{Greene2001,Greene2002}, and why any computational account of ethical behaviour must be grounded in an empirically accurate model of moral cognition~\cite{Cushman2013}. The goal is foundational rather than encyclopaedic: to establish the theoretical substrate that motivates, constrains, and ultimately validates the experimental investigation that follows.

\medskip

\noindent
The remainder of the chapter develops this integration along three axes. First, it introduces the principal ethical concepts—deontic, consequentialist, and virtue-theoretic—that define the normative landscape of moral evaluation~\cite{Korsgaard1996,Scanlon1998,Foot2001}. Second, it examines the empirical architecture of moral cognition, with emphasis on intuitionist and dual-process models~\cite{Haidt2001,Greene2001,Cushman2013}. Third, it links these philosophical and psychological constructs to the computational disciplines that analyse social behaviour—Social Signal Processing, Affective Computing, and broader work in embodied AI~\cite{Vinciarelli2009,Picard1997,Breazeal2003}. 

\noindent
By weaving these strands together, the chapter provides the normative and conceptual tools needed to understand why—and by what mechanism—synthetic presence can reshape the evaluative topology of human decision-making. This synthesis prepares the ground for the experimental investigation that follows, where robotic co-presence is used as a principled probe into the cognitive machinery through which moral cues acquire behavioural force.


\section{Ethical Theory as Second-Order Analysis}
\label{sec:second_order_ethics}

\noindent
If the opening sections of this chapter establish the transition from first-order moral cognition to second-order ethical reflection, the present task is to spell out the methodological consequences of this shift. The distinction is not merely terminological. It determines which claims aim to explain behaviour, which aim to justify it, and which are constrained by empirical evidence. Failure to keep these levels distinct has led to recurring conceptual confusions in both philosophical ethics and computational modelling~\cite{Black1972,Hare1981,Hempel1965,Floridi2008,Moor2006,FloridiSanders2004,McLaren2006,Coeckelbergh2023}. This section therefore clarifies what second-order ethical theory \emph{is}, what it \emph{explains}, and what it \emph{cannot} plausibly do.

\subsection{Ethical Reflection and the Second-Order Stance}

\noindent
First-order moral judgements arise from the cognitive--affective architecture examined in the Morality Primer. They are psychologically instantiated, context-sensitive, and behaviourally measurable. Their structure reflects the mechanisms analysed in Chapter~\ref{chap:moral_primer}: operations on perceptual salience, affective appraisal, intuitive heuristics, social meaning, and controlled modulation under conflict. These judgements are the \emph{phenomena} that ethical theory seeks to interpret.

Second-order ethical theory is structurally different. It is reflexive rather than generative. It asks questions of justification rather than description:  
\emph{What counts as a reason? What makes an obligation binding? What norms govern deliberation and responsibility?}  
These questions presuppose capacities for abstraction, generalisation, and rational evaluation that are not themselves the proximate causal mechanisms of moral behaviour~\cite{Haidt2001,Greene2001,Young2012,Kohlberg1969,Narvaez2005,Kahneman2011,Baumeister2010}. Sidgwick’s distinction in \emph{The Methods of Ethics} between the psychology of moral sentiment and the ``method” of determining right conduct~\cite[Book~I]{SidgwickMethods} makes exactly this point. Lemos’s treatment of epistemic justification similarly separates doxastic psychology from the normative assessment of belief~\cite{Lemos2020}. The analogy is instructive: ethics stands to moral judgement as epistemology stands to belief-formation.

\noindent
Viewed from this stance, second-order theory is not a set of procedural rules that moral agents execute. It is a reflective framework for articulating the standards by which judgements \emph{ought} to be evaluated. Its success depends on conceptual clarity and justificatory coherence, not on behavioural predictiveness. Confusing this stance with the causal mechanisms of moral cognition risks treating normative categories as if they were psychological operators.

\subsection{Levels of Abstraction and the Proper Location of Ethical Explanation}

\noindent
The distinction between first-order and second-order claims becomes sharper through Floridi’s framework of \emph{Levels of Abstraction} (LoA)~\cite{Floridi2008, Floridi2010}. Every explanatory enterprise selects an LoA defined by its observables, its conceptual resolution, and the class of questions it can intelligibly answer. Ethical theory and moral cognition do not merely occupy different LoAs; they constitute \emph{different explanatory kinds}.

\medskip

\noindent
At the \textbf{cognitive LoA}, the explananda are:
\begin{itemize}
	\item perceptual salience and attentional capture;
	\item affective appraisal and embodied valuation;
	\item intuitive heuristics and rapid social inference;
	\item conflict monitoring and controlled modulation;
	\item the temporal dynamics of integrating these processes.
\end{itemize}
These are psychologically realised mechanisms with causal influence on behaviour. They are the variables the experimental chapters manipulate directly. \emph{This is the LoA at which this thesis measures moral cognition.}

\medskip

\noindent
At the \textbf{normative LoA}, by contrast, the objects of analysis are:
\begin{itemize}
	\item principles of justification and admissible reasons,
	\item conceptions of duty, value, and obligation,
	\item normative standards of agency and responsibility.
\end{itemize}
These are not causal operators but interpretive and justificatory categories. They organise moral practice but do not generate its behaviour. Ethical theory therefore evaluates the grammar of moral reasons rather than the mechanisms of moral cognition.

\medskip

\noindent
\textbf{Classical Machine Ethics collapsed these LoAs.}  
By treating deontic principles, utility structures, or prima facie duties as mechanistic generators of behaviour, early systems implicitly assumed that normative concepts function at the same LoA as cognitive processes. This assumption fails on two fronts:

\begin{enumerate}
	\item It misattributes causal status to normative constructs: duties and principles do not behave like salience gradients or affective appraisals.
	\item It ignores empirical work showing that behaviour emerges from intuitive, affective, and situational mechanisms long before propositional reasoning is engaged.
\end{enumerate}

\noindent
From the perspective developed here, this is not merely incomplete—it is methodologically incoherent. It attempts to engineer behaviour by manipulating abstractions at a LoA that is \emph{not behaviourally operative}.

\medskip

\noindent
The limitations of classical systems illustrate this point clearly. Top-down architectures such as Arkin’s ethical governor~\cite{Arkin2009}, Anderson and Anderson’s principlist models~\cite{Anderson2007,Anderson2011}, logic-based deontic programs~\cite{Bringsjord2006,Ganascia2007}, consequentialist utility-systems~\cite{Abel2016}, and virtue-theoretic computational frameworks~\cite{Powers2006,Thornton2013} all treated normative abstractions as if they were implementable causal rules. Floridi’s LoA analysis makes explicit why this reduction cannot succeed: normative categories belong to a reflective LoA concerned with justification, while computational models operate at an implementational LoA concerned with mechanism. Conflating the two yields systems whose “moral” behaviour is an artefact of representational choices rather than genuine moral competence.

\medskip

\noindent
\textbf{LoA discipline therefore becomes essential.}  
Explanations of behaviour require the cognitive LoA; evaluations of reasons require the normative LoA. Neither reduces to the other. Yet they are not independent: normative evaluation presupposes a psychology capable of rendering moral salience operative, while psychological findings constrain the plausibility of normative theory.

\medskip

\noindent
This interdependence links this chapter to both Chapter~\ref{chap:moral_primer} and the experimental analysis that follows. Chapter~\ref{chap:moral_primer} established that the cognitive LoA is \emph{topologically structured}: moral cognition unfolds within an evaluative field whose gradients depend on affective cues, attentional dynamics, and interpretive processes. Perturbations to this field—whether through altered salience, modified affective tone, or ambiguous social presence—can reshape behaviour even when normative commitments remain unchanged.

\medskip

\noindent
Seen through the LoA framework, the thesis’s central research question can now be restated with precision:
\begin{quote}
	\emph{How do normative expectations, psychological mechanisms, and environmental structures jointly determine the transition from moral perception to moral action?}
\end{quote}

\noindent
This question cannot be answered by ethical theory alone, nor by psychology in isolation. It requires a representational structure capable of linking the causal architecture of moral cognition (first-order) with the justificatory architecture of ethical evaluation (second-order). The remainder of this chapter argues that the notion of \textbf{evaluative topology}—introduced in Chapter~\ref{chap:moral_primer} and developed throughout the thesis—provides precisely such a bridge.

%%% HERE %%%

\subsection{Evaluative Topology as a Bridge Between Orders}

\noindent
The central challenge established thus far is not to collapse first-order moral cognition into second-order ethical theory, nor to treat normative principles as mechanistic generators of behaviour. Rather, the task is to articulate a structure that enables principled interaction between these orders without confusing their explanatory roles. \emph{Evaluative topology}, introduced in the Morality Primer (Chapter~\ref{chap:moral_primer}) and developed throughout this thesis, provides precisely such a structure.

\medskip

Evaluative topology is naturally situated within a long-standing tradition in computational cognitive science that models perception, valuation, and action as components of continuous dynamical systems rather than discrete symbolic modules. Moral psychology already supplies extensive evidence that moral judgement emerges from distributed interactions among perceptual salience, affective appraisal, attentional dynamics, and socially embedded interpretation. Models such as Haidt’s social intuitionism and Greene’s dual-process account capture moral appraisal as an interaction within a multi-dimensional affective and social field rather than as rule application~\cite{Haidt2001,Greene2001,Young2012}. Neurocognitive work extends this perspective: Nussbaum and Churchland both treat emotions as forms of evaluative perception with graded, vector-like organisation~\cite{Nussbaum2001,Churchland2011}. Social Signal Processing research likewise conceptualises interpersonal evaluation as a shifting landscape of cues modulating behavioural trajectories in real time~\cite{Pentland2007}.

\medskip

Against this background, evaluative topology provides a computationally meaningful formalisation. It treats the moral landscape as a dynamic field that structures the flow from perceptual input to action readiness. Instead of assuming that behaviour is produced by discrete maxims or fixed utility scores, evaluative topology models moral cognition as continuous transformations across a structured state-space. This aligns with dynamical-systems approaches that explain action selection through attractors, salience gradients, and field-like organisation rather than propositional inference. The topology encodes the shape of the evaluative field: the stability of certain trajectories, the resistance of others, and the ways in which local variations in perceptual or affective input can redirect the subject toward different moral outcomes.

\medskip

By locating moral appraisal within a dynamic state-space, evaluative topology supplies a principled bridge between first-order cognition and second-order ethical theory. It mirrors the empirical architecture of human moral cognition—distributed, affectively grounded, context-responsive—while remaining compatible with the justificatory concerns of normative ethics. This enables descriptive and normative orders to interact without reduction: ethical theory specifies global constraints on evaluative structure; moral psychology identifies the mechanisms through which those structures are realised; and topology provides the medium in which they meet.

\medskip

\noindent
At its core, evaluative topology treats the moral landscape not as a set of isolated judgements or abstract principles, but as a \emph{dynamic field} whose configuration determines the pathways from perception to action~\cite{Haidt2001,Greene2001,Churchland2011,Young2012,Nussbaum2001,Narvaez2005}. Its explanatory primitives include:

\begin{itemize}
	\item \textbf{salience gradients}: patterns of perceptual or affective prominence;
	\item \textbf{affective attractors}: regions of the field toward which intuitive appraisal rapidly converges;
	\item \textbf{attentional pathways}: routes through which cognitive resources flow;
	\item \textbf{normative deformations}: structural constraints introduced by duties, commitments, or justificatory expectations;
	\item \textbf{social or synthetic perturbations}: distortions induced by the presence of other agents, including artificial ones.
\end{itemize}

\noindent
Unlike classical ethical theories, which operate at a reflective and often idealised level~\cite{SidgwickMethods,Rawls2020,Mill1861,Korsgaard2009,Scanlon1998}, evaluative topology is sensitive to the real-time mechanisms through which moral cognition unfolds. And unlike purely mechanistic psychological models, which chart causal influences without normative content, topology captures the relational and counterfactual structure of moral appraisal: how behavioural trajectories \emph{would} shift under alternative affective, attentional, or contextual configurations.

\medskip

This leads to a three-part alignment essential for this thesis:

\begin{enumerate}
	\item \textbf{Ethical theory} identifies which evaluative configurations \emph{ought} to carry normative authority.
	\item \textbf{Moral psychology} identifies which configurations \emph{do} govern actual behaviour.
	\item \textbf{Evaluative topology} identifies how these structures interact, diverge, and can be perturbed.
\end{enumerate}

\noindent
This tripartite structure yields both diagnostic and constructive insights. Diagnostically, it explains the failure of many classical Machine Ethics frameworks: they attempted to engineer behaviour by manipulating abstractions at a normative LoA while ignoring the topological organisation of the cognitive LoA that actually produces behaviour. Constructively, it provides a psychologically realistic substrate on which normative reflection can operate without reducing ethics to psychology or cognition to normativity.

\medskip

\paragraph{Topological Consequences for Moral Perturbation.}
The Morality Primer established that moral behaviour emerges from traversal across a dynamically structured evaluative field. Within this framework, \emph{perturbation} has a precise, measurable meaning: any alteration that changes the curvature or attractor structure of the field will shift the probability distribution over behavioural trajectories. This includes changes to salience, affective tone, attentional competition, or the introduction of a new agent into the interaction ecology.

A synthetic presence—perceptually social yet ontologically indeterminate—is therefore not merely an “observer” but a topological operator. It changes the field in which moral meaning becomes behaviourally operative. This is the theoretical insight that shaped the experimental design in Chapter~\ref{chap:experimental_methods}: by embedding a morally charged cue (the Watching-Eye stimulus) within a field perturbed by a humanoid robot, we could test whether subtle topological deformation suffices to attenuate prosocial action.

\medskip

\paragraph{Interim Synthesis: Positioning the Argument.}
The conceptual machinery developed thus far establishes the structural conditions for the experimental work:

\begin{itemize}
	\item First, moral judgement operates at the cognitive LoA through dynamic, affectively responsive, socially sensitive processes.
	\item Second, ethical theory operates at the normative LoA, providing justificatory structures but not generative mechanisms.
	\item Third, evaluative topology provides the bridge between these orders by modelling the structural constraints and transformations governing the transition from moral perception to moral action.
	\item Fourth, this bridge is indispensable for understanding how synthetic agents perturb human moral behaviour.
\end{itemize}

\noindent
With this scaffolding in place, we can now reconstruct the major normative traditions. The reconstruction is not a survey but a methodological necessity: each tradition identifies distinct loci of normativity, and these differences directly shape how the experimental attenuation should be interpreted. Without situating the empirical perturbation within a structured normative framework, one could describe \emph{what} changed but not \emph{what the change means}.

\noindent
The next section therefore introduces deontic, consequentialist, and virtue-theoretic architectures through the combined lens of Levels of Abstraction and evaluative topology, preparing the conceptual ground for assessing the ethical significance of the perturbation demonstrated experimentally.


\section{The Normative Landscape: Structuring Ethical Theories Through LoA and Topology}
\label{sec:normative_landscape}

\noindent
With the methodological apparatus now established, we can introduce the major normative frameworks that constitute the philosophical background against which the behavioural findings of this thesis must ultimately be interpreted. The purpose of this section is not encyclopaedic exposition but \emph{conceptual reconstruction}: each theory is presented in a form that preserves its philosophical integrity while situating it within the Levels of Abstraction (LoA) discipline and the evaluative–topological architecture developed across the thesis~\cite{Floridi2008,Rawls2020,Scanlon1998,Korsgaard2009}.

\medskip

Two methodological constraints guide this reconstruction:

\begin{enumerate}
	\item \textbf{Philosophical fidelity} — the theories must be represented in a manner consistent with their canonical formulations within moral philosophy~\cite{Kant1785,AristotleNE,Mill1861,SidgwickMethods,HumeTreatise,SmithTMS}.
	\item \textbf{Integrative compatibility} — the theories must be articulated in a way that allows principled interaction with the cognitive–affective and topological models of moral judgment introduced in Chapter~\ref{chap:moral_primer} and developed through the Discussion~\cite{Haidt2001,Greene2001,Churchland2011,Narvaez2005}.
\end{enumerate}

\noindent
The aim, then, is not to catalogue doctrines, but to map the \emph{structural logic of normativity} in a way that will later clarify the ethical significance of the empirical perturbations produced by synthetic presence.

% -----------------------------------------------------------
\subsection{The Three Dimensions of Normative Analysis}

\noindent
Normative theories differ not only in the moral claims they endorse, but in the \emph{architecture of normativity} they assume~\cite{Scanlon1998,Korsgaard2009,Wallace2012}. To analyse them systematically, we distinguish three fundamental dimensions—each corresponding to a feature of evaluative topology and LoA structure.

\begin{enumerate}
	\item \textbf{Source of normativity}  
	— the origin of justificatory authority: rational agency (Kant~\cite{Kant1785}), human flourishing (Aristotle~\cite{AristotleNE}), aggregated welfare (Mill, Sidgwick~\cite{Mill1861,SidgwickMethods}), affective sentiment (Hume, Smith~\cite{HumeTreatise,SmithTMS}), or interpersonal justification (Scanlon~\cite{Scanlon1998}).
	
	\item \textbf{Mode of evaluation}  
	— the features of action or character that determine moral relevance: maxims, outcomes, virtues, motives, relational duties, or context-specific particulars~\cite{Dancy2004,Foot1978,Rawls2020}.
	
	\item \textbf{Mechanism of action-guidance}  
	— the process through which evaluation becomes behaviour: categorical imperatives, welfare optimisation, virtue-structured perception, affective resonance, or justificatory equilibrium~\cite{McDowell1979,Korsgaard2009,Scanlon1998}.
\end{enumerate}

\noindent
These dimensions allow us to re-express classical theories as \emph{evaluative topologies}—distinct structural configurations of the moral field:

\begin{itemize}
	\item \textbf{Kantian ethics} imposes deontic invariants that carve the evaluative field into sharply bounded permissible and impermissible regions~\cite{Kant1785,Korsgaard2009}.
	\item \textbf{Consequentialism} defines a gradient field over states of affairs: action flows along trajectories of maximal expected welfare~\cite{Mill1861,SidgwickMethods,Railton1984}.
	\item \textbf{Virtue ethics} defines dispositional attractors: stable patterns of moral sensitivity shaping perception and evaluative attention~\cite{AristotleNE,Foot1978,McDowell1979}.
	\item \textbf{Sentimentalism} defines affectively weighted pathways through which moral appraisal propagates~\cite{HumeTreatise,SmithTMS,Prinz2004}.
	\item \textbf{Contractualism} defines justificatory equilibria: a topology structured by mutual recognisability of claims~\cite{Scanlon1998,Rawls2020}.
	\item \textbf{Particularism} rejects fixed topologies: moral relevance emerges from local patterns of salience and relation~\cite{Dancy2004}.
\end{itemize}

\noindent
This analytic frame yields a common representational language in which ethical theory and moral psychology can be jointly expressed. Theories that diverge substantially in content become comparable in structural terms—how they configure the evaluative field, where they locate normative constraints, and how they model the transition from judgment to action~\cite{McDowell1979,Korsgaard2009,Railton2017}.

% -----------------------------------------------------------
\subsection{Why This Framework Matters for the Experimental Chapter}

\noindent
This normative topology is not abstract ornamentation; it is the conceptual infrastructure that allows the experiment to be interpreted. The behavioural question—whether robotic co-presence attenuates prosocial donation—cannot be evaluated ethically without a framework that explains \emph{how} moral cues acquire force in the first place~\cite{Haidt2001,Greene2001,Churchland2011}.

Three structural claims follow immediately from the reconstruction above:

\begin{enumerate}
	\item \textbf{Moral action depends on the configuration of the evaluative field.}  
	Normative theories differ in source, mode, and guidance, but all assume that moral behaviour emerges from structured evaluative relations, not arbitrary choice~\cite{AristotleNE,Korsgaard2009,Scanlon1998}.
	
	\item \textbf{Synthetic presence modulates this field by perturbing salience, attention, and affective resonance.}  
	A humanoid robot does not supply new reasons; it alters the environment within which reasons become behaviourally operative~\cite{Pentland2007,Conty2016,Dear2019,Zlotowski2015}.
	
	\item \textbf{Normative theories must therefore be expressed within the joint framework of LoA and evaluative topology in order to interpret the empirical perturbation coherently.}
\end{enumerate}

\noindent
This is the philosophical function of the present section: to establish the normative coordinates that will allow the experimental results—introduced later in the thesis—to be understood not merely as statistical differences, but as shifts in the moral significance of an action within a structured evaluative landscape~\cite{Railton2017,Korsgaard2009,Scanlon1998}.

\medskip

The stage is now set for the substantive reconstruction. In the following sections, each major normative framework—deontological, consequentialist, virtue-theoretic, sentimentalist, contractualist, and particularist—is examined as a topology of normativity embedded within the cognitive–affective architecture of human agents. These reconstructions will serve as the interpretive foundation for assessing how, and why, synthetic presence can reshape the moral field in the experiment.


\section{Deontological Structures: The Architecture of Practical Reason}
\label{sec:deontology}

\noindent
The methodological framework established above motivates a disciplined reconstruction of deontological ethics through the joint lens of Levels of Abstraction (LoA) and evaluative topology. The aim is not to treat deontology as a psychological model—indeed, it is explicitly \emph{not} one—but to articulate how deontic normativity can be represented as a structural component of the evaluative field within which moral agents operate. This reconstruction preserves the philosophical identity of deontological theory while rendering it compatible with the cognitive–affective and topological architecture developed across the thesis.

\medskip

Three constraints guide the reconstruction:

\begin{enumerate}
	\item \textbf{Philosophical fidelity}: The core commitments that distinguish deontology must remain intact.
	\item \textbf{LoA discipline}: Deontic principles cannot be treated as psychological mechanisms or behaviour-generating algorithms.
	\item \textbf{Topological embedding}: Duties must be expressed as structural constraints within the evaluative field, not as direct causes of action.
\end{enumerate}

\noindent
Within this framework, deontology identifies \emph{invariant structures} in the moral field: boundaries of permissibility and prohibition that constrain evaluative trajectories without functioning as generative cognitive operators. These invariants occupy a reflective LoA and serve as standards of justification, not as engines of behaviour.

% -----------------------------------------------------------
\subsection{The Source of Normativity: Rational Agency and the Form of Law}

\noindent
For Kant, moral authority arises from the structure of rational agency itself. The categorical imperative offers a formal test of maxims—whether a maxim could be willed as a universal law—not a psychological process for generating behaviour \cite{Kant1785,Korsgaard2009,Allison2011}. Its role is to define the \emph{conditions of justificatory coherence}, situated at a higher LoA than the cognitive mechanisms analysed in Chapter~\ref{chap:moral_primer}. The categorical imperative belongs to the space of reflective evaluation, not to the causal substrate of intuitive moral appraisal.

\medskip

This distinction is essential to the present thesis. Classical Machine Ethics frequently misinterpreted universalisability tests as if they were procedural decision rules—algorithmic operators that could be executed at run time \cite{Anderson2007,Anderson2011,Bringsjord2006,Govindarajulu2017,Ganascia2007,Arkin2009}. But Kant never proposed that deontic evaluation functions as a mechanistic generator of moral action.\footnote{See \cite{Allison2011} and \cite{Korsgaard1996} for detailed discussion of the reflective, non-psychological status of the categorical imperative.} Treating such tests as computational procedures constitutes the very LoA confusion diagnosed earlier: it collapses reflective justification into first-order cognition.

\medskip

A brief survey of Classical Machine Ethics illustrates this confusion clearly.  
Anderson and Anderson’s principlist architectures computationalised prima facie duties as weighted decision rules \cite{Anderson2007,Anderson2011}; Bringsjord and colleagues embedded deontic obligations into the cognitive event calculus \cite{Bringsjord2006,Govindarajulu2017}; Ganascia formalised ethical constraints as logical conditions governing action permissibility \cite{Ganascia2007}; and Arkin’s “ethical governor’’ implemented deontological rules derived from Just War Theory as real-time filters on autonomous behaviour \cite{Arkin2009}. In each case, duties intended as reflective constraints were treated as if they were causal action-selection mechanisms.

As Moor and Coeckelbergh emphasise, this is a fundamental mistake of abstraction: ethical principles belong to a normative LoA, whereas cognitive processes and computational models operate at a mechanistic LoA \cite{Moor2023,Coeckelbergh2023}. Conflating these levels does not produce ethically competent machines; it produces systems that mechanically enforce the representational choices of their designers.

% -----------------------------------------------------------
\subsection{Deontic Invariants as Topological Constraints}

\noindent
Reconstructed through the evaluative–topological lens, deontological duties are best understood as \emph{structural constraints} that shape the moral field without functioning as its generative forces. Instead of treating the categorical imperative as a behavioural algorithm, we interpret deontic norms as imposing \emph{invariant boundaries} on permissible trajectories in the evaluative manifold. Formally, a deontic constraint can be expressed as a region of the field $\mathcal{E}$ that action trajectories cannot cross without violating justificatory coherence.

\medskip

This topological rendering preserves the normative role of deontology while integrating it with the empirical architecture of moral cognition:

\begin{itemize}
	\item At the \textbf{cognitive LoA}, intuitive appraisal and affective resonance drive the formation of evaluative gradients.
	\item At the \textbf{topological LoA}, deontic norms impose structural boundaries that constrain the space of evaluatively permissible outcomes.
	\item At the \textbf{normative LoA}, reflective justification assesses whether a trajectory is consistent with universalizable maxims.
\end{itemize}

\noindent
These levels remain distinct, yet their interaction can now be modelled without conflation. Deontic invariants do not guide moment-to-moment appraisal, but they structure the higher-level evaluative landscape in which such appraisal takes place.

% -----------------------------------------------------------
\subsection{Relevance to Synthetic Perturbation}

\noindent
This reconstruction equips us to interpret the experimental findings later in the thesis. If deontic norms function as structural constraints on the evaluative field, then synthetic presence—by altering salience, attention, and the perceived sociality of the environment—can modify the \emph{access} agents have to those constraints without altering the constraints themselves.

\medskip

From a deontological perspective, then, attenuation under robotic co-presence is not a violation of duty. It is a deformation of the cognitive–affective substrate through which agents track deontic salience. The duty remains; the \emph{grip} of the duty is weakened because the evaluative conditions under which it becomes behaviourally operative have been perturbed.

\medskip

This interpretation preserves the philosophical integrity of deontology while situating it precisely within the cognitive–topological framework of the thesis. Deontic normativity thus provides one dimension of the interpretive foundation necessary for understanding how synthetic presence reshapes the moral field.

\subsection{Mode of Evaluation: Maxims, Duties, and the Structure of Permissibility}

\noindent
Deontological theories evaluate actions through the \emph{form} of the underlying maxim and the duties that follow from rational consistency. In the present framework, these evaluative commitments introduce a characteristic structure into the moral field. Their core features can be expressed topologically:

\begin{itemize}
	\item \textbf{Invariance}: duties bind independently of context, affective state, or anticipated outcome.
	\item \textbf{Non-gradience}: obligations often define discrete boundaries—permissible vs.\ impermissible—rather than continuous slopes.
	\item \textbf{Symmetry}: the universal law test imposes interpersonal consistency constraints across agents.
	\item \textbf{Role-relativity}: some duties apply only under specific relational or social conditions (e.g.\ fidelity, respect, special obligations).
\end{itemize}

\noindent
Viewed through evaluative topology, these features correspond to \emph{hard constraints} within the evaluative landscape. They do not shape the gradients that drive moment-to-moment appraisal; instead, they partition the field into admissible and inadmissible regions. Deontological normativity thus defines the \emph{regulatory geometry} within which cognitive–affective trajectories unfold.

% -----------------------------------------------------------
\subsection{Action-Guidance: How Normative Constraints Influence Behaviour}

\noindent
A central challenge now arises. If deontological principles do not describe psychological processes, how do they guide action?

\noindent
The answer, consistent with LoA discipline, is that their influence operates \emph{indirectly} and at distinct temporal and explanatory scales:

\begin{enumerate}
	\item \textbf{At the cognitive LoA} (real-time appraisal), deontic principles do not produce behaviour. Behaviour emerges from the integration of perceptual salience, affective valuation, intuitive appraisal, and controlled modulation—processes analysed empirically in Chapter~\ref{chap:moral_primer}.
	
	\item \textbf{At the normative LoA} (reflective endorsement), deontological principles determine which trajectories can be justified as consistent with rational agency. They also shape the long-term development of moral character by influencing attention, affect, and self-regulation through training, habituation, and self-constitution.
\end{enumerate}

\noindent
In this long-term sense, internalised deontic commitments function as a form of \emph{normative scaffolding}. Over time they:

\begin{itemize}
	\item heighten sensitivity to cues of respect, dignity, or violation;
	\item modulate affective responses to dishonesty, coercion, or unfairness;
	\item strengthen top–down inhibitory control when intuitive impulses conflict with perceived duty.
\end{itemize}

\noindent
Thus, deontology does not operate the machinery of moral cognition. Instead, it calibrates aspects of that machinery across development and reflective practice. It provides the structural frame against which agents regulate their evaluative postures.

% -----------------------------------------------------------
\subsection{Deontological Normativity as Topological Invariance}

\noindent
This perspective allows the central insight of the reconstruction to be stated precisely. Within a topological model of moral cognition, deontological ethics identifies \emph{non-negotiable invariants}: fixed points or boundaries that preserve the structural integrity of the moral field.

\noindent
These invariants:

\begin{itemize}
	\item partition the evaluative manifold into permissible and impermissible zones;
	\item resist deformation by short-term changes in affect, context, or incentives;
	\item stabilise behavioural tendencies by constraining rational endorsement over time;
	\item provide the reflective standpoint from which agents evaluate the legitimacy of their conduct.
\end{itemize}

\noindent
Accordingly, the categorical imperative is not an algorithmic decision rule but a \emph{topological constraint}: a principle that ensures global coherence of evaluative structure rather than ad hoc, context-bound optimisation.

% -----------------------------------------------------------
\subsection{Why Deontology Matters for the Experimental Logic}

\noindent
This reconstruction is essential for integrating the experimental findings into a normative framework. The experiment does not merely identify behavioural differences; it raises the question of their \emph{moral significance}. Deontology supplies one dimension of the interpretive structure required to answer that question.

\medskip

Before stating the connection explicitly, one clarification is needed. The experiment employs a widely studied social–moral prime: the “Watching-Eye” cue. As detailed in Chapter~\ref{chap:experimental_methods}, such cues increase accountability, evoke reciprocity norms, and prime compliance with expectations of beneficence—even though they involve no real observer. They thus operate on precisely the evaluative sensitivities that internalised deontic structures help regulate.

\medskip

Given this, the relevance of deontology to the experimental logic can be articulated through three claims:

\begin{enumerate}
	\item \textbf{Perturbations of prosocial behaviour must be normatively classified.}  
	If synthetic presence reduces donation, we must ask whether the shift remains within the deontically permissible region or whether it signals a distortion in the agent’s sensitivity to obligation.
	
	\item \textbf{The Watching-Eye cue implicitly invokes deontic expectations.}  
	It activates norms of accountability, respect, and reciprocity. A reduction in prosociality under this cue suggests that the synthetic agent may interfere with the mechanisms through which deontic salience is apprehended.
	
	\item \textbf{Deontology provides the vocabulary for distinguishing moral distortion from benign modulation.}  
	Not all behavioural shifts are ethically significant; deontic analysis helps determine whether attenuation constitutes weakened duty-tracking rather than mere affective dampening.
\end{enumerate}

\noindent
This is the point at which the present thesis departs most sharply from monolithic Machine Ethics. Classical approaches attempted to encode deontic rules as behavioural algorithms. But the empirical findings in later chapters show why this strategy is misguided: deontic norms do not generate behaviour, and behavioural perturbations cannot be interpreted solely as rule deviations. Instead, synthetic presence acts on the evaluative field \emph{upstream} of duty, altering the conditions under which deontic invariants become behaviourally operative.

\medskip

\noindent
With deontology reconstructed as a system of topological constraints rather than computational rules, we can now proceed to consequentialism. There, normativity takes the form of gradient fields over outcomes—structures that interact with the evaluative machinery of moral cognition in different, but equally revealing, ways.

\subsection{Conceptual Note: Gradient Fields in Consequentialist Topology}

\noindent
Within the evaluative–topological framework developed in this thesis, a \emph{gradient field} denotes a structured moral landscape in which each possible action–outcome configuration is associated with a scalar value—typically representing expected welfare, utility, or outcome-based moral worth. Conceptually, a gradient field assigns to each point in this space a direction of steepest ascent: the direction in which a marginal shift would produce the greatest increase in expected value. Classical utilitarian reasoning implicitly presupposes such a structure when it assesses actions by their contribution to overall welfare \cite{Bentham1789,Mill1861,SidgwickMethods}. Here, the notion is used in a non-formal but philosophically precise sense: as a way of modelling how consequentialist evaluation imposes directional structure on the moral field, where moral improvement corresponds to movement toward higher expected value.

\noindent
A consequentialist gradient field has three defining properties:

\begin{enumerate}
	\item \textbf{Scalar valuation}: each point in the evaluative manifold has a determinable (actual or expected) value, enabling continuous comparison along a single welfare dimension.
	
	\item \textbf{Directional guidance}: the moral significance of an option lies in its orientation relative to the gradient; actions are preferable to the extent that they align with the direction of steepest welfare ascent.
	
	\item \textbf{Empirical sensitivity}: because value depends on expected outcomes, the structure of the field varies with beliefs, evidence, uncertainty, and situational detail.
\end{enumerate}

\noindent
Crucially, in this reconstruction gradient fields do \emph{not} function as psychological mechanisms. Agents do not compute welfare gradients when acting, nor do they evaluate global states of the world through analytic integration. Consequentialist structures operate at the \emph{normative Level of Abstraction}: they specify how actions are \emph{justified} under reflective endorsement, not how they are generated in real-time cognition. Sidgwick’s distinction between the ``point of view of the universe’’ and the psychology of everyday decision-making is an early articulation of this separation \cite[Book~IV]{SidgwickMethods}.

\medskip

\noindent
\textbf{Interaction with the Evaluative Machinery of Moral Cognition.}  
Although gradient fields belong to the normative LoA, they interact indirectly with the empirical machinery of moral cognition introduced in Chapter~\ref{chap:moral_primer}. Four forms of interaction are especially relevant:

\begin{enumerate}
	\item \textbf{Salience modulation}.  
	Anticipated outcomes influence which parts of a situation become perceptually salient. Potential harm, benefit, or risk amplifies attention and reshapes local evaluative configuration before explicit reasoning is engaged.
	
	\item \textbf{Affective valuation}.  
	Affective systems track outcome-related information with strong valence, effectively providing local approximations of the gradient. Positive and negative affect bias intuitive appraisal toward or away from certain actions in ways that loosely track expected value.
	
	\item \textbf{Heuristic internalisation}.  
	Over time, agents extract outcome-sensitive heuristics—``help when it is easy'', ``avoid imposing harm''—that are computationally tractable proxies for gradient following. These heuristics allow the cognitive system to approximate consequentialist structure without computing it.
	
	\item \textbf{Deliberative correction}.  
	When intuitive and affective processes conflict or when the situation is ambiguous, controlled processes may approximate explicit comparisons of expected harm or benefit. This engages the gradient field at a coarse resolution, albeit with substantial computational limits.
\end{enumerate}

\noindent
A fifth mode is essential for the present thesis:

\begin{enumerate}
	\setcounter{enumi}{4}
	\item \textbf{Perturbation sensitivity}.  
	Because valuations depend on perceived outcomes, any perturbation to perception, attention, or social meaning—such as the introduction of a humanoid robot—can reshape the agent’s \emph{perceived} gradient field. Consequentialist structures are thus especially sensitive to environmental distortions of the kind tested experimentally.
\end{enumerate}

\noindent
Evaluative topology makes these interactions explicit. It models behaviour not as the execution of explicit calculations, but as movement through a dynamically shaped field whose gradients are only indirectly approximated by affective and attentional processes.

\medskip

\noindent
This integration is necessary for the thesis as a whole. It renders consequentialism compatible with the empirical finding that moral behaviour is modulated by subtle shifts in the perceptual–social environment. It also clarifies how the experimentally observed attenuation of prosocial donation under synthetic presence can be interpreted: as a local distortion of the gradient field that normally favours prosocial conduct.

% ----------------------------------------------------------------------
\section{Consequentialist Structures: Value Gradients and the Topology of Outcomes}
\label{sec:consequentialism}

\noindent
Having reconstructed deontological ethics as a system of topological invariants that constrain the space of permissible action without directly generating behaviour, we now turn to consequentialism. Here the architecture differs along every structural dimension. Where deontology imposes \emph{fixed boundaries} in the evaluative field, consequentialism supplies \emph{value gradients}. Where deontology locates normativity in the form of maxims, consequentialism locates it in outcome structure. And where deontology articulates duties, consequentialism articulates trajectories across possible states of the world.

\noindent
As in the preceding section, the aim is not historical analysis but conceptual reconstruction. The goal is to articulate consequentialist normativity in a way that respects LoA discipline and integrates with the evaluative–topological account of moral cognition developed earlier. This reconstruction also prepares a normative lens through which the experimental attenuation effect can later be interpreted.

\subsection{The Source of Normativity: Welfare, Impartiality, and the Structure of Reasons}

\noindent
Classical utilitarianism grounds moral authority in the promotion of welfare. Bentham’s felicific calculus \cite{Bentham1789}, Mill’s qualitative distinctions \cite{Mill1861}, and Sidgwick’s systematic treatment of impartiality \cite{SidgwickMethods} converge on the view that what ultimately matters is the value of outcomes, aggregated across persons. On this view, an action is right insofar as it maximises (or sufficiently promotes) overall good.

\noindent
From the perspective of Levels of Abstraction, this places consequentialist normativity at a \emph{reflective} LoA concerned with:

\begin{itemize}
	\item evaluating and comparing outcomes,
	\item aggregating welfare or value across individuals,
	\item and justifying action from an impartial standpoint.
\end{itemize}

\noindent
These commitments are not descriptive claims about the mechanisms of moral cognition. Sidgwick is explicit that the deliberative standpoint of consequentialist justification is distinct from ordinary motivation. Consequentialism thus supplies a criterion of rightness, not a psychological procedure.

\noindent
This point is crucial for avoiding the LoA confusion characteristic of classical Machine Ethics. Outcome-based formalisms—utility functions, reward optimisers, expected-utility maximisers—are often treated as if they were \emph{surrogates} for moral cognition itself. But these belong to different explanatory orders: normative structure at the reflective LoA and cognitive–affective processes at the psychological LoA (Chapter~\ref{chap:moral_primer}). Any mapping between them must be justified, not assumed.

\subsection{Mode of Evaluation: Consequences, Expected Value, and Scalar Normativity}

\noindent
Consequentialism evaluates actions by the value of their actual or expected outcomes. Unlike deontological theories, which generate categorical constraints, consequentialism is \emph{scalar}: options can be morally preferable to varying degrees. This scalar structure has a natural topological representation.

\noindent
In the evaluative–topological model, a consequentialist landscape exhibits:

\begin{itemize}
	\item \textbf{Gradience}: moral evaluation varies continuously with expected value.
	\item \textbf{Optimisation structure}: right action corresponds to local or global maxima on the welfare landscape.
	\item \textbf{Context-dependence}: the shape of the field depends on empirical facts about consequences.
	\item \textbf{Impartiality}: welfare contributions have equal evaluative standing across persons.
\end{itemize}

\noindent
Because of these features, consequentialism lends itself readily to computational formulation: utility functions, reward structures, and optimisation routines approximate the mathematics of value gradients. This explains its prominence in reinforcement-learning–based approaches to Machine Ethics.

\noindent
Yet computational elegance must not be mistaken for cognitive realism. Human moral cognition does not perform explicit optimisation; it relies on heuristic, affective, and context-responsive mechanisms that only loosely approximate consequentialist ideals \cite{Kahneman2011,Greene2001,Haidt2001,Slovic2007}. Treating human agents as literal expected-utility maximisers is another instance of LoA confusion.


\subsection{Action-Guidance Mechanism: From Value Gradients to Behavioural Pressure}

\noindent
How, then, does consequentialism guide action without collapsing into a psychologically implausible calculus? The answer—consistent with LoA discipline—is that consequentialism exerts its influence through \emph{indirect modulation} of the evaluative topology rather than through explicit computation.

\noindent
At the normative LoA, consequentialism states:
\begin{quote}
	An action is right insofar as it maximises (or sufficiently promotes) expected welfare.
\end{quote}

\noindent
At the cognitive LoA, by contrast, behaviour emerges from the interaction of intuitive appraisal, affective resonance, social cues, and controlled modulation. Consequentialist considerations shape this machinery only \emph{over time}, through pathways such as:
\begin{itemize}
	\item \textbf{Dispositional shaping}: moral education increases sensitivity to outcomes and harm, thereby steepening certain evaluative gradients.
	\item \textbf{Outcome-sensitive heuristics}: agents internalise tractable rules (e.g.\ ‘‘help when it costs little’’) that loosely approximate expected-value comparisons.
	\item \textbf{Attentional modulation}: anticipated benefits or harms alter what becomes salient and thus influence intuitive appraisal.
	\item \textbf{Deliberative correction}: when intuitive responses conflict, deliberation may reweight options in favour of outcome-based considerations.
\end{itemize}

\noindent
Topologically, consequentialism does not \emph{run} the cognitive system. Instead, it shapes the evaluative field by reorienting trajectories and adjusting the relative steepness of welfare-relevant gradients.

\subsection{Consequentialist Topology: Moral Action as Gradient Following}

\noindent
Within the topological framework of this thesis, the core consequentialist idea can be expressed succinctly: moral action corresponds to (approximate) \emph{gradient following} in a welfare-defined landscape. Behaviour counts as morally preferable when it moves ``uphill'' along these value gradients.

\noindent
This yields several structural implications:

\begin{enumerate}
	\item \textbf{Smoothness}: unlike deontic boundaries, consequentialist landscapes permit continuous gradations of moral improvement.
	\item \textbf{Directionality}: the moral relevance of an action depends on its orientation relative to welfare ascent.
	\item \textbf{Trade-offs}: multi-dimensional outcomes (helping one party, imposing small burdens on another) are represented as interacting gradients.
	\item \textbf{Perturbation sensitivity}: because evaluation depends on expected consequences, shifts in salience, attention, or perceived social meaning can locally distort the gradient.
\end{enumerate}

\noindent
This final feature is directly relevant to the experiment: if synthetic presence alters the perceived consequences of donating—by changing the social meaning of helping or by absorbing attentional and affective resources—the value gradient favouring prosocial action can be flattened.

\subsection{Why Consequentialism Matters for the Experimental Logic}

\noindent
Consequentialism provides one indispensable dimension for interpreting the attenuation observed in the experimental results. Prosocial donation is simultaneously:

\begin{itemize}
	\item a \emph{behavioural output} of the cognitive architecture, and
	\item a \emph{welfare-relevant action} whose outcomes can be straightforwardly ordered.
\end{itemize}

\noindent
Within this dual frame, the Watching-Eye prime and synthetic presence can be understood as modifying the agent’s \emph{perceived consequence structure}.

\begin{enumerate}
	\item \textbf{The Watching-Eye cue steepens the prosocial gradient.}  
	As reviewed in Chapter~\ref{chap:experimental_methods}, visual cues of being observed increase the perceived reputational or social value of helping. In topological terms, the gradient from ``keep'' to ``donate'' becomes steeper.
	
	\item \textbf{Synthetic presence can flatten or redirect this gradient.}  
	The humanoid robot constitutes an ambiguous social agent whose presence may blunt or partially occlude the evaluative pathway activated by the Watching-Eye cue. If attention shifts toward the robot, or if the robot is not integrated into the relevant social-evaluative schema, the perceived payoff of donating may weaken.
	
	\item \textbf{Consequentialism provides a normative reading of this shift.}  
	From a consequentialist perspective, attenuation signals that the agent’s welfare-related field has been deformed: donating no longer appears sufficiently beneficial—socially, affectively, or interpersonally—to overcome competing evaluative forces.
\end{enumerate}

\noindent
Importantly, nothing in this reconstruction treats consequentialism as a blueprint for machine implementation. Unlike classical Machine Ethics approaches that equate “ethical design’’ with encoding explicit utility functions, consequentialism here functions as a \emph{normative lens}: a structured perspective on how synthetic presence perturbs the evaluative topology that normally favours prosocial behaviour.

\medskip

\noindent
The next section turns to virtue ethics, which locates normativity not in constraints or outcomes but in cultivated dispositions and perceptual sensitivities. This framework will illuminate a further dimension of the evaluative topology: how character, habituation, and moral perception shape susceptibility to synthetic perturbation.

\section{Virtue-Theoretic Structures: Dispositions, Character Topology, and Moral Sensitivity}
\label{sec:virtue_ethics}

\noindent
Deontological invariants and consequentialist gradients capture two dimensions of the evaluative field, but they remain incomplete without an account of the \emph{agent} who navigates that field. Virtue ethics—classically Aristotelian \cite{Aristotle_nicomachean} and developed in modern neo-Aristotelian and psychological accounts \cite{Foot2001,Hursthouse1999,Annas2011}—locates normativity not in rules or outcomes but in the \emph{perceptual and dispositional architecture} of the moral agent. This makes virtue theory particularly well-suited to the present thesis, where experimentally observed attenuation varies systematically across latent trait ecologies (Chapter~\ref{chap:experimental_methods}).  

\noindent
Our task is therefore to reconstruct virtue ethics in a form compatible with the evaluative-topological model and LoA discipline. This reconstruction must:
\begin{enumerate}
	\item preserve the philosophical distinctiveness of virtue theory as an account of normativity grounded in moral perception and stable character,
	\item express dispositional structure in topological terms—as curvature and attractor shape in the evaluative field,
	\item and connect directly to the empirical pattern of cluster-dependent susceptibility under synthetic perturbation.
\end{enumerate}

\noindent
Within these constraints, virtue ethics becomes a theory of \emph{moral sensitivity as a topologically structured, personality-dependent field}, shaped by long-term habituation and modulated by local perturbations such as robotic co-presence.

\subsection{The Source of Normativity: Character, Practical Wisdom, and Moral Perception}

\noindent
In the virtue-theoretic tradition, normativity originates in the \emph{well-formed character} of the agent. Virtues are not propositional rules but \emph{stable perceptual–evaluative dispositions}: they structure which features of a situation stand out as salient, how those features are weighted, and which actions appear fitting or required \cite{McDowell1979,Foot2001}. Aristotle’s \emph{phronesis} captures this idea as \emph{perceptual attunement}: the capacity to discern morally relevant particulars and respond appropriately \cite{Aristotle_nicomachean}.

\noindent
This maps directly onto the evaluative-topological framework. A virtuous agent’s evaluative field contains:
\begin{itemize}
	\item \textbf{stable attractors} corresponding to benevolence, honesty, fairness, and other prosocial dispositions;
	\item \textbf{well-shaped gradients} that reliably direct appraisal toward morally appropriate trajectories;
	\item \textbf{robustness under perturbation}, where minor contextual shifts do not destabilise moral sensitivity.
\end{itemize}

\noindent
By contrast, deficiencies in character manifest as distortions in the field: shallow attractors, flattened gradients, or unstable transitions. Thus, virtue ethics provides a natural bridge between normative theory and personality-structured cognitive architecture.

\subsection{Mode of Evaluation: Dispositions as Topological Structure}

\noindent
Virtue ethics evaluates actions as \emph{expressive of character}, not merely as discrete events. The morally relevant unit is the dispositional pattern through which the agent perceives and structures the situation. This is exactly the level at which the experiment reveals systematic variation.

\subsubsection*{(i) Mathematical and Topological Interpretation}

\noindent
Let the agent’s dispositional profile be represented as a vector
\[
\beta_C \in \mathbb{R}^k,
\]
where \(k\) indexes latent psychological traits (e.g.\ agreeableness, empathy, conscientiousness). Chapter~\ref{chap:experimental_methods} showed that participants form coherent clusters \(C_1,\dots,C_m\) in this space.

\noindent
In virtue-theoretic terms, we can model the mapping
\[
\mathcal{T}: \mathbb{R}^k \rightarrow \mathcal{F},
\]
where \(\mathcal{F}\) is the space of evaluative fields. Under this mapping:
\begin{itemize}
	\item high-empathy / warm–sociable clusters exhibit deeper prosocial attractors and sharper gradients toward helping,
	\item analytical–structured clusters exhibit more stable but less affectively steep topologies,
	\item emotionally reactive clusters exhibit shallow, volatile attractor basins.
\end{itemize}

\noindent
This aligns with empirical personality research linking empathic concern, agreeableness, and prosocial orientation to enhanced moral sensitivity \cite{Haidt2012,Snow2010,Dancy2004}. In the experiment, these dispositional field differences predicted differential susceptibility to perturbation under synthetic presence—precisely what a virtue-theoretic model would anticipate.

\subsubsection*{(ii) Connection to Moral Psychology}

\noindent
Contemporary moral psychology emphasises that moral responsiveness depends on stable trait configurations.  
Research on moral foundations \cite{Haidt2012}, character-based accounts \cite{Snow2010}, and perceptualist theories of moral sensitivity \cite{Dancy2004,McDowell1979} all converge on the idea that moral judgment is a function of habituated perception.  

\noindent
The experimental data vindicate this insight. The humanoid robot did not uniformly attenuate behaviour; instead, attenuation varied by cluster:
\begin{itemize}
	\item strongest in the Prosocial--Empathic ecology (where affective gradients are steep and easily perturbed),
	\item weak but present in the Analytical--Structured ecology (where action is driven by stability rather than resonance),
	\item negligible in the Emotionally Reactive ecology (where gradients are shallow and noise-dominated).
\end{itemize}

\noindent
This pattern is exactly what virtue-theoretic topology predicts: \emph{where the field is most morally sensitive, it is most susceptible to perturbation}. The experiment therefore provides an empirical instantiation of a core virtue-theoretic claim: that character structure determines not only moral dispositions but the \emph{topology of susceptibility} to environmental modulation.


\subsection{Action-Guidance Mechanism: Habituation, Stability, and Situated Sensitivity}

\noindent
Virtue ethics explains action not by invoking explicit rules or outcome calculations but through the \emph{habituated patterns of salience, affect, and response} characteristic of a well-formed agent. This lines up directly with the dual-process architecture established in Chapter~\ref{chap:moral_primer}:  
\begin{itemize}
	\item intuitive, first-pass appraisals are shaped by long-term habituation into affective–perceptual sensitivities;
	\item controlled processes integrate commitments, identities, and reflective self-conceptions that stabilise these sensitivities over time;
	\item behavioural output reflects the depth or fragility of dispositional attractors.
\end{itemize}

\noindent
Topologically, virtues correspond to \emph{deep, well-curved attractor basins} resistant to perturbation; deficiencies correspond to \emph{shallow, volatile, or weakly integrated attractors}. This resonates with computational models of habit formation \cite{Wood2016} and empirical accounts of moral perception as a learned sensitivity \cite{Reynolds2006}.  

\noindent
Importantly for this thesis, the clusters identified in Chapter~\ref{chap:experimental_methods} instantiate precisely this kind of dispositional architecture: warm–prosocial participants exhibit steep affective gradients; analytical profiles show stable but less affective curvature; reactive profiles show shallow, noise-dominated dynamics.

\subsection{Virtue-Theoretic Topology: Stability, Curvature, and Susceptibility to Perturbation}

\noindent
Within the evaluative-topological model, virtue ethics can be expressed in dynamical-systems terms:
\[
\dot{x} = f(x;\beta_C),
\]
where \(x\) is the agent’s state in evaluative space and \(\beta_C\) parametrises dispositional curvature. Robotic co-presence introduces a perturbation
\[
\dot{x}' = f(x;\beta_C) + \delta f(x;\mathscr{R}),
\]
with $\mathscr{R}$ denoting synthetic presence.

\noindent
This formalism directly reflects the empirical pattern:
\begin{itemize}
	\item in the Prosocial--Empathic ecology, perturbation \(\delta f\) significantly shifts trajectories away from the prosocial basin, producing the strongest attenuation;
	\item in the Analytical--Structured ecology, attractor curvature is sufficient to absorb most of the perturbation, yielding only modest displacement;
	\item in the Emotionally Reactive ecology, shallow, unstable attractors produce minimal directional change—behaviour is already close to noise-level variation.
\end{itemize}

\noindent
This mapping from dispositional structure to perturbation susceptibility is precisely the kind of structure virtue theory predicts: character determines \emph{how} moral affordances are perceived and how perturbations are absorbed or amplified.

\subsection{Why Virtue Ethics Matters for the Experimental Logic}

\noindent
Virtue ethics is indispensable for interpreting the experimental results, for three reasons that integrate tightly with the Discussion chapter and set up the thesis conclusion.

\paragraph{1.\ Latent Trait Modulation: Explaining Cluster Differences}
The experiment demonstrates that robotic co-presence induces a \emph{field-level} perturbation whose \emph{impact} depends on dispositional topology. Virtue theory provides the conceptual vocabulary for this dependency. It explains why prosocial action is fragile in agents with shallow affective attractors, why highly empathic profiles show strong attenuation, and why analytical profiles exhibit relative resistance. The experiment therefore reveals a virtue-theoretic phenomenon: moral sensitivity is intrinsically \emph{trait-dependent}.

\paragraph{2.\ Character as the Medium of Moral Topology}
The mapping
\[
\beta_C \mapsto \mathcal{T}(\beta_C)
\]
shows that moral responsiveness is a function of trait geometry. Character shapes the curvature of the evaluative manifold, determining which cues stand out as morally salient and how the Watching-Eye prime interacts with background dispositions. Synthetic presence perturbs this trait-conditioned topology, yielding precisely the cluster-conditioned attenuation patterns identified earlier.

\paragraph{3.\ Machine Ethics Omits Dispositional Structure Entirely}
Classical Machine Ethics contains no representation of habituation, perceptual attunement, or trait-level topology. It models moral behaviour as rule-execution or utility optimisation, ignoring the dispositional substrate that governs real moral sensitivity. This makes it structurally incapable of predicting the experimental pattern:  
\emph{the strongest attenuation occurs precisely where the evaluative gradients are steepest—where moral sensitivity is highest}.  

This result is unintelligible on rule-based or utility-based models but follows naturally from a virtue-theoretic account of character topology.

\medskip

\noindent
In sum, virtue ethics interprets the experimental findings as demonstrating that synthetic agents perturb moral action by modulating the \emph{dispositional geometry} through which moral salience is processed. Deontology contributes boundary structure, consequentialism contributes gradient structure, but virtue ethics contributes the \emph{curvature of the evaluative manifold}: the habituated topology that determines how agents absorb, refract, or amplify perturbations.  

This sets the stage for the final normative lenses—sentimentalism, contractualism, and particularism—which illuminate additional dimensions of how synthetic presence reshapes the evaluative field investigated experimentally.

\section{Integrated Ethical Interpretation of the Experimental Results}
\label{sec:integrated_interpretation}

\noindent
With deontology, consequentialism, and virtue ethics reconstructed through the discipline of Levels of Abstraction and embedded within the evaluative–topological architecture developed in this thesis, we can now articulate their joint significance for the experimental findings. The aim is not to allocate explanatory priority but to show why a multi-framework normative analysis is \emph{required} if the behavioural perturbation induced by synthetic presence is to be ethically intelligible.

\subsection*{1.\ Deontology: Invariant Structure and the Integrity of Moral Expectation}

\noindent
On the deontological reconstruction, duties function as \emph{structural invariants} within the evaluative field. The Watching-Eye cue (see Chapter~\ref{chap:experimental_methods}) implicitly activates precisely these invariants: expectations of accountability, reciprocity, and fairness.

\noindent
When donation decreases in the Robot condition, the relevant normative question is not whether participants ``broke rules’’ but whether synthetic presence \emph{disrupted sensitivity} to these invariant structures:
\begin{itemize}
	\item If the robot attenuates uptake of deontic salience, the perturbation carries ethical significance beyond preference change.
	\item Because all explicit cues remain constant across conditions, any weakening of accountability sensitivity isolates $\mathscr{R}$ as a potential interference with deontic perception.
	\item Deontology therefore provides the vocabulary to distinguish superficial behavioural modulation from a deeper deformation in the agent’s grasp of duty.
\end{itemize}

\noindent
Thus, the deontological reading aligns with the empirical finding of uniform attenuation: synthetic presence does not introduce new norms; it suppresses the felt relevance of existing ones.

\subsection*{2.\ Consequentialism: Gradient Deformation and the Perceived Structure of Outcomes}

\noindent
From a consequentialist perspective, moral orientation depends on the perceived gradient of expected value. Watching-Eye cues steepen this gradient by increasing the anticipated social or reputational payoff of prosocial action.

\noindent
Synthetic presence perturbs this structure in three ways:
\begin{enumerate}
	\item by introducing an ambiguous observer whose evaluative stance is unclear, flattening outcome expectations;
	\item by competing with or overshadowing the reputational signal generated by the Watching-Eye stimulus;
	\item by transforming a dyadic human–target context into a triadic social configuration with uncertain evaluative implications.
\end{enumerate}

\noindent
In topological terms, $\mathscr{R}$ deforms the gradient landscape surrounding donation. The attenuation effect thus fits naturally within the consequentialist lens: prosocial movement becomes less strongly favoured because the perceived payoff slope has been locally flattened.

\subsection*{3.\ Virtue Ethics: Dispositional Curvature and Cluster-Dependent Susceptibility}

\noindent
Virtue ethics provides the most direct connection between normative theory and the empirical structure of the experiment. On the virtue-theoretic reconstruction, moral responsiveness depends on the agent’s \emph{dispositional curvature}: the depth, stability, and integration of their evaluative attractors.

\subsection*{Virtue-Ethical Interpretation of Latent Ecologies}

\noindent
Cluster analyses (Chapter~\ref{chap:experimental_methods}) revealed distinct evaluative ecologies:
\begin{itemize}
	\item \textbf{Prosocial--Empathic}: steep, affectively rich attractors; strong Watching-Eye response; moderate attenuation under $\mathscr{R}$.
	\item \textbf{Emotionally Reactive / Low-Structure}: shallow, unstable attractors; greatest susceptibility to perturbation.
	\item \textbf{Analytical--Structured}: stable but less affective curvature; small but systematic displacement when interpretive coherence is disrupted.
\end{itemize}

\noindent
These patterns are \emph{structurally predicted} by the virtue-theoretic framework:
\[
\dot{x}' = f(x;\beta_C) + \delta f(x;\mathscr{R}),
\]
where $f(x;\beta_C)$ represents each ecology’s dispositional dynamics and $\delta f(x;\mathscr{R})$ the perturbation induced by synthetic presence.

\noindent
Critically, $\delta f$ is not uniform. Its sign and magnitude depend on the curvature encoded by $\beta_C$:
\begin{itemize}
	\item for Prosocial--Empathic agents, $\delta f$ weakens empathic gradients;
	\item for Reactive agents, $\delta f$ amplifies existing volatility;
	\item for Analytical agents, $\delta f$ disrupts interpretive coherence rather than affective force.
\end{itemize}

\noindent
Thus, virtue ethics explains the \emph{cluster-dependent pattern} of attenuation: synthetic presence interacts with dispositional topology, not with explicit rules or outcome computation.

\subsection*{4.\ What Classical Machine Ethics Misses}

\noindent
This integrated reading exposes a core limitation of classical Machine Ethics:
\begin{enumerate}
	\item Treating deontic principles as behavioural algorithms misidentifies their LoA and cannot account for perturbations in deontic uptake.
	\item Treating utilities as generative of moral cognition ignores the role of salience and affect in shaping perceived gradients.
	\item Omitting dispositional topology leaves no framework for predicting cluster-dependent deformation or for understanding why the strongest attenuation occurs where empathic gradients are steepest.
\end{enumerate}

\noindent
Machine Ethics repeatedly commits the LoA confusion: it treats normative abstractions as if they were psychological operators. The experiment demonstrates that moral behaviour emerges instead from field-level dynamics that no monolithic framework can capture.

\subsection*{5.\ Concluding Perspective: Why a Multi-Framework Interpretation Is Necessary}

\noindent
The three reconstructed frameworks converge on a single insight: \textbf{synthetic presence reshapes the evaluative field through which moral salience becomes action}. Each theory captures a different dimension of this deformation:
\begin{itemize}
	\item deontology identifies disruptions to sensitivity toward invariant expectations;
	\item consequentialism identifies gradient flattening in perceived outcomes;
	\item virtue ethics identifies dispositional curvature as the mediator of susceptibility.
\end{itemize}

\noindent
The experiment therefore reveals not only that robots alter behaviour, but \emph{how} they do so: by deforming the topological substrate that links perception to moral action. This integrated interpretation provides the normative scaffolding for the sentimentalist analysis that follows, in which affective vector fields become central to explaining the immediate, pre-reflective dynamics of the perturbation.

\section{Sentimentalism and Emotion-Based Normativity: Affective Vector Fields in Moral Topology}
\label{sec:sentimentalism}

\noindent
Having reconstructed deontology as topological invariance and consequentialism as value-gradient optimisation, we now turn to the normative framework most directly implicated in the experimental results: \emph{sentimentalism}. In the sentimentalist tradition—Hume, Smith, and contemporary affect-based theorists—moral evaluation originates in \emph{patterns of affective resonance} \cite{HumeTreatise,Smith1759,Slote2010,Nichols2004}. Nodes of moral significance are detected not through principles or calculations but through the affective forces that structure our perceptual–social encounter with others.

\noindent
Within the evaluative–topological model, sentimentalism corresponds to an \textbf{affective vector field}:
\[
\mathbf{A}(x) : \mathcal{X} \to \mathbb{R}^n,
\]
where $\mathcal{X}$ is the space of perceived states and $\mathbf{A}(x)$ encodes the direction and magnitude of empathic pull, aversive push, compassion, warmth, or distress.

\noindent
This is not metaphorical. The experimental attenuation effect is realised precisely through the dampening of these affective vectors: synthetic presence reduces the strength of the empathic pull generated by the Watching-Eye cue, especially within ecologies where affective sensitivity ordinarily drives moral behaviour. In this sense, sentimentalism offers the most proximate normative interpretation of the perturbation mechanism revealed by the data.
\section{Sentimentalism and Emotion-Based Normativity: Affective Vector Fields in Moral Topology}
\label{sec:sentimentalism}

\noindent
Having reconstructed deontological invariants and consequentialist gradients, we now turn to the normative framework that most directly connects with the causal mechanism revealed by the experiment: \emph{sentimentalism}. In the sentimentalist tradition—Hume, Smith, and contemporary affect-based theorists—moral evaluation originates in the structured responsiveness of the affective system to features of the social world \cite{HumeTreatise,Smith1759,Slote2010,Nichols2004}. Moral distinctions are “more properly felt than judged” \cite{HumeTreatise}, not because sentiment replaces judgment, but because affective resonance is the primary medium through which moral salience is registered.

\subsection{The Source of Normativity: Sentiment as the Basis of Moral Appraisal}

\noindent
Sentimentalist normativity arises from patterns of affective response—empathy, warmth, aversion, indignation—that furnish the evaluative significance of morally relevant situations. This aligns closely with the cognitive LoA discussed in Chapter~\ref{chap:moral_primer}: affective tagging (amygdala; insula), empathic resonance (mPFC–TPJ), and rapid harm appraisal provide the first curvature of the evaluative field.

\noindent
Where deontology imposes constraints and consequentialism imposes gradients, sentimentalism specifies the \emph{affective geometry} of moral space: how warmth draws agents toward prosocial trajectories; how distress or fear generates repulsion; and how empathic concern shapes the topology through which moral meaning is experienced.

\subsection{Mode of Evaluation: Affective Resonance as Moral Metric}

\noindent
The sentimentalist mode of evaluation is grounded in:
\begin{itemize}
	\item \textbf{empathic responsiveness} to others’ welfare;
	\item \textbf{reactive attitudes} such as guilt, gratitude, and indignation;
	\item \textbf{affiliative and prosocial motivation};
	\item \textbf{interpersonal attunement} in shared affective contexts.
\end{itemize}

\noindent
This structure maps almost exactly onto the \textbf{Prosocial--Empathic / Warm--Sociable ecology}. Here, moral relevance is not merely recognised; it is \emph{felt}. Prosocial donation emerges as the behavioural manifestation of a strongly weighted affective vector field.

\noindent
If moral action is the integral of affective forces across the evaluative field, then any disturbance that reduces the amplitude of these forces will proportionally diminish prosocial behaviour. This is precisely the pattern observed in the experiment.

\subsection{Action Guidance: Affective Vector Fields and Behavioural Dynamics}

\noindent
Within the evaluative–topological model, sentimentalism becomes computationally explicit when expressed as a dynamical system:
\[
\dot{x} = f(x) + \mathbf{A}(x),
\]
where $f(x)$ encodes baseline evaluative drift and $\mathbf{A}(x)$ represents affective vectors.

\noindent
Synthetic presence introduces a deformation operator:
\[
\dot{x}' = f(x) + \mathbf{A}(x) + \delta \mathbf{A}(x;\mathscr{R}),
\]
where $\delta \mathbf{A}(x;\mathscr{R})$ attenuates or reorients affective flow.

\noindent
This model captures the empirical pattern with exceptional fidelity:
\begin{itemize}
	\item \textbf{Prosocial--Empathic}: $\delta \mathbf{A}$ dampens empathic activation, flattening the trajectory toward donation.
	\item \textbf{Emotionally Reactive}: $\delta \mathbf{A}$ destabilises an already volatile field, producing the strongest attenuation.
	\item \textbf{Analytical--Structured}: $\delta \mathbf{A}$ is comparatively weak; affect is not the dominant driver.
\end{itemize}

\noindent
In short, synthetic presence modulates the evaluative field by \emph{reducing affective curvature}—a canonical sentimentalist effect.

\subsection{Machine Ethics and the Blind Spot of Affective Architecture}

\noindent
Classical Machine Ethics is structurally incapable of recognising this mechanism. It replaces:
\begin{itemize}
	\item empathic resonance with rule sets,
	\item moral perception with logical inference,
	\item affective appraisal with propositional justification.
\end{itemize}

\noindent
But on a sentimentalist account, affect is not peripheral: it is the \emph{substrate} of moral cognition. Our experiment makes this omission explicit. A silent robot, devoid of speech or action, modifies behaviour not by altering rules or utilities, but by reshaping the affective vectors through which moral cues become behaviourally operative.

\noindent
Machine Ethics has no representational resources for modelling such perturbations. A sentimentalist topology does.

\subsection{Experimental Realisation: Synthetic Dampening of Empathic Resonance}

\noindent
The core empirical finding is that robotic co-presence attenuates prosocial donation even in the presence of a strong empathic cue (Watching-Eye stimulus). In sentimentalist terms, this corresponds to:
\[
\delta \mathbf{A}(x;\mathscr{R}) < 0,
\]
for affectively weighted regions of the evaluative field, where:
\begin{itemize}
	\item $x$ is the agent’s evaluative state;
	\item $\mathbf{A}(x)$ encodes empathic pull and related affective forces;
	\item $\mathscr{R}$ denotes robotic co-presence.
\end{itemize}

\noindent
This inequality states that $\mathscr{R}$ reduces the strength of affective forces driving prosocial action. The perturbation does not reverse moral direction; it \emph{dampens} the affective momentum that would otherwise support donation.

\noindent
Two mechanisms are plausible:
\begin{enumerate}
	\item \textbf{Affective dilution}: attention and empathic focus are partially diverted to an ambiguous social other.
	\item \textbf{Affective deflection}: ontological ambiguity disrupts the clarity of empathic pathways toward the child beneficiary.
\end{enumerate}

\noindent
Cluster differences appear as natural consequences:
\begin{itemize}
	\item \textbf{Prosocial--Empathic}: attenuation via diluted empathic resonance;
	\item \textbf{Emotionally Reactive}: attenuation via heightened volatility;
	\item \textbf{Analytical--Structured}: weak attenuation because affect is not primary.
\end{itemize}

\noindent
Sentimentalism therefore provides the most \emph{mechanistically precise} interpretation of the perturbation: synthetic presence alters the affective landscape that underwrites moral sensitivity.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title={Interpretive Synthesis: Sentimentalism and Synthetic Moral Perturbation}]
		\noindent
		The attenuation of prosocial behaviour under robotic co-presence is a paradigmatic sentimentalist phenomenon. In affectively driven ecologies, $\delta \mathbf{A}(x;\mathscr{R})$ dampens empathic resonance; in volatile ecologies, it amplifies instability; in structurally dominated ecologies, its influence is limited. These cluster-specific dynamics cannot be captured by rule-based or utility-maximising models. They require a framework in which affective forces are constitutive of moral cognition. Reconstructed as a vector-field theory of affective appraisal, sentimentalism thus offers the most direct normative interpretation of the experiment: synthetic presence deforms the affective topology through which moral salience becomes action.
	\end{tcolorbox}
\end{center}

\section{Contractualism, Particularism, and Hybrid Normative Models}
\label{sec:contractualism_particularism_hybrid}

\noindent
The preceding sections reconstructed deontological, consequentialist, and virtue-theoretic ethics as topological configurations of the evaluative field. To complete the normative architecture required for interpreting the experimental results, we now introduce three additional frameworks—\emph{contractualism}, \emph{particularism}, and \emph{hybrid or pluralist models}. Each is reconstructed briefly but with conceptual precision, and each is integrated into the LoA discipline and the evaluative-topological model that structures this chapter.

Two motivations justify their inclusion.  
First, these theories constitute major branches of contemporary ethics. Contractualism foregrounds interpersonal justification and mutual accountability \cite{Scanlon1998}; particularism emphasises contextual moral salience over general principles \cite{McDowell1979,Audi2015}; and pluralist approaches highlight the multidimensionality of moral reasons \cite{Doris2002}.  
Second, the experimental effects demonstrated in this thesis cannot be interpreted solely through invariants, gradients, or dispositional attractors. Rule-based invariants fail to capture context-dependence \cite{Morscher2002}, outcome-based gradients omit intuitive and affective dynamics \cite{Greene2001}, and virtue-theoretic attractors do not fully explain global field-level perturbations \cite{Doris2002}. Minimal cues of social evaluation—watching eyes, ambiguous agency, or robotic presence—modulate cooperation and prosociality across contexts \cite{Bremner2022,Francey2012,Kawamura2017,Malle2016}. These phenomena require frameworks that can model justification pressure, situational salience, and relational moral dynamics.

\noindent
\textit{Their inclusion is therefore methodological rather than ornamental.} A thesis that aims to integrate ethical theory with empirical results and computational structure must preserve continuity with the normative canon. Without these frameworks, the chapter would lack both systematic coverage and the conceptual resources needed to situate the experimental findings within the full contemporary landscape of moral theory.

%------------------------------------------------------------
\subsection{Contractualism: Moral Claims as Justification-Equilibria}
%------------------------------------------------------------

\noindent
Contractualism, classically articulated by Scanlon~\cite{Scanlon1998}, grounds moral rightness in the requirement that one’s actions be justifiable to others on principles that no one could reasonably reject. The \emph{source of normativity} is thus located not in rules, welfare, or character, but in the relational structure of mutual accountability.

In the LoA framework, contractualism occupies the reflective normative LoA: it specifies the standards according to which agents can regard themselves as standing in legitimate moral relations. Yet contractualist justification presupposes cognitive capacities—sensitivity to others’ perspectives, empathic uptake, and the perception of oneself as under evaluative regard.

\medskip

\noindent
\textbf{Topological interpretation.}  
Contractualism can be expressed as defining \emph{justificatory equilibria} in the evaluative field: regions where an action can withstand the test of mutual recognisability and reasonable non-rejection. Scanlon emphasises the interpersonal nature of moral motivation \cite{Scanlon1998}, while Strawson’s analysis of reactive attitudes highlights that accountability presupposes recognition of others as answerable participants \cite{Strawson1962}. These equilibria remain stable only when agents perceive themselves as situated within a network of evaluative regard.

Synthetic presence interacts with this structure in a distinctive way. Watching-eye cues typically heighten the salience of interpersonal accountability, increasing prosociality by intensifying the sense of being answerable to others \cite{Francey2012,Kawamura2017}. A humanoid robot, however, is perceptually social yet ontologically ambiguous. Empirical work shows that such agents can elicit social facilitation while failing to occupy stable interpersonal roles \cite{Bremner2022,Malle2016}. The result is a perturbation of the justificatory field: the implicit sense of being under the evaluative regard of others is displaced or diluted.

\medskip

\noindent
\textbf{Relevance to the experimental findings.}  
Contractualism illuminates why the Prosocial--Empathic ecology exhibited strong attenuation under robotic presence. Individuals in this ecology are dispositionally sensitive to accountability cues and interpersonal evaluation \cite{Cialdini2007}. Under ordinary conditions, the Watching-Eye cue amplifies mutual recognisability and reinforces justificatory pressure to donate \cite{Francey2012,Kawamura2017}.  
The robot, however, disrupts this justificatory equilibrium: although it triggers social cognition, it does not reliably anchor interpersonal accountability. Its ambiguous status—neither fully agentic nor normatively irrelevant—diminishes the perceived field of mutual evaluative regard \cite{Malle2016,Carpenter2016}. Donation declines not because duty is overridden, nor because consequences are miscalculated, but because the justificatory landscape loses structural integrity.

Thus contractualism interprets the displacement effect as a \emph{deformation of interpersonal accountability}: a weakening of the conditions under which reasons become mutually recognisable and moral motivations are sustained.

\subsection{Moral Particularism: Contextual Salience and the Fragmented Topology of Reasons}

\noindent
Moral particularism rejects fixed principles, stable evaluative gradients, and invariant reason-valences. On this view, what counts morally in a situation is entirely context-dependent: a consideration that favours an action in one case may count against it in another \cite{Dancy2004}. McDowell’s perceptual account makes the same point in phenomenological terms: moral salience emerges from the concrete situation rather than from any codifiable rule \cite{McDowell1979}. Work in moral epistemology reinforces this picture, emphasising that evaluative uptake is governed by context-sensitive attention rather than generalisable principles \cite{Audi2015}.

\noindent
In evaluative-topological terms, particularism corresponds to a landscape without global invariants or fixed gradients. Instead, the moral field is composed of \emph{local salience contours} that continually shift with changes in attention, affect, and perceptual framing. Empirical research in moral psychology supports this: intuitive responses, perceptual cues, and distributed cognitive processes dynamically determine which features of a situation are experienced as morally significant \cite{Haidt2001,Greene2001,Narvaez2005}. Moral appraisal, on this account, is a matter of context-sensitive responsiveness, not rule-following nor global optimisation.

\medskip

\noindent
\textbf{Synthetic perturbation under particularism.}  
If the evaluative landscape is locally assembled, then synthetic presence need not override a stable map—indeed, there may be no stable map to override. Instead, the robot reshapes the \emph{local salience geometry} through which the situation is initially apprehended.

Watching-eye cues heighten accountability salience almost immediately \cite{Francey2012}, but the introduction of a humanoid robot modifies attention, affect, and perceived agency in more ambiguous ways \cite{Bremner2022,Malle2016,Carpenter2016}. The result is not a shift in principle or outcome assessment, but a reordering of which cues enter the evaluative episode first. Social Signal Processing shows that socially meaningful agents exert bottom-up pressure on attentional allocation \cite{Pentland2007,Vinciarelli2012}, and HRI studies demonstrate that even minimal humanoid cues redirect gaze and reorganise the perceptual field \cite{Mutlu2009,Admoni2017,Krach2008}. Emotion- and attention-based research similarly shows that agentive or affectively salient stimuli suppress competing cues \cite{Bargh1999,Phelps2006,Zaki2012}.

In this topological setting, synthetic presence functions as a local perturbator: it alters what becomes salient, how quickly, and for how long. For the Prosocial--Empathic cluster, the Watching-Eye stimulus typically heightens empathic attunement and interpersonal accountability. But the robot’s ambiguous interpersonal status—neither fully social nor fully inert—introduces a conflicting source of salience that partially eclipses the eye cue. The result is attenuated empathic uptake and reduced prosocial behaviour. This matches perceptual accounts in which the ordering and persistence of salience are constitutive of the evaluative episode itself \cite{McDowell1979,Slote2010}.

For the Emotionally Reactive cluster, the picture is different. Their evaluative fields are already dominated by situational micro-variability; the robot introduces noise, but not disruption relative to an already-fluid topology. This is exactly what particularism predicts: the more context-sensitive the agent, the weaker the relative effect of an additional perturbation.

\bigskip

%------------------------------------------------------------
\subsection{Hybrid and Pluralist Models: Multidimensional Evaluative Topologies}
%------------------------------------------------------------

Hybrid or pluralist theories—from Ross’s irreducible prima facie duties \cite{Ross2002} to contemporary value pluralism \cite{Chang2013}—hold that normativity arises from multiple independent sources. Moral assessment is shaped by the interplay of constraints, outcomes, character, relationships, and contextual considerations \cite{Griffin1986,Stocker1990,Korsgaard2009,Scanlon1998}. No single evaluative dimension dominates.

Topologically, pluralism corresponds to a \emph{multi-dimensional evaluative manifold}. Rather than a single axis of moral value, the evaluative field contains intersecting constraints, gradients, attractors, and salience structures. Psychological and neurocognitive research supports this picture: affective intuitions, rule-based processes, and outcome-tracking mechanisms operate semi-independently and interact dynamically in judgment \cite{Haidt2001,Greene2001,Churchland2011}. Moral appraisal is thus the navigation of a field shaped by heterogeneous normative forces.

\medskip

\noindent
\textbf{Why pluralism fits the experimental results.}  
The experimental displacement effect is best understood as a \emph{manifold-level perturbation}. Each normative dimension is involved:

\begin{itemize}
	\item Watching-eye cues activate deontic expectations (public accountability).  
	\item Donation expresses consequentialist gradients (welfare benefits).  
	\item Cluster-level differences reflect virtue-theoretic dispositions.  
	\item The robot refracts interpersonal meaning (contractualist disruption).  
	\item Salience competition reflects particularist sensitivity to context.  
\end{itemize}

No single theory predicts the uniform attenuation across clusters. Instead, the results indicate that synthetic presence modulates several normative gradients simultaneously. The robot alters empathic resonance, perceived accountability, attentional competition, and expected social payoffs at once \cite{Malle2016,Komatsu2016,Krach2008,Carpenter2016,Bremner2022,Groom2010}. The Watching-Eye effect, ordinarily robust, is dampened by competing social signals—precisely the pattern revealed in studies of accountability cues and attentional capture \cite{Francey2012,Kawamura2017,Phelps2006,Zaki2012,Pentland2007,Vinciarelli2012}.

The experiment thus provides empirical grounding for the core claim of normative pluralism: moral judgment emerges from the configuration of multiple evaluative dimensions, each susceptible to contextual perturbation \cite{Ross2002,Chang2013,Scanlon1998}. The robot’s presence produces a field-level reconfiguration, not merely a shift in a single evaluative axis.

\medskip

\noindent
\textbf{Pluralism and dispositional structure.}  
This field-level displacement does not contradict the stable trait differences revealed by the clustering analysis. The clusters represent distinct \emph{starting positions} within the manifold—different dispositional orientations that shape ordinary evaluative navigation. But the robotic perturbation acts on the \emph{shared topology} of the field itself. This is why all clusters, despite psychological divergence, show a consistent directional attenuation. Dispositions shape baseline trajectories; synthetic presence reshapes the manifold in which those trajectories unfold.

In pluralist terms, the robot perturbs the evaluative manifold, not the individual gradients. The cluster analysis and the displacement effect therefore capture complementary layers of moral cognition: enduring dispositional geometry and context-sensitive field-level modulation.

\subsection{Integrative Ethical Interpretation of the Experimental Findings}

\noindent
Bringing the reconstructed frameworks together, we can now articulate the ethical significance of the experimental results in a manner that reflects both the normative pluralism developed throughout this chapter and the dual-layer structure of moral cognition revealed empirically. The attenuation of prosocial donation under robotic co-presence does not arise from the weakening of a single moral principle or evaluative dimension. Rather, it reflects a \emph{global perturbation} of the evaluative field—the structured moral ecology in which diverse moral reasons are ordinarily weighted, integrated, and rendered behaviourally operative.

\begin{enumerate}
	\item \textbf{Deontological lens: weakened accountability cues.}  
	The robot diminishes the felt presence of a morally relevant observer, thereby attenuating the duty-oriented accountability that the Watching-Eye cue is designed to amplify. The displacement effect indicates a disruption in the implicit normative expectations that scaffold rightful agency, rather than a violation of explicit moral rules.
	
	\item \textbf{Consequentialist lens: flattened outcome gradients.}  
	Synthetic presence alters the perceived payoff structure of helping. Reputational, affective, and interpersonal “returns” become less sharply defined, flattening the gradient that normally favours donation. Altruistic output declines not because agents miscalculate utility, but because the social-evaluative topology itself has shifted.
	
	\item \textbf{Virtue-theoretic lens: dispositional curvature under field-level modulation.}  
	The perturbation does not target trait-based motivations directly. Instead, it reveals that even robust dispositional architectures—captured in the psychometric clusters—are expressed \emph{within} an evaluative field susceptible to contextual deformation. The uniform directional shift in donation across clusters demonstrates that character is not a self-contained engine of action but a gradient embedded in a modifiable field.
	
	\item \textbf{Contractualist lens: disrupted justificatory equilibrium.}  
	Contractualist motivation depends on recognising the presence of others to whom reasons are owed. The robot introduces ambiguity into this interpersonal field, weakening the sense of mutual answerability. The justificatory landscape becomes noisier and less structured, reducing the force of the requirement to act in ways that others could not reasonably reject.
	
	\item \textbf{Particularist lens: reconfigured salience geometry.}  
	The robot alters the fine-grained pattern of contextual salience. The Watching-Eye cue remains physically present, but its normative traction is displaced by a new and ambiguous source of social meaning. What becomes salient first—and for how long—changes, thereby altering the evaluative episode itself.
	
	\item \textbf{Pluralist-topological lens: manifold-level displacement.}  
	The findings are precisely what a pluralist model predicts when multiple normative gradients interact with a global perturbation to social meaning. The donation attenuation reflects not the suppression of a single evaluative dimension but a deformation of the multi-dimensional evaluative manifold. This explains both the robustness and the cross-cluster consistency of the effect.
\end{enumerate}

\noindent
Taken together, these interpretations converge on a unified thesis:

\begin{center}
	\begin{tcolorbox}[colback=white, colframe=black!60,
		title=Integrative Conclusion: The Ethical Signature of Moral Displacement]
		The presence of a humanoid robot reshapes the multi-dimensional evaluative 
		topology through which moral salience becomes action. This perturbation operates 
		at the level of the evaluative field itself, modulating deontic expectations, 
		consequentialist gradients, dispositional attractors, justificatory relations, 
		and contextual salience structures simultaneously. No monolithic ethical 
		framework captures this phenomenon. The experimental results therefore vindicate 
		a pluralist, topological, empirically grounded model of moral cognition—revealing 
		how synthetic agents can globally displace moral evaluation in ways systematically 
		overlooked by classical Machine Ethics.
	\end{tcolorbox}
\end{center}

\noindent
By reconstructing the major normative theories through Levels-of-Abstraction discipline and embedding them within a topologically structured model of moral cognition, this chapter has provided the conceptual architecture required to understand the ethical significance of synthetic moral perturbation. The experiment demonstrates how such perturbation manifests as a field-level displacement effect, thereby integrating normative theory, cognitive psychology, and computational modelling into a unified account of how artificial agents reshape the evaluative terrain of human moral behaviour.

