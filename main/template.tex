\documentclass[review]{elsarticle}
%\documentclass[final,3p]{elsarticle}

%%%%%%%%%%%%%%%%%%%%%%%%%%
% Remove this for adding lines in abstract and keywords
% %%%%%%%%%%%%%%%%%%%%%%%%
\makeatletter
  \long\def\pprintMaketitle{\clearpage
  \iflongmktitle\if@twocolumn\let\columnwidth=\textwidth\fi\fi
  \resetTitleCounters
  \def\baselinestretch{1}%
  \printFirstPageNotes
  \begin{center}%
 \thispagestyle{pprintTitle}%
   \def\baselinestretch{1}%
    \Large\@title\par\vskip18pt
    \normalsize\elsauthors\par\vskip10pt
    \footnotesize\itshape\elsaddress\par\vskip36pt
    % \hrule\vskip12pt
    % \ifvoid\absbox\else\unvbox\absbox\par\vskip10pt\fi
    % \ifvoid\keybox\else\unvbox\keybox\par\vskip10pt\fi
    % \hrule\vskip12pt
    \end{center}%
  \gdef\thefootnote{\arabic{footnote}}%
  }
  
%%%%%%%%%%%%%%%%%%%%%%%%%%
% This controls the bottom runner
% %%%%%%%%%%%%%%%%%%%%%%%%
 
 \def\ps@pprintTitle{%
 \let\@oddhead\@empty
 \let\@evenhead\@empty
 \def\@oddfoot{\hfill\footnotesize\itshape F. Perrone}%
 \let\@evenfoot\@oddfoot}
 
 \renewcommand{\MaketitleBox}{%
  \resetTitleCounters
  \def\baselinestretch{1}%
  \begin{center}
    \def\baselinestretch{1}%
    \Large \@title \par
    \vskip 18pt
    \normalsize\elsauthors \par
    \vskip 10pt
    \footnotesize \itshape \elsaddress \par
  \end{center}
  \vskip 12pt
}
 %%
 
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%
% End title modifications
% %%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{lineno,hyperref}
\modulolinenumbers[20]

\journal{Journal of \LaTeX\ Templates}

%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{graphicx}

%%%%%%% MY PERSONAL SETTINGS %%%%%%%
\usepackage{xspace}
\newcommand{\ie}{\emph{i.e.}\@\xspace}
\newcommand{\eg}{\emph{e.g.}\@\xspace}
\newcommand{\nextdiv}{\vspace{2mm}\noindent}

%%%%%%% MY PERSONAL NOTES %%%%%%%
\usepackage{xcolor}
\usepackage{hyperref}
\definecolor{fpgreen}{HTML}{A6D609}
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\fpcom}[1]{\vspace{2mm} \todo[inline, size=\scriptsize, color=fpgreen!80]{\textbf{FP}: #1}}
\newcommand{\fpincom}[1]{\todo[size=\tiny, color=fpgreen!80]{\textbf{FP}: #1}}

\usepackage{enumitem} % For customizing list
%\usepackage{geometry} 

\begin{document}

\begin{frontmatter}

\title{The title\tnoteref{mytitlenote}}
%\tnotetext[mytitlenote]{Fully documented templates are available in the elsarticle package on \href{http://www.ctan.org/tex-archive/macros/latex/contrib/elsarticle}{CTAN}.}

%% Group authors per affiliation:
%\author{Francesco Perrone\fnref{myfootnote}}
\author{Francesco Perrone}
\address{Glasgow, UK}
\author[]{University of Glasgow}
\author[]{School of Computing Science}
%\fntext[myfootnote]{Since 1880.}
%% or include affiliations in footnotes:
%\author[mymainaddress,mysecondaryaddress]{University of Glasgow}
%\ead[url]{www.elsevier.com}

%\author[mymainaddress]{School of Computing Science}
%\corref{mycorrespondingauthor}}
%\cortext[mycorrespondingauthor]{Corresponding author}
%\ead{support@elsevier.com}
%\address[mymainaddress]{Sir Alwyn Williams Building, Glasgow}
%\address[mysecondaryaddress]{360 Park Avenue South, New York}

%\begin{abstract}
%This template helps you to create a properly formatted \LaTeX\ manuscript.
%\end{abstract}

%\begin{keyword}
%\texttt{elsarticle.cls}\sep \LaTeX\sep Elsevier \sep template
%\MSC[2010] 00-01\sep  99-00
%\end{keyword}

\end{frontmatter}

\newpage
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is for draft numbering
% %%%%%%%%%%%%%%%%%%%%%%%%
\linenumbers
% Some introductionary text without a precise place just yet

%One of the main contribution give by modern Social Cognition is the large experimental evidence of the fact that humans' inferences directed to the execution of certain behaviours happen without precise, and clear, a priori \textit{conscious} decision, i.e. without conscious and situated rational deliberation processes.

\newpage
\section{Forewords}
\newpage
\section{Introduction}
The research presented here examines the role of experimental methodologies as a new tool for investigating prosocial behaviour and moral deliberation in the field of Machine Ethics. We show that these methodologies allow us to study how such behaviors manifest under the subtle yet controlled influence of robots coexisting with humans. In particular, we describe how the mere presence of a non-interactive machine can shape ethical deliberation and prosocial behavior, through perceived observation under controlled experimental settings.

\nextdiv
Withal, we outline two main research activities that we conducted, in the field of Machine Ethics:

\begin{enumerate}[label=\alph*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	\item \textbf{An experimental activity} about the interplay between the presence of social robots and human prosocial behaviour.
	\item \textbf{A comparative analysis of the literature} that suggests the emergence of the following:
	\begin{enumerate}[label=\Roman*.]
		\item Two related, but distinct, research themes in Machine Ethics which we call Human-Machine Ethics and Computational Machine Ethics.
		\item The emergence of two distinct trends in Psychology and Philosophy, \ie cognitive/affective models of moral judgments and rationalism/intuitionist approaches to moral reasoning, that exert a deep influence on the research objectives and methodologies in Computational Machine Ethics.
	\end{enumerate}
\end{enumerate}


\nextdiv
Furthermore, following the analysis in a) and evidences in b) we will argue in favour of the adoption of new research methodologies in Computational Machine Ethics (a subfield of Machine Ethics) that should follow recent experimental evidences in support of models of moral judgements as aﬀect-laden intuitions (explained below). This model of moral reasoning has not yet been taken into consideration in any of the work done in Machine Ethics up to date.

\nextdiv
The most interesting implications of such a turn for Computational Machine Ethics would arguably be the following:

\begin{enumerate}[label=\arabic*)\,, leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	
	\item  The possibility to design experiments that quantify diﬀerences in moral attitudes
	through the measurable outcomes of decisions made by subjects at least in a controlled
	setting (i.e. experiments);
	\item The possibility of analysing moral decisions through measuring behaviour, which in
	turn lends itself to the application of Social Signal Processing and Aﬀective Computing
	methodologies to the investigation of moral deliberation, its analysis and automation.
\end{enumerate}

\nextdiv
On this account, the following two questions were addressed during the course of this research, forming the basis of the intended \textit{research statements}:


\begin{enumerate}[label=(Q\arabic*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	
	\item  Does the presence of social robots change the outcome of decisions made by humans?
	\item  Do moral decision leave physical traces in terms of observable, machine detectable
	behavioural cues?
\end{enumerate}

\nextdiv
Q1 refers mainly to point 1, and will shows that it is possible to explore whether principles and laws underlying Moral Psychology apply to Computational Machine Ethics.

\nextdiv
Q2 refers mainly to point 2, and will show that it is possible to apply existing social and psychological approaches for improving the investigation and validation of theories of human moral behaviour.

\nextdiv
The remainder of this work is organized as follows. [...]
\newpage
\section{Moral Judgement}
\label{sec:moral}
\newpage
\section{Machine Ethics}

Over the past decade, the field of Machine Ethics—an area of inquiry concerned with the moral dimensions of artificial systems—has garnered significant attention from the scientific community. \fpincom{Good, now the problem is the start and structure of the next portion of text but one step at time! Keep nextdiv for next portion. It's good to have a division like this. Remember the focus is to introduce ME as soon as we open.}

\nextdiv
The growing prominence of Machine Ethics within the scientific community is evidenced by multiple indicators. A bibliometric analysis of AI and ethics publications revealed a significant rise in research output, with over 1,500 papers published by mid-2021 and a marked acceleration from 2014 onward \cite{Chuang2022}. Foundational works, such as Anderson and Anderson’s Machine Ethics (2011), have played a pivotal role in catalyzing this interest by providing early frameworks for exploring the moral capabilities of artificial systems \cite{Anderson2011}.

\nextdiv
This trend is further underscored by the institutionalization of AI ethics as a recognized academic discipline. A keyword analysis spanning two decades identifies 2014 as a pivotal year, marking a surge in academic engagement with terms related to Machine Ethics and the ethical dimensions of AI research \cite{Gao2024}. The increasing focus on these issues is reflected in the growing body of literature addressing topics like transparency, accountability, and human oversight in autonomous systems \cite{Wallach2008}.

\nextdiv
Finally, recent meta-analyses highlight the expansion of Machine Ethics as a domain of inquiry, capturing the attention of researchers and practitioners alike. For example, Otterbacher \textit{et al.} (2023) discuss the heightened focus on ethical challenges posed by AI, particularly over the past decade \cite{Otterbacher2023}. Together, these developments illustrate a clear trajectory of growth and consolidation, establishing Machine Ethics as an area of significant and sustained interest within the scientific community.

\nextdiv
Truth be told, Machine Ethics, as a term and filed, encompasses a wide range of ethical considerations related to machines, often leading to conflation of distinct issues. To address this, the domain of Machine Ethics is redefined through the integration of philosophical traditions and insights from Moral Psychology. This redefinition establishes a clear vocabulary and experimental framework for investigating how the mere presence of robots influences human moral deliberation and prosocial behavior. Grounded in empirical methodologies, this approach positions Machine Ethics as a critical intersection of ethical theory and moral psychology, advancing the understanding of the nuanced dynamics between humans and intelligent systems

A detailed comparative analysis of the literature on Machine Ethics and related academic disciplines, such as Philosophy and Moral Psychology, highlights a relationship that forms the basis for classifying two distinct research paradigms within Machine Ethics.

Machine Ethics can be divided into two primary areas of focus. The first, termed \textit{Human-Machine Ethics}, examines ethical considerations for humans, centering on behavior in relation to AI and robotic systems. This area addresses societal responsibilities, ethical dilemmas, and legal implications surrounding the deployment and use of AI technologies. The second area, referred to as \textit{Computational Machine Ethics}, focuses on designing systems capable of autonomous moral reasoning, enabling them to operate within predefined ethical parameters.


In most cases, the ethics of AI focuses on the socio-economic, and legal impacts of AI and, the moral and ethical issues surrounding the use of these systems. 


Machine Ethics is the subfield of Computer Science that develops methods and theories aimed at enabling machines to interact morally with their users in real-world scenarios~\cite{Anderson2011, Nallur2020, Pereira2020, Tolmeijer2020}.  For some, \textit{the new field} of Machine Ethics is concearned with giving machines ethical procedures for discovering ways to resolve the ethical problems that \textit{they might encounter}, thus enabling them to function through their own ethical decision~\cite[pp. i - iv]{Anderson2011}. Unlike Computer and Information Ethics, which refer to the application of various ethical thoeries (\eg utilitarianism, Kantianism, virtue ethics) to cases that significantly involve computers and computer networks, or to ethical issues surrounding human use of machines~\cite{Bynum2018}, the ultimate goal of Machine Ethics, is to create machines that follow an ideal ethical principle or a set of principles; that is to say, it is guided by this principle or these principles in decisions it makes about possible courses of action it could take. 

Machine Ethics concears the behaviours of complex , autonomus systems, towards humans~\cite{Otterbacher2023}

While this work may be classified as technical, I assume readers possess a basic understanding of certain non-technical concepts, such as artificial intelligence and autonomous intelligent systems. For technical terminology mentioned throughout, I provide concise definitions to clarify their context.


\nextdiv
A central reason for this trend is an unprecedented interdisciplinarity: researchers in Machine Ethics are now capable of freely drawing on scientific resources and experimental data from well beyond the confines of their fields~\cite{Anderson2011}, which can now be integrated into Artificial Intelligence (AI) technologies. Machine Ethics could be thought as a laboratory to verify and generalise, philosophical small-scale theories and thought experiments, which have heavily characterised and shape the work in this field up until now~\cite{Allen2006, allen2012}


\fpcom{this should be part of the closing remarks to introduce the experiment.}
\nextdiv
In Floridi's view~\cite{Floridi2004}, machines that exibit such capabilities for moral deliberaiton, needs to be moral agents in the sense that they should be capable of performing actions with moral significance whcih in turn is define by two primary criteria.

\begin{enumerate}[label=(P\arabic*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	\item \textbf{Autonomy}.  A moral agent must have the ability to act independently and make choices that are not entirely determined by external forces. Autonomy entails intentionality, which means the agent acts with a purpose or goal in mind. A moral agent must be capable of being held accountable for its actions. 
	\item \textbf{Responsibility} This accountability implies that the agent understands the consequences of its actions and can justify them within a moral framework. robots or algorithms, as they can act in ways that significantly affect the moral landscape. However, he acknowledges that their "agency" is limited and derivative because they lack intrinsic moral intentionality, functioning instead within parameters set by human designers.
\end{enumerate}
 
\nextdiv
A moral patient, in contrast, is an entity that can be affected by the actions of a moral agent and therefore deserves moral consideration. Floridi emphasizes: 

\begin{enumerate}[label=(P\arabic*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	\item \textbf{(Intrinsic Worth)}Moral patients have value in and of themselves and must not be treated merely as a means to an end (echoing Kantian ethics).
	\item \textbf{Vulnerability} Moral patients are characterized by their capacity to be harmed or benefited. This includes humans, animals, ecosystems, and increasingly, informational entities (e.g., data or digital environments).
	\item  \textbf{Inclusiveness} Floridi's framework expands traditional moral boundaries. He argues for considering entities like artificial agents and digital ecosystems as potential moral patients, based on their capacity to be affected within the infosphere. 
\end{enumerate}

Floridi's theory is particularly relevant in the context of the infosphere, a term he uses to describe the informational environment we live in, including digital and physical realms. He introduces the concept of distributed morality:

\begin{enumerate}[label=\alph*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	\item Actions are no longer confined to individual moral agents but are distributed across networks of human and non-human actors.
	\item For instance, a decision made by an algorithm (moral agent) might impact a user (moral patient) in ways that require ethical scrutiny.
\end{enumerate}

Floridi moves beyond anthropocentric (human-centered) ethics to advocate for ontocentric (being-centered) ethics, where all entities with intrinsic worth, including informational and digital entities, are considered. By redefining moral agents and patients, Floridi expands moral responsibility to include designers and users of technology, artificial agents with decision-making capabilities, and vulnerable systems in the infosphere. Floridi’s theory is grounded in information ethics, where the fundamental moral value is the "flourishing of the infosphere." Harm is understood as any action that degrades the informational integrity or flourishing of an entity. The implications are Floridi's framework suggests that as AI becomes more integrated into society, its role as a moral agent and its impact on moral patients (users, ecosystems, etc.) must be carefully managed. The inclusion of ecosystems and informational entities as moral patients aligns with broader discussions on environmental ethics and sustainability. By emphasizing distributed morality, Floridi’s theory calls for collaborative responsibility in technology design, governance, and ethical AI deployment. In summary, Floridi's theory redefines moral agents and patients to address the complexities of modern, interconnected environments, emphasizing responsibility, inclusiveness, and the flourishing of all entities within the infosphere.
\newpage
\section{Section}

This thesis investigates moral reasoning as it manifests under the subtle yet controlled influence of human-robot coexistence, an experimental terrain where ethical principles encounter observable behavior, under robotic observation. While it does not directly engage with the philosophical history or psychological foundations of morality, it draws upon both to establish the conceptual framework and terminology necessary to understand how machines might influence human ethical decision-making through a deliberately non-interactive experimental setting that invites participants to confront ethical scenarios under robotic observation.



\nextdiv
Central to this investigation are precise questions concerning the influence of human-robot interactions on moral reasoning: How do autonomous systems shape ethical decision-making in humans? What are the mechanisms through which robots alter perceptions of what is morally right or wrong? How can experimental methodologies illuminate these processes with empirical clarity? Addressing these questions requires a robust foundation in defining moral reasoning, first through a philosophical lens that considers consequentialist, deontological, and virtue ethics traditions, and then through the perspective of moral psychology, which examines the cognitive and emotional processes underlying ethical judgments. These frameworks collectively enable a systematic exploration of how human-robot interactions inform and reshape our understanding of morality.

\nextdiv
Moral reasoning, as a species of practical reasoning, is the deliberative process directed towards deciding what to do, ultimately culminating in a judgment and, when successful, issuing in an intention. In this context, moral judgment represents the evaluative conclusion of reasoning, bridging deliberation and action. This thesis adopts this dual perspective, integrating philosophical frameworks such as deontology and virtue ethics with psychological theories of intuitive and deliberative reasoning, to examine how autonomous systems influence these processes in human decision-making.

While moral reasoning can be undertaken on another’s behalf, it is paradigmatically an agent’s first-personal (individual or collective) practical reasoning about what, morally, they ought to do. Philosophical examination of moral reasoning faces both distinctive puzzles – about how we recognize moral considerations and cope with conflicts among them and about how they move us to act – and distinctive opportunities for gleaning insight about what we ought to do from how we reason about what we ought to do.

We can use the map shown in Figure~\ref{fig:moral_judgements} to captures foundational distinctions in the realm of judgments, particularly as they relate to moral philosophy and psychology. The map reflects central philosophical inquiries: What is true (factual)? What is right or wrong (moral)? What ought to be done (normative)?

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{"../img/maps/typesOfJudgements_corrections.pdf"}
	\caption{Diagram of Types of Judgements.}
	\label{fig:moral_judgements}
\end{figure}



\paragraph{Paragraph}
\paragraph{Paragraph} 
%\section{Bibliography}
% \section*{References}
\newpage
\bibliographystyle{ieeetr}
\bibliography{/Users/francesco/Desktop/research/appunti/reference.bib}
\newpage
\section*{Notes}
\paragraph{Robot Details and Role}The experiment involved the NAO humanoid robot in an autonomous life setting, specifically simulating a breathing animation. This design aimed to give participants the impression of being observed subtly. This was core to the experiment, as it replicated the watching eye effect without direct interaction.

\paragraph{Impact of Robot Presence} The robot's presence in the room was intended to explore its influence on prosocial behavior, particularly in the context of moral decision-making, measured by charitable donations. The participants were unaware beforehand that a robot might be present or that donations would be part of the taks.

\paragraph{Social Cognition} Social Cognition is a field of study that investigates how individuals perceive, interpret, and respond to social stimuli and interaction \ie, events, actions, or signals in a social environment that influence individuals' behaviors and responses \fpincom{Fiske2020, Baron2012}, encompassing the processes by which people understand themselves and others. It emphasises both the automatic and deliberate aspects of social interactions, with a focus on how cognitive processes operate in social contexts.

\nextdiv
In early 2000, Jonathan Haidt in~\cite{Haidt2001} laid the foundation of the Social Intuitionist Model (SIM) understanding how moral judgments are primarily driven by quick, automatic intuitions rather than deliberate reasoning processes. SIM contracts traditional models of moral reasoning, empathising the subconscious and socially intuitive nature of moral behaviour. This shift was important in highlighting the intuitive nature of moral reasoning which contrasted the established belief that reasoning was the main driver of moral-decision making. After Haidt’s theoretical introduction, a series of empirical studies supported and expanded upon his claims. 

\nextdiv
Greene et al. conducted fMRI studies to explore the neurological basis of moral decision-making, providing empirical support for Haidt's model. Their findings demonstrated that emotional regions of the brain were more active during moral dilemmas involving personal engagement (e.g., in "trolley problems"). Greene's 2001 paper, "An fMRI Investigation of Emotional Engagement in Moral Judgment," found that emotionally engaging dilemmas activated brain regions linked to emotion, reinforcing Haidt's idea that emotions, rather than rational deliberation, often drive moral judgments.

\nextdiv
In 2004, Greene expanded this work with the study, "The Neural Bases of Cognitive Conflict and Control in Moral Judgment," demonstrating that rational control is often secondary to emotional intuitions in moral scenarios. Greene's later works, such as his 2008 paper, integrated a dual-process theory that further solidified Haidt’s ideas by showing that moral judgment is influenced by both intuitive/emotional and rational/cognitive processes. This model helps reconcile instances where rational deliberation plays a role, complementing Haidt’s initial SIM by illustrating a spectrum between automatic intuitions and deliberate reasoning.

\nextdiv
\textit{Other researchers contributed by showing how automatic, unconscious processes play a central role in moral judgment, which supported Haidt's position. Studies on priming effects in moral decision-making illustrated how subtle cues could shift moral judgments without individuals being consciously aware of these influences.}

\nextdiv
One of the main contributions to SIM comes from provided by modern Social Cognition that provides a vast experimental evidence that human inferences leading to the execution of certain behaviors occur without precise, clear, a priori conscious decision-making—i.e., without the involvement of conscious and situated rational deliberation processes. 

\nextdiv
Research in psychopathology, particularly in the context of schizophrenia, further supports this view by demonstrating that critical aspects of social cognition, such as emotion perception and theory of mind (ToM), operate at a largely subconscious level. Penn et al. (2008) and Green et al. (2008, 2015) describe these processes not as deliberate, conscious judgments, but rather as automatic responses to social cues. For example, the concept of motor resonance—where the observation of another's behavior triggers neural activation similar to performing that behavior oneself—illustrates the intuitive and automatic nature of social understanding. These findings reinforce Haidt's SIM by showing that social cognitive processes, like emotion perception and mentalizing, are largely pre-reflective and automatic, further underlining the dominance of intuition over reasoning in shaping moral judgments.

\nextdiv
This aligns strongly with Jonathan Haidt's SIM, which posits that moral judgments are primarily the result of automatic, intuitive processes rather than explicit reasoning, highlighting how these social cognitive functions usually operate largely outside of conscious awareness. By showing that even in altered psychological states these processes remain largely automatic, the argument for the automatic and intuitive nature of social cognition, as posited by SIM, becomes more compelling. The use of psychopathology provides a contrasting scenario that highlights the essential, subconscious operation of these processes in normal functioning.
\end{document}