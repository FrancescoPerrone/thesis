\documentclass[review]{elsarticle}
%\documentclass[final,3p]{elsarticle}

%%%%%%%%%%%%%%%%%%%%%%%%%%
% Remove this for adding lines in abstract and keywords
% %%%%%%%%%%%%%%%%%%%%%%%%
\makeatletter
  \long\def\pprintMaketitle{\clearpage
  \iflongmktitle\if@twocolumn\let\columnwidth=\textwidth\fi\fi
  \resetTitleCounters
  \def\baselinestretch{1}%
  \printFirstPageNotes
  \begin{center}%
 \thispagestyle{pprintTitle}%
   \def\baselinestretch{1}%
    \Large\@title\par\vskip18pt
    \normalsize\elsauthors\par\vskip10pt
    \footnotesize\itshape\elsaddress\par\vskip36pt
    % \hrule\vskip12pt
    % \ifvoid\absbox\else\unvbox\absbox\par\vskip10pt\fi
    % \ifvoid\keybox\else\unvbox\keybox\par\vskip10pt\fi
    % \hrule\vskip12pt
    \end{center}%
  \gdef\thefootnote{\arabic{footnote}}%
  }
  
%%%%%%%%%%%%%%%%%%%%%%%%%%
% This controls the bottom runner
% %%%%%%%%%%%%%%%%%%%%%%%%
 
 \def\ps@pprintTitle{%
 \let\@oddhead\@empty
 \let\@evenhead\@empty
 \def\@oddfoot{\hfill\footnotesize\itshape F. Perrone}%
 \let\@evenfoot\@oddfoot}
 
 \renewcommand{\MaketitleBox}{%
  \resetTitleCounters
  \def\baselinestretch{1}%
  \begin{center}
    \def\baselinestretch{1}%
    \Large \@title \par
    \vskip 18pt
    \normalsize\elsauthors \par
    \vskip 10pt
    \footnotesize \itshape \elsaddress \par
  \end{center}
  \vskip 12pt
}
 %%
 
\makeatother
%%%%%%%%%%%%%%%%%%%%%%%%%%
% End title modifications
% %%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%
% For Paragraphs
%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{titlesec}

% Ensure paragraphs are numbered according to the sections (e.g., 3.1, 3.2)
\setcounter{secnumdepth}{4} % Enable numbering up to paragraphs
\setcounter{tocdepth}{4}    % Include paragraphs in the Table of Contents if needed

% Customize \paragraph to show numbers from the section hierarchy
\titleformat{\paragraph}
{\normalfont\itshape} % Italic heading (unchanged)
{\theparagraph}       % Display the paragraph number
{1em}                 % Spacing between number and title
{}                    % Code preceding the paragraph title
\renewcommand{\theparagraph}{\thesection.\arabic{paragraph}} % Number format


%%%%%%%%%%%%%%%%%%%%%%%%%%
% End Paragraph formatting
%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{lineno,hyperref}
\modulolinenumbers[20]

\journal{Journal of \LaTeX\ Templates}

%%%%%%%%%%%%%%%%%%%%%%%
%% Elsevier bibliography styles
%%%%%%%%%%%%%%%%%%%%%%%
%% To change the style, put a % in front of the second line of the current style and
%% remove the % from the second line of the style you would like to use.
%%%%%%%%%%%%%%%%%%%%%%%

%% Numbered
%\bibliographystyle{model1-num-names}

%% Numbered without titles
%\bibliographystyle{model1a-num-names}

%% Harvard
%\bibliographystyle{model2-names.bst}\biboptions{authoryear}

%% Vancouver numbered
%\usepackage{numcompress}\bibliographystyle{model3-num-names}

%% Vancouver name/year
%\usepackage{numcompress}\bibliographystyle{model4-names}\biboptions{authoryear}

%% APA style
%\bibliographystyle{model5-names}\biboptions{authoryear}

%% AMA style
%\usepackage{numcompress}\bibliographystyle{model6-num-names}

%% `Elsevier LaTeX' style
\bibliographystyle{elsarticle-num}
%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{graphicx}

%%%%%%% MY PERSONAL SETTINGS %%%%%%%
\usepackage{xspace}
\newcommand{\ie}{\emph{i.e.}\@\xspace}
\newcommand{\eg}{\emph{e.g.}\@\xspace}
\newcommand{\nextdiv}{\vspace{2mm}\noindent}

%%%%%%% MY PERSONAL NOTES %%%%%%%
\usepackage{xcolor}
\usepackage{hyperref}
\definecolor{fpgreen}{HTML}{A6D609}
\usepackage[colorinlistoftodos]{todonotes}
\newcommand{\fpcom}[1]{\vspace{2mm} \todo[inline, size=\scriptsize, color=fpgreen!80]{\textbf{FP}: #1}}
\newcommand{\fpincom}[1]{\todo[size=\tiny, color=fpgreen!80]{\textbf{FP}: #1}}

\usepackage{enumitem} % For customizing list
%\usepackage{geometry} 

\begin{document}

\begin{frontmatter}

\title{The title\tnoteref{mytitlenote}}
%\tnotetext[mytitlenote]{Fully documented templates are available in the elsarticle package on \href{http://www.ctan.org/tex-archive/macros/latex/contrib/elsarticle}{CTAN}.}

%% Group authors per affiliation:
%\author{Francesco Perrone\fnref{myfootnote}}
\author{Francesco Perrone}
\address{Glasgow, UK}
\author[]{University of Glasgow}
\author[]{School of Computing Science}
%\fntext[myfootnote]{Since 1880.}
%% or include affiliations in footnotes:
%\author[mymainaddress,mysecondaryaddress]{University of Glasgow}
%\ead[url]{www.elsevier.com}

%\author[mymainaddress]{School of Computing Science}
%\corref{mycorrespondingauthor}}
%\cortext[mycorrespondingauthor]{Corresponding author}
%\ead{support@elsevier.com}
%\address[mymainaddress]{Sir Alwyn Williams Building, Glasgow}
%\address[mysecondaryaddress]{360 Park Avenue South, New York}

%\begin{abstract}
%This template helps you to create a properly formatted \LaTeX\ manuscript.
%\end{abstract}

%\begin{keyword}
%\texttt{elsarticle.cls}\sep \LaTeX\sep Elsevier \sep template
%\MSC[2010] 00-01\sep  99-00
%\end{keyword}

\end{frontmatter}

\newpage
\tableofcontents
\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%
% This is for draft numbering
% %%%%%%%%%%%%%%%%%%%%%%%%
\linenumbers
% Some introductionary text without a precise place just yet

%One of the main contribution give by modern Social Cognition is the large experimental evidence of the fact that humans' inferences directed to the execution of certain behaviours happen without precise, and clear, a priori \textit{conscious} decision, i.e. without conscious and situated rational deliberation processes.

\newpage
\section{Forewords}
\newpage
\section{Introduction}
The research presented here examines the role of experimental methodologies as a new tool for investigating prosocial behaviour and moral deliberation in the field of Machine Ethics. We show that these methodologies allow us to study how such behaviors manifest under the subtle yet controlled influence of robots coexisting with humans. In particular, we describe how the mere presence of a non-interactive machine can shape ethical deliberation and prosocial behavior, through perceived observation under controlled experimental settings.

\nextdiv
Withal, we outline two main research activities that we conducted, in the field of Machine Ethics:

\begin{enumerate}[label=\alph*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	\item \textbf{An experimental activity} about the interplay between the presence of social robots and human prosocial behaviour.
	\item \textbf{A comparative analysis of the literature} that suggests the emergence of the following:
	\begin{enumerate}[label=\Roman*.]
		\item Two related, but distinct, research themes in Machine Ethics which we call Human-Machine Ethics and Computational Machine Ethics.
		\item The emergence of two distinct trends in Psychology and Philosophy, \ie cognitive/affective models of moral judgments and rationalism/intuitionist approaches to moral reasoning, that exert a deep influence on the research objectives and methodologies in Computational Machine Ethics.
	\end{enumerate}
\end{enumerate}


\nextdiv
Furthermore, following the analysis in a) and evidences in b) we will argue in favour of the adoption of new research methodologies in Computational Machine Ethics (a subfield of Machine Ethics) that should follow recent experimental evidences in support of models of moral judgements as aﬀect-laden intuitions (explained below). This model of moral reasoning has not yet been taken into consideration in any of the work done in Machine Ethics up to date.

\nextdiv
The most interesting implications of such a turn for Computational Machine Ethics would arguably be the following:

\begin{enumerate}[label=\arabic*)\,, leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	
	\item  The possibility to design experiments that quantify diﬀerences in moral attitudes
	through the measurable outcomes of decisions made by subjects at least in a controlled
	setting (i.e. experiments);
	\item The possibility of analysing moral decisions through measuring behaviour, which in
	turn lends itself to the application of Social Signal Processing and Aﬀective Computing
	methodologies to the investigation of moral deliberation, its analysis and automation.
\end{enumerate}

\nextdiv
On this account, the following two questions were addressed during the course of this research, forming the basis of the intended \textit{research statements}:


\begin{enumerate}[label=(Q\arabic*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	
	\item  Does the presence of social robots change the outcome of decisions made by humans?
	\item  Do moral decision leave physical traces in terms of observable, machine detectable
	behavioural cues?
\end{enumerate}

\nextdiv
Q1 refers mainly to point 1, and will shows that it is possible to explore whether principles and laws underlying Moral Psychology apply to Computational Machine Ethics.

\nextdiv
Q2 refers mainly to point 2, and will show that it is possible to apply existing social and psychological approaches for improving the investigation and validation of theories of human moral behaviour.

\nextdiv
The remainder of this work is organized as follows. [...]
\newpage
\section{Moral Decision Making}
\label{sec:moral}
\paragraph{Introduction}

moral reasoning directed towards deciding what to do involves forming judgments about what one ought, morally, to do. On these understandings, asking what one ought (morally) to do can be a practical question, a certain way of asking about what to do.

Practical reason refers to the distinctively human capacity to determine, through reflective deliberation, the appropriate course of action in a given situation~\cite{Aristotle_nicomachean, Aquinas_summa, Kant_practical_reason}. 

\nextdiv
In this context, reflective deliberation is a cognitive function often characterised by conscious, effortful, and reason-guided evaluation of options, or courses of action. It usualy characterised in the literature as involving:

\begin{enumerate}[label=\arabic*)\,, leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	
	\item \textbf{ Philosophical Perspective:} The capacity to critically assess one's desires, beliefs, and values, often engaging in second-order thinking to evaluate not just what one wants but whether those wants align with broader principles or long-term goals. Rooted in Kantian ethics and Aristotelian practical reasoning, it emphasizes autonomy and rationality~\cite{Aristotle_nicomachean, Korsgaard1996}.
	\item \textbf{Psychological Perspective:} A metacognitive process where individuals engage in controlled, systematic thinking to weigh evidence, consider alternatives, and predict outcomes. Reflective deliberation contrasts with automatic or heuristic-driven decision-making, drawing from dual-process theories of cognition~\cite{Kahneman2011, Stanovich2000}.
\end{enumerate}


This deliberative process in practical reasoning is, indeed, \textit{practical} in two essential respects. Firstly, it pertains to the \textit{domain of action}, as its focus is on resolving questions related to what \textit{should be done}. Secondly, it is practical in its \textit{outcomes}, as the act of reflecting on matters of action inherently guides and motivates individuals toward acting~\cite{Wallace2020}. A natural way to interpret this point of view is to contrast it with the standpoint of theoretical reason. 

\nextdiv
Theoretical reasoning is concerned with resolving questions that are fundamentally theoretical rather than practical in nature. It focuses on explanation and prediction, retrospectively asking why events have occurred and prospectively determining what might happen in the future. Paradigmatic expressions of theoretical reasoning are found in the natural and social sciences, where causal relationships and empirical evidence are central~\cite{Nagel1979, Hempel1965, Tversky1974, Hirschfeld1994}. Beyond this, theoretical reasoning also extends to \textit{non-causal explanations}, such as those explored in metaphysical, logical, and conceptual inquiries. 
%Between these two stands epistemic reasoning, which guides the evaluation and justification of beliefs. Epistemic reasoning concerns itself with questions of what one should believe, based on evidence, coherence, and rational assessment. It aligns closely with theoretical reasoning in its commitment to truth but also intersects with practical reasoning in contexts where action depends on justified belief—for instance, in scientific decision-making or ethical dilemmas.
Its focus on understanding matters of fact is distinct in its impersonal and \textit{universally accessible approach}, which contrasts with the more situated and action-oriented focus of practical reasoning.

\nextdiv
Practical reasoning, by contrast, centers on deliberation about what one \textit{ought to do}, providing guidance for action in specific circumstances. Unlike theoretical reasoning, which seeks to understand the world as it is, practical reasoning addresses how to navigate complex situations and achieve goals. It operates across a wide range of contexts, from moral obligations, such as promoting well-being or fulfilling promises, to professional domains like medicine, scientific experimentation, artistic creation, or athletic performance. Practical reasoning is also tied to how-to knowledge and technical skill, enabling individuals to adapt to dynamic environments and deliberate effectively about actions.

\nextdiv
There is, however, a different and arguably better way of understanding the contrast between practical and theoretical reason, stressing the parallels rather than the differences between the two forms of reflection [needs reprhasing]~\cite{Berker2013}.

On this view, theoretical reasoning, like practical reasoning, addresses normative questions—in this case, what one ought or is permitted to believe. It evaluates and balances reasons for belief, weighing considerations that support or challenge specific conclusions about the world. This process occurs from a standpoint of first-personal reflection: theoretical reasoning adopts the engaged perspective of the believer, rather than a detached analysis of one’s beliefs (Moran, 2001; Boyle, 2011). Thus, the distinction between practical and theoretical reasoning lies in the types of norms they involve: practical norms govern action, while epistemic norms regulate belief (for further discussion, see McHugh et al., 2018).

\nextdiv
Theoretical reasoning, in this sense, reflects on what reasons justify accepting particular claims as true. Its focus is on evidential considerations that indicate the likelihood of propositions being correct. Practical reasoning, by contrast, deliberates on what makes actions desirable or worthy of choice. Its reasons are those that justify actions as worth performing. This divergence in subject matter also leads to different outcomes: theoretical reasoning modifies one’s belief system by aligning it with truth, whereas practical reasoning culminates in action. As previously noted, practical reasoning is tied to action not only in its subject matter but also in its purpose and results.

\begin{figure}[ht]
	\centering
	\includegraphics[width=\textwidth]{/home/francesco/Desktop/research/work/thesis/img/diagrams/TypesOfReasoning.pdf}
	\caption{Diagram illustrating the types of reasoning, distinguishing between theoretical and prescriptive reasoning.}
	\label{fig:types_of_reasoning}
\end{figure}

\nextdiv
Lastly, it should be said that despite their differences, theoretical and practical reasoning share an underlying structural unity. Both involve evaluating reasons, assessing justification, and adhering to principles of rationality, albeit in different domains. This shared framework is evident in our common vocabulary: we \textit{speak} of what is "right to do" and "right to think," of being "justified" in both actions and beliefs, or of having reasons for what we choose or conclude. This structural unity reveals how the forms of reasoning mirror one another, even as their substantive concerns diverge—whether focusing on understanding facts, guiding action, or grounding belief.

\nextdiv
Hence, 

While moral reasoning can be undertaken on another’s behalf, it is paradigmatically an agent’s first-personal (individual or collective) practical reasoning about what, morally, they ought to do.

A fundamental aspect of the human experience is our capacity for judgement. We constantly make judgements about the world around us, evaluating everything from the taste of our food to the merits of a political argument. But amongst this vast sea of judgements, a particular type stands out: \textit{moral judgements}. These judgements are about what is right and wrong, about what we ought to do and what we ought not to do.

This chapter delves into the intricate world of reasoning, judgment, and the formidable challenges encountered in replicating these human faculties within artificial intelligence (AI) systems. The exploration commences with a meticulous examination of reasoning and its practical manifestation, establishing a firm conceptual foundation for subsequent analyses.

\paragraph{Practical reasoning}
Reasoning, in its essence, is an inferential process. It operates on the attitudes of a subject, transforming them into the formation or modification of other attitudes~\cite{har}. This intricate dance of mental states, propelled by the engine of inference, lies at the heart of our cognitive capacities.
Practical reasoning, a specialized subset of reasoning, zeroes in on the pivotal question of what one is to do. Its subject matter is action, and its consequences are practical, ultimately culminating in the performance of actions. Practical reasoning grapples with normative inquiries, pondering what one ought to do or which action emerges as the most rational choice given the available reasons
\paragraph{What is Judgment}
\paragraph{The Scope of Ethics}
We adopt here Sidgwick's characterisation of Ethics exposing its \textit{systemic} nature charaterised by his definitions accorgint to whcih "method of ethics refers to any rational procedure by which we determine what individual human
beings ‘ought’ to do or what it is ‘right’ for them to do, or to try to bring about by voluntary action"~\cite{SidgwickMethods}

\nextdiv
To provide systems of general theories of reasons for action. It is in this very same domain that Ethics differs from the other \textit{positive science}. Ethics is a \textit{practical} science whose \textit{end} is the direction of human actions. In the \textit{Methods of Ethics} Sidgwick (1838-1900) explains that the Methods that Ethics seeks to build is made of \textit{rational procedures} by which we can determine what \textit{individual} humans (Aristotle's moral agents) \textit{ought to do}, or try to bring about with \textit{voluntary actions}. Ethics aims to build a systematic and precise general knowledge of what \textit{ought to be} and in this sense its aim and methods can be called scientific \cite{SidgwickMethods}
\subparagraph{Metaethics}\noindent Of a different nature are questions about Ethics are there moral facts, if so how could we know them? Without such facts what else could make moral judgements true. Recall that to make a judgement is to \textit{affirm the truth} of some claim or content. Judgements are mental states or attitudes in connection to a mental representation of existing objects. "The initial claim is that for propositions to be true is for them to stand in a special relation to things in the world; they must “fit” those things; or, as it is usually put, they must correspond to them" \cite{LouxMetaphysics}. \textcolor{red}{[]go back to metaphysics and search for predicates link particulars and universal then go down to predicate and proposition this is for talking about the king of judgement which we define in the tree]}. According to Kant judgment (\textit{Urteil}) is any conscious mental representation of.. [not finished 13/01/2020 went on judgment research]`

\newpage
\section{Machine Ethics}

Over the past decade, the field of Machine Ethics—an area of inquiry concerned with the moral dimensions of artificial systems—has garnered significant attention from the scientific community. \fpincom{Good, now the problem is the start and structure of the next portion of text but one step at time! Keep nextdiv for next portion. It's good to have a division like this. Remember the focus is to introduce ME as soon as we open.}

\nextdiv
The growing prominence of Machine Ethics within the scientific community is evidenced by multiple indicators. A bibliometric analysis of AI and ethics publications revealed a significant rise in research output, with over 1,500 papers published by mid-2021 and a marked acceleration from 2014 onward \cite{Chuang2022}. Foundational works, such as Anderson and Anderson’s Machine Ethics (2011), have played a pivotal role in catalyzing this interest by providing early frameworks for exploring the moral capabilities of artificial systems \cite{Anderson2011}.

\nextdiv
This trend is further underscored by the institutionalization of AI ethics as a recognized academic discipline. A keyword analysis spanning two decades identifies 2014 as a pivotal year, marking a surge in academic engagement with terms related to Machine Ethics and the ethical dimensions of AI research \cite{Gao2024}. The increasing focus on these issues is reflected in the growing body of literature addressing topics like transparency, accountability, and human oversight in autonomous systems \cite{Wallach2008}.

\nextdiv
Finally, recent meta-analyses highlight the expansion of Machine Ethics as a domain of inquiry, capturing the attention of researchers and practitioners alike. For example, Otterbacher \textit{et al.} (2023) discuss the heightened focus on ethical challenges posed by AI, particularly over the past decade \cite{Otterbacher2023}. Together, these developments illustrate a clear trajectory of growth and consolidation, establishing Machine Ethics as an area of significant and sustained interest within the scientific community.

\nextdiv
Truth be told, Machine Ethics, as a term and filed, encompasses a wide range of ethical considerations related to machines, often leading to conflation of distinct issues. To address this, the domain of Machine Ethics is redefined through the integration of philosophical traditions and insights from Moral Psychology. This redefinition establishes a clear vocabulary and experimental framework for investigating how the mere presence of robots influences human moral deliberation and prosocial behavior. Grounded in empirical methodologies, this approach positions Machine Ethics as a critical intersection of ethical theory and moral psychology, advancing the understanding of the nuanced dynamics between humans and intelligent systems

A detailed comparative analysis of the literature on Machine Ethics and related academic disciplines, such as Philosophy and Moral Psychology, highlights a relationship that forms the basis for classifying two distinct research paradigms within Machine Ethics.

Machine Ethics can be divided into two primary areas of focus. The first, termed \textit{Human-Machine Ethics}, examines ethical considerations for humans, centering on behavior in relation to AI and robotic systems. This area addresses societal responsibilities, ethical dilemmas, and legal implications surrounding the deployment and use of AI technologies. The second area, referred to as \textit{Computational Machine Ethics}, focuses on designing systems capable of autonomous moral reasoning, enabling them to operate within predefined ethical parameters.


In most cases, the ethics of AI focuses on the socio-economic, and legal impacts of AI and, the moral and ethical issues surrounding the use of these systems. 


Machine Ethics is the subfield of Computer Science that develops methods and theories aimed at enabling machines to interact morally with their users in real-world scenarios~\cite{Anderson2011, Nallur2020, Pereira2020, Tolmeijer2020}.  For some, \textit{the new field} of Machine Ethics is concearned with giving machines ethical procedures for discovering ways to resolve the ethical problems that \textit{they might encounter}, thus enabling them to function through their own ethical decision~\cite[pp. i - iv]{Anderson2011}. Unlike Computer and Information Ethics, which refer to the application of various ethical thoeries (\eg utilitarianism, Kantianism, virtue ethics) to cases that significantly involve computers and computer networks, or to ethical issues surrounding human use of machines~\cite{Bynum2018}, the ultimate goal of Machine Ethics, is to create machines that follow an ideal ethical principle or a set of principles; that is to say, it is guided by this principle or these principles in decisions it makes about possible courses of action it could take. 

Machine Ethics concears the behaviours of complex , autonomus systems, towards humans~\cite{Otterbacher2023}

While this work may be classified as technical, I assume readers possess a basic understanding of certain non-technical concepts, such as artificial intelligence and autonomous intelligent systems. For technical terminology mentioned throughout, I provide concise definitions to clarify their context.


\nextdiv
A central reason for this trend is an unprecedented interdisciplinarity: researchers in Machine Ethics are now capable of freely drawing on scientific resources and experimental data from well beyond the confines of their fields~\cite{Anderson2011}, which can now be integrated into Artificial Intelligence (AI) technologies. Machine Ethics could be thought as a laboratory to verify and generalise, philosophical small-scale theories and thought experiments, which have heavily characterised and shape the work in this field up until now~\cite{Allen2006, allen2012}


\fpcom{this should be part of the closing remarks to introduce the experiment.}
\nextdiv
In Floridi's view~\cite{Floridi2004}, machines that exibit such capabilities for moral deliberaiton, needs to be moral agents in the sense that they should be capable of performing actions with moral significance whcih in turn is define by two primary criteria.

\begin{enumerate}[label=(P\arabic*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	\item \textbf{Autonomy}.  A moral agent must have the ability to act independently and make choices that are not entirely determined by external forces. Autonomy entails intentionality, which means the agent acts with a purpose or goal in mind. A moral agent must be capable of being held accountable for its actions. 
	\item \textbf{Responsibility} This accountability implies that the agent understands the consequences of its actions and can justify them within a moral framework. robots or algorithms, as they can act in ways that significantly affect the moral landscape. However, he acknowledges that their "agency" is limited and derivative because they lack intrinsic moral intentionality, functioning instead within parameters set by human designers.
\end{enumerate}
 
\nextdiv
A moral patient, in contrast, is an entity that can be affected by the actions of a moral agent and therefore deserves moral consideration. Floridi emphasizes: 

\begin{enumerate}[label=(P\arabic*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	\item \textbf{(Intrinsic Worth)}Moral patients have value in and of themselves and must not be treated merely as a means to an end (echoing Kantian ethics).
	\item \textbf{Vulnerability} Moral patients are characterized by their capacity to be harmed or benefited. This includes humans, animals, ecosystems, and increasingly, informational entities (e.g., data or digital environments).
	\item  \textbf{Inclusiveness} Floridi's framework expands traditional moral boundaries. He argues for considering entities like artificial agents and digital ecosystems as potential moral patients, based on their capacity to be affected within the infosphere. 
\end{enumerate}

Floridi's theory is particularly relevant in the context of the infosphere, a term he uses to describe the informational environment we live in, including digital and physical realms. He introduces the concept of distributed morality:

\begin{enumerate}[label=\alph*), leftmargin=1cm, rightmargin=1cm]
	\setlength{\itemsep}{-0.5em} % Reduce vertical space between items
	\item Actions are no longer confined to individual moral agents but are distributed across networks of human and non-human actors.
	\item For instance, a decision made by an algorithm (moral agent) might impact a user (moral patient) in ways that require ethical scrutiny.
\end{enumerate}

Floridi moves beyond anthropocentric (human-centered) ethics to advocate for ontocentric (being-centered) ethics, where all entities with intrinsic worth, including informational and digital entities, are considered. By redefining moral agents and patients, Floridi expands moral responsibility to include designers and users of technology, artificial agents with decision-making capabilities, and vulnerable systems in the infosphere. Floridi’s theory is grounded in information ethics, where the fundamental moral value is the "flourishing of the infosphere." Harm is understood as any action that degrades the informational integrity or flourishing of an entity. The implications are Floridi's framework suggests that as AI becomes more integrated into society, its role as a moral agent and its impact on moral patients (users, ecosystems, etc.) must be carefully managed. The inclusion of ecosystems and informational entities as moral patients aligns with broader discussions on environmental ethics and sustainability. By emphasizing distributed morality, Floridi’s theory calls for collaborative responsibility in technology design, governance, and ethical AI deployment. In summary, Floridi's theory redefines moral agents and patients to address the complexities of modern, interconnected environments, emphasizing responsibility, inclusiveness, and the flourishing of all entities within the infosphere.
\newpage
\section{Section}

This thesis investigates moral reasoning as it manifests under the subtle yet controlled influence of human-robot coexistence, an experimental terrain where ethical principles encounter observable behavior, under robotic observation. While it does not directly engage with the philosophical history or psychological foundations of morality, it draws upon both to establish the conceptual framework and terminology necessary to understand how machines might influence human ethical decision-making through a deliberately non-interactive experimental setting that invites participants to confront ethical scenarios under robotic observation.



\nextdiv
Central to this investigation are precise questions concerning the influence of human-robot interactions on moral reasoning: How do autonomous systems shape ethical decision-making in humans? What are the mechanisms through which robots alter perceptions of what is morally right or wrong? How can experimental methodologies illuminate these processes with empirical clarity? Addressing these questions requires a robust foundation in defining moral reasoning, first through a philosophical lens that considers consequentialist, deontological, and virtue ethics traditions, and then through the perspective of moral psychology, which examines the cognitive and emotional processes underlying ethical judgments. These frameworks collectively enable a systematic exploration of how human-robot interactions inform and reshape our understanding of morality.

\nextdiv
Moral reasoning, as a species of practical reasoning, is the deliberative process directed towards deciding what to do, ultimately culminating in a judgment and, when successful, issuing in an intention. In this context, moral judgment represents the evaluative conclusion of reasoning, bridging deliberation and action. This thesis adopts this dual perspective, integrating philosophical frameworks such as deontology and virtue ethics with psychological theories of intuitive and deliberative reasoning, to examine how autonomous systems influence these processes in human decision-making.

While moral reasoning can be undertaken on another’s behalf, it is paradigmatically an agent’s first-personal (individual or collective) practical reasoning about what, morally, they ought to do. Philosophical examination of moral reasoning faces both distinctive puzzles – about how we recognize moral considerations and cope with conflicts among them and about how they move us to act – and distinctive opportunities for gleaning insight about what we ought to do from how we reason about what we ought to do.

We can use the map shown in Figure~\ref{fig:moral_judgements} to captures foundational distinctions in the realm of judgments, particularly as they relate to moral philosophy and psychology. The map reflects central philosophical inquiries: What is true (factual)? What is right or wrong (moral)? What ought to be done (normative)?

\begin{figure}[h!]
	\centering
	\includegraphics[width=\textwidth]{"../img/graphs/typesOfJudgements_corrections.pdf"}
	\caption{Diagram of Types of Judgements.}
	\label{fig:moral_judgements}
\end{figure}



\paragraph{Paragraph}
\paragraph{Paragraph} 
%\section{Bibliography}
% \section*{References}
\newpage
\bibliographystyle{ieeetr}
\bibliography{/home/francesco/Desktop/research/appunti/reference.bib}
\newpage
\section*{Notes}
\paragraph{Robot Details and Role}The experiment involved the NAO humanoid robot in an autonomous life setting, specifically simulating a breathing animation. This design aimed to give participants the impression of being observed subtly. This was core to the experiment, as it replicated the watching eye effect without direct interaction.

\paragraph{Impact of Robot Presence} The robot's presence in the room was intended to explore its influence on prosocial behavior, particularly in the context of moral decision-making, measured by charitable donations. The participants were unaware beforehand that a robot might be present or that donations would be part of the taks.

\paragraph{Social Cognition} Social Cognition is a field of study that investigates how individuals perceive, interpret, and respond to social stimuli and interaction \ie, events, actions, or signals in a social environment that influence individuals' behaviors and responses \fpincom{Fiske2020, Baron2012}, encompassing the processes by which people understand themselves and others. It emphasises both the automatic and deliberate aspects of social interactions, with a focus on how cognitive processes operate in social contexts.

\nextdiv
In early 2000, Jonathan Haidt in~\cite{Haidt2001} laid the foundation of the Social Intuitionist Model (SIM) understanding how moral judgments are primarily driven by quick, automatic intuitions rather than deliberate reasoning processes. SIM contracts traditional models of moral reasoning, empathising the subconscious and socially intuitive nature of moral behaviour. This shift was important in highlighting the intuitive nature of moral reasoning which contrasted the established belief that reasoning was the main driver of moral-decision making. After Haidt’s theoretical introduction, a series of empirical studies supported and expanded upon his claims. 

\nextdiv
Greene et al. conducted fMRI studies to explore the neurological basis of moral decision-making, providing empirical support for Haidt's model. Their findings demonstrated that emotional regions of the brain were more active during moral dilemmas involving personal engagement (e.g., in "trolley problems"). Greene's 2001 paper, "An fMRI Investigation of Emotional Engagement in Moral Judgment," found that emotionally engaging dilemmas activated brain regions linked to emotion, reinforcing Haidt's idea that emotions, rather than rational deliberation, often drive moral judgments.

\nextdiv
In 2004, Greene expanded this work with the study, "The Neural Bases of Cognitive Conflict and Control in Moral Judgment," demonstrating that rational control is often secondary to emotional intuitions in moral scenarios. Greene's later works, such as his 2008 paper, integrated a dual-process theory that further solidified Haidt’s ideas by showing that moral judgment is influenced by both intuitive/emotional and rational/cognitive processes. This model helps reconcile instances where rational deliberation plays a role, complementing Haidt’s initial SIM by illustrating a spectrum between automatic intuitions and deliberate reasoning.

\nextdiv
\textit{Other researchers contributed by showing how automatic, unconscious processes play a central role in moral judgment, which supported Haidt's position. Studies on priming effects in moral decision-making illustrated how subtle cues could shift moral judgments without individuals being consciously aware of these influences.}

\nextdiv
One of the main contributions to SIM comes from provided by modern Social Cognition that provides a vast experimental evidence that human inferences leading to the execution of certain behaviors occur without precise, clear, a priori conscious decision-making—i.e., without the involvement of conscious and situated rational deliberation processes. 

\nextdiv
Research in psychopathology, particularly in the context of schizophrenia, further supports this view by demonstrating that critical aspects of social cognition, such as emotion perception and theory of mind (ToM), operate at a largely subconscious level. Penn et al. (2008) and Green et al. (2008, 2015) describe these processes not as deliberate, conscious judgments, but rather as automatic responses to social cues. For example, the concept of motor resonance—where the observation of another's behavior triggers neural activation similar to performing that behavior oneself—illustrates the intuitive and automatic nature of social understanding. These findings reinforce Haidt's SIM by showing that social cognitive processes, like emotion perception and mentalizing, are largely pre-reflective and automatic, further underlining the dominance of intuition over reasoning in shaping moral judgments.

\nextdiv
This aligns strongly with Jonathan Haidt's SIM, which posits that moral judgments are primarily the result of automatic, intuitive processes rather than explicit reasoning, highlighting how these social cognitive functions usually operate largely outside of conscious awareness. By showing that even in altered psychological states these processes remain largely automatic, the argument for the automatic and intuitive nature of social cognition, as posited by SIM, becomes more compelling. The use of psychopathology provides a contrasting scenario that highlights the essential, subconscious operation of these processes in normal functioning.
\end{document}