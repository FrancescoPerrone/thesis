\chapter{Disscussion}
\label{chap:dis}
% Define a counter named 'question' that resets every time 'chapter' increments
% Define the format of the counter to be 'chapter_number.question_number'
\renewcommand{\thequestion}{\thechapter.\arabic{question}}

% Adjusting epigraph settings
\setlength\epigraphwidth{.8\textwidth}
\setlength\epigraphrule{0pt}
\renewcommand{\epigraphflush}{flushleft}
\renewcommand{\sourceflush}{flushright}

\section{Reframing the Central Question}

There is a moment in any investigation—scientific, philosophical, or somewhere 
between, though that “between” dissolves if one grants, as I do, that the 
distinction lacks separability in the same way certain physical systems resist 
factorisation—when one steps back from the models and the statistics and 
returns to the question that set the entire project in motion. It is usually 
small, almost embarrassingly simple, yet it carries the force of something that 
refuses to be ignored:%
%
\bigskip
\begin{center}
	\begin{leftbar}
		\textit{Why do small, seemingly insignificant presences in our environment alter what we take to be the ‘right’ thing to do?}
	\end{leftbar}
\end{center}
\bigskip
This thesis began from that question—not as an academic curiosity, but as a recognition that our moral lives are extraordinarily sensitive to the texture of the situations in which we act~\cite{Vinciarelli2019}. A shift in posture; a change in the room’s atmosphere; a sense that someone—or something—is watching: the same quiet pressure that guided the traveller’s path in the opening parable.
%A shift in posture; a change in the room’s atmosphere; a sense that someone—or something—is watching. 
These subtleties often shape our decisions long before we would describe ourselves as ``reasoning about ethics.’’

The experiment in the previous chapter suggests that this sensitivity may extend
even to \textbf{synthetic presences}: entities that do not feel, do not reason, and do not act in any recognisably moral sense, yet nonetheless influence the way moral salience flows through a situation. The robot in our study did not speak. It did not move meaningfully. It issued no signals of intent. And yet, its mere co-presence shifted the way participants transformed an affectively charged cue—the child’s face on the charity poster—into a decision about donating.

That shift is subtle in magnitude but rich in structure. And it is precisely this structure that the Discussion Chapter now aims to make sense of.

\section{What Can Be Inferred from This Experiment}

The findings of the previous chapter can be summarised directly:

\begin{itemize}
	\item A measurable attenuation of prosocial donation is observed when a
	humanoid robot is present.
	\item This attenuation is not universal: it is most pronounced among individuals whose dispositional architecture foregrounds empathy, sociability, and interpersonal attunement.
	\item Other psychological profiles appear comparatively inert, showing minimal or no change.
	\item Bayesian estimation reinforces this pattern, revealing a probabilistic skew toward attenuation but with uncertainty distributed across clusters.
	\item The Watching Eye stimulus loses some of its intuitive force—arguably not because empathy collapses, but because the robot’s ontological ambiguity refracts the salience of the moral cue.
\end{itemize}

In short, the experiment indicates a \textbf{topology}, not a cause. A \textbf{reconfiguration}, not a negation. A \textbf{modulation}, not a suppressor.

The robot appears to influence how moral meaning is \emph{processed}, not whether moral meaning exists. This is the interpretive hinge on which the Discussion
Chapter builds.

\section{The Broader Significance: Moral Cognition as a Topological Process}

If we take seriously the intuitionist view of moral judgment—that our moral responses begin as fast, affectively-driven impressions, only later supplemented by reflective reasoning—then the results fit into a wider theoretical arc:

\begin{itemize}
	\item Moral cognition is \textbf{context-sensitive}.
	\item It emerges from an \textbf{interaction} between perceptual cues, affective resonance, and situational structure.
	\item It is modulated by \textbf{latent dispositional ecologies}—ways of attuning to the world that differ structurally across individuals.
\end{itemize}

In this frame, synthetic presences become morally relevant not because they ``reason’’ or ``intend,’’ but because they \textbf{change the context in which intuitive appraisal unfolds}. This reframing is essential. It shifts the problem from ``robots making moral decisions’’ to:
\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{How does the presence of artificial bodies alter the intuitive pathways through which humans interpret moral signals?}
	\end{leftbar}
\end{center}
\bigskip
\noindent
It is this reframing that structures the remainder of the Discussion Chapter:
the reinterpretation of the cluster structures, the integration of the Levels of
Abstraction framework, the implications for intuitionist moral psychology, the
reassessment of current Machine Ethics, and the broader ethical and epistemic
considerations for AI design. To maintain clarity and momentum, we will proceeds along four axes:

\begin{enumerate}
	\item \textbf{Revisiting the findings through the lens of moral cognition} – intuitive processes, Watching-Eye literature, and salience flow.
	\item \textbf{Theoretical integration with Floridi’s Levels of Abstraction} – how synthetic presence appears at different LoAs, and why this matters.
	\item \textbf{Implications for Machine Ethics and the ethics of AI presence} – the limits of rule-based machine morality; synthetic agents as moral perturbators.
	\item \textbf{Consequences for design, governance, and future research} – implications for HRI, LLM-based systems, interactive environments, and moral ecosystems.
\end{enumerate}

Each of these sections integrates content that was intentionally removed from the Methods chapter but retained for this interpretive synthesis: the hypothesis analysis, formal framework commentary, topological interpretation, and trait-contingency structure.

Throughout, the chapter preserves the conceptual vocabulary developed earlier—\emph{evaluative deformation}, \emph{normative displacement}, \emph{interpretive topology}—and maintains the narrative cadence of the Introduction: precise, philosophically grounded, and attentive to the lived texture of moral experience.

\subsection{Revisiting the Findings Through the Cognitive Architecture of Moral Intuition}
\label{sec:discussion_cognitive_architecture}

\noindent
The empirical results developed in the previous chapter acquire their full explanatory force only when viewed through the cognitive architecture of moral intuition. As we have largely seen in Chapter~\ref{chap:moral_primer}, much of the Moral Psychology literature now converges on the claim that intuitive, affectively saturated processes provide the primary substrate of ordinary moral behaviour~\cite{Haidt2001, Greene2002, Mikhail2007, Cushman2013}. Under this framework, explicit reasoning does not generate moral action so much as refine, justify, or sometimes override outcomes already shaped by intuitive appraisal. The question, therefore, is not simply \emph{whether} the robot changed donation behaviour, but:
\medskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{How it entered and reorganised the intuitive machinery that normally guides prosocial response under minimal moral prompting.}
	\end{leftbar}
\end{center}
\medskip
\noindent
The Watching--Eye stimulus used in the experiment—the prominently displayed
charity poster depicting a child in medical need—constitutes a canonical form of
\emph{intuitive moral cue}. It does not offer reasons, arguments, or explicit evalua-
tions; it merely provides a perceptual signal that activates reputational cognition
and empathic awareness, as seen in Chapter~\ref{chap:tools_new}.  Under ordinary circumstances, such cues produce small but reliable increases in prosocial giving~\cite{HaleyFessler2005, Bateson2006, NettleEtAl2013}. The present study is consistent with this baseline in the Control condition (figure~\ref{fig:experimental-topology}, page~\pageref{fig:experimental-topology}). The Robot condition, however, suggests that this intuitive moral channel is
sensitive to contextual modulation: the presence of an ontologically ambiguous
artificial body appears sufficient to alter which aspects of the situation
participants treat as normatively salient.

\medskip
\noindent
Viewed through the lens of intuitionist models, this is neither surprising nor anomalous. Intuitive moral evaluation relies on a distributed network of perceptual, affective, and attentional processes (see Chapter~\ref{chap:moral_primer}). When these processes operate smoothly, the Watching--Eye cue exerts its characteristic pull: reputational awareness is heightened, empathic resonance is foregrounded, and donation becomes more likely. 


When the robot is present, the intuitive transition from cue to action appears to shift. Attention may be divided, anthropomorphic expectations may be activated—as suggested by evidence that even minimal agent-like cues elicit spontaneous mentalising and mind-ascription in ambiguous contexts~\cite{Waytz2010,Gray2012}—and the semantic organisation of the environment may be subtly modulated, as shown by work demonstrating that the mere presence of social or quasi-social stimuli reorganises perceptual categorisation and contextual interpretation~\cite{Baldwin1985,Scholl2004}. None of these processes involve explicit reasoning; they operate beneath the level of reflective deliberation and shape the intuitive conditions from which later reasoning could emerge.

\medskip
\noindent
The cluster analyses indicate that this intuitive terrain is not uniform across
individuals. The \textit{Prosocial--Empathic} profile, characterised by strong
affective and interpersonal attunement, is the cognitive ecology in which the
Watching--Eye cue appears to exert the greatest influence. It is also the
regime in which NAO’s presence is associated with the largest attenuation. In
this group, intuitive appraisal relies heavily on empathic resonance, making the
processing of salient cues more susceptible to modulation by an ambiguous
synthetic presence. In contrast, the \textit{Analytical--Structured} profile
shows little to no change under robotic co-presence, consistent with a cognitive
style that depends less on affective input and more on explicit, norm-based
evaluation. The \textit{Emotionally Reactive} profile lies between these
patterns, exhibiting higher variance and no consistent direction of modulation.

\medskip
\noindent
Taken together, these patterns suggest that the moral effect of synthetic
presence is neither a failure of empathy nor a rational recalibration of cost
and benefit. Rather, it appears as a deformation of the \emph{intuitive architecture} through which moral meaning is normally processed. The robot bends—gently but recognisably—the pathway by which morally salient cues gain behavioural expression. This bending is plausibly mediated by attentional capture, affective dilution, and the structural ambiguity of NAO’s perceived
ontology.


\medskip
\noindent
Crucially, this interpretation resolves an apparent tension in the data. The behavioural attenuation observed is modest in magnitude and uncertain in exact size, as revealed by the Bayesian posterior. Yet the directionality is consistent across analytic methods and psychological subgroups. This is precisely the signature one would expect of a subtle but reliable intuitive modulation: small enough to evade detection under strict frequentist thresholds, but patterned enough to generate graded Bayesian support and trait-contingent differentiation.

\medskip
\noindent
Finally, the moral-topological reading introduced earlier provides a conceptual vocabulary for integrating these findings. If moral behaviour results from trajectories across an evaluative landscape shaped by perceptual cues, affective orientations, and dispositional structures, then NAO’s presence appears to alter the curvature of that landscape at the intuitive level. It introduces a competing centre of salience whose ontological ambiguity may shift the distribution of intuitive weight. Under this interpretation, the Watching--Eye cue does not lose its moral force; it is partially absorbed into a more complex semiotic environment.


\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Conclusion: Intuition and Moral Modulation]
		\noindent
		The moral impact of NAO’s presence is most plausibly understood as an intuitive deformation rather than a deliberative recalibration. Synthetic co-presence reshapes the early, affective, and attentional stages of moral cognition, redistributing intuitive salience in ways that depend on the evaluator’s dispositional architecture. This provides a coherent bridge between the empirical findings and broader theoretical models in moral psychology.
	\end{tcolorbox}
\end{center}

\noindent
This perspective prepares the ground for the next section, where we examine how these intuitive modulations connect to wider debates in machine ethics, social cognition, and the design of synthetic agents.

\section{Synthetic Presence and the Topology of Moral Salience}
\label{sec:discussion_topology}

\noindent
The experiment leaves us with a question that sits beneath the behavioural
results, beneath the statistics: \emph{what does it mean for a synthetic presence to bend the topology of moral salience?}

The data indicate that NAO does not persuade, signal, or instruct. Its
influence is quieter: a shift in the background against which moral cues acquire
their pull. Something in the evaluative machinery appears to tilt; the gradients
along which moral meaning ordinarily flows are subtly redrawn. The task of this
section is to interpret that shift using the theoretical vocabulary developed
earlier in Chapter~\ref{chap:moral_primer} and \ref{chap:tools_new}—evaluative topology, the evaluative transformation $f(\cdot)$, the tripartite decomposition $\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R)$,
and the conceptual apparatus derived from Floridi’s Levels of Abstraction--let's now see how.

\medskip
\noindent
A central claim of this thesis is that moral behaviour emerges from movement
within an \emph{evaluative field}: a structured cognitive space shaped by
perceptual cues, dispositional architectures, and implicit normative
expectations. Under ordinary conditions, morally salient stimuli—such as the
infant face in the charity poster—occupy local attractors in this field,
pulling evaluative trajectories toward prosocial action. This is captured
abstractly by the mapping
\[
\Sigma \longrightarrow \mathscr{D},
\]
in which perceptual input $\Sigma$ is transduced into behavioural output
$\mathscr{D}$ through the evaluative function $f(\cdot)$.

\medskip
\noindent
The robot’s presence introduces an additional informational element:
\[
\Sigma \cup \mathscr{R}.
\]
Crucially, $\mathscr{R}$ contributes no propositions, reasons, or explicit social
signals. Its influence lies instead in how it reorganises the geometry of the
evaluative field. It introduces \emph{ontological ambiguity}: an entity shaped
like an agent yet not behaving as one. From the perspective of Floridi’s Levels
of Abstraction, this ambiguity is operative. Participants encounter NAO at the
LoA of \emph{perceptual sociality}, where posture, gaze potentiality, and
micro-movements carry informational weight.

\medskip
\noindent
Within this framework, the term $\gamma_R$ in
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R)
\]
captures not robotic agency, but the \emph{perturbative affordances} of
synthetic presence. Under this interpretation, a synthetic agent modulates the
transformation from $\alpha_E$ (environmental moral cues) to $\mathscr{D}$
(behaviour) by introducing a new curvature into the evaluative field. The cluster
analyses suggest that this curvature interacts with $\beta_C$, producing the
observed pattern:
\[
\mathbb{E}[f(\Sigma \cup \mathscr{R})]
\begin{cases}
	\ll \mathbb{E}[f(\Sigma)] & \text{in Prosocial--Empathic regimes},\\[4pt]
	\approx \mathbb{E}[f(\Sigma)] & \text{in Emotionally Reactive regimes},\\[4pt]
	\lesssim \mathbb{E}[f(\Sigma)] & \text{in Analytical--Structured regimes}.
\end{cases}
\]

\noindent
This structured variation aligns with Hypothesis~\ref{hyp:synthetic_perturbation},
which proposed that synthetic presence would \emph{modulate}, rather than
categorically shift, the evaluative pathways linking moral salience to action.

What the experiment allows us to say is more modest but still theoretically 
significant. The behavioural pattern observed under robotic co-presence is 
\textbf{consistent with an interpretation in which synthetic presence functions as a 
topological modulation of the evaluative field}, rather than as a direct causal 
force. The data do not identify a mechanism; they show a systematic shift in 
the distribution of behavioural outcomes across conditions.

Under this interpretive frame, one may say that salience appears redistributed, 
that evaluative weights are differently balanced, and that the intuitive 
pathways linking moral perception to action are expressed differently across the 
two environments. The Watching–Eye stimulus remains potent, but its behavioural 
expression varies in ways aligned with a deformation of the evaluative 
structure through which it is processed, not with any identifiable causal 
operation of the robot itself.

\medskip
\noindent
This interpretation is consistent with contemporary accounts of moral cognition
as a \emph{field-sensitive} process: a dynamic interplay between perceptual
affordances and dispositional filters~\cite{Haidt2001, Cushman2013}. It also
aligns with work in computational moral psychology and Social Signal
Processing~\cite{Vinciarelli2009}, in which moral behaviour is inseparable from
the informational structure of the environment in which it is enacted.

\medskip
\noindent
The experimental data therefore point toward an expanded conception of moral
salience. Moral cues do not operate in isolation; they operate within a
structured perceptual topology that can be modulated or overshadowed by
synthetic presences. In this experiment, NAO functions as such a presence—a
minimal but persistent modulation within the moral environment. Its influence is
subtle: not accessible to reflection, but detectable in the behavioural traces
it leaves.

\bigskip
\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Interpretive Summary BOx: Topological Modulation of Moral Salience]
		The contribution of NAO’s presence lies not in agency or argument, but
		in its capacity to reshape the topology of salience within which moral
		cues are processed. Moral behaviour arises not from isolated stimuli but
		from the structure of the evaluative field—and synthetic presence may
		modulate that structure.
	\end{tcolorbox}
\end{center}
\bigskip
\noindent

Let us now answer the opening question from the inside—the reader’s inside.
A robot enters the room, offers no speech, performs no communicative act, and yet the moral texture of the moment tilts. The poster that pulled you a moment ago is still there, unchanged, but you feel it differently. Your attention recalibrates, your sense of being observed acquires a new contour; the meaning of the scene subtly reorganises. This is what modulation is: not a new voice added to the situation, but a quiet rearrangement of the space in which your intuitions move.
Not persuasion, not instruction—simply a presence that reshapes the contours of how the world matters to you. 

\textit{To say that a synthetic presence modulates the topology of moral salience is to claim that it alters the structural conditions under which perceptual cues acquire evaluative weight.}

This topological perspective sets the stage for the next sectiuon, where we examine its implications for Machine Ethics, synthetic agency, and the normative governance of artificial systems in human moral ecologies.


\section{Beyond Machine Ethics: Synthetic Systems as Moral Perturbators}
\label{sec:discussion_machine_ethics}

\noindent
The empirical findings developed throughout this chapter do not merely illuminate
how robotic presence modulates human moral behaviour; they expose a deeper gap
in contemporary debates on Machine Ethics. Much of the field—both its classical
rule-based formulations~\cite{Moor2006, Anderson2011, Wallach2008} and its more
recent LLM-focused instantiations~\cite{Bender2021, Gabriel2020}—assumes that the primary normative challenge is to encode ethical principles or constraints within artificial systems. The dominant question has thus been: \textit{What moral rules should a machine follow?}

\medskip
\noindent
The experiment exposes an incompleteness in this dominant framing. NAO’s presence in the experimental room involved no explicit norms, reasons, or ethical
architectures. It performed no deliberation, offered no guidance, and issued no
signals of norm compliance. Yet its ontological ambiguity—its subtly animate
form, its quasi-gaze, its minimal motion—appears sufficient to modulate the
topology of moral salience within the human environment. Under Control
conditions, the charity poster functioned as the central attractor in the
evaluative field; under robotic co-presence, that field appears partially
reconfigured, and its intuitive pull toward prosocial action reduced.

\medskip
\noindent
This pattern has two important implications for Machine Ethics.


\paragraph{1. Moral influence precedes moral agency.}
Artificial systems can exert morally relevant effects without possessing any
internal moral architecture. NAO did not ``act morally’’ or ``immorally’’; it
simply \emph{shifted what became salient}. The locus of moral influence
therefore moves from internal reasoning to \textit{ambient modulation}: machines
affect moral cognition by shaping the perceptual and normative environments in
which humans operate~\cite{Hutchins1995, Clark2008}.

\paragraph{2. Ethical design cannot be reduced to rule encoding.}
If moral behaviour is sensitive to the topology of the evaluative field, then a
central task in AI design is not only to embed codes of conduct, but to
understand and govern the ways in which artificial systems reshape that field.
This includes their presence, their framing effects, their aesthetic and
affective affordances, and their patterns of ambiguity. The point extends beyond
robotics: large language models, recommender systems, and interactive platforms
also influence behaviour by reorganising attention, salience, and interpretive
structure~\cite{Coeckelbergh2023, Floridi2024LLM}. The empirical findings here
render such influence both measurable and theoretically tractable.


\medskip
\noindent
From the standpoint of Floridi’s Levels of Abstraction, NAO does not acquire
normative relevance by virtue of its internal properties, but through its
\emph{LoA of encounter}. Participants did not perceive code or architecture; they
encountered a semiotic bundle whose perceptual cues activated anthropomorphic
expectations. This aligns with Floridi’s claim that artificial systems can become
morally relevant not through agency but through their informational role within a
situation~\cite{Floridi2013}. Our data illustrate such informational relevance in
operation: mere presence appears sufficient to modulate the evaluative mapping
$f(\cdot)$, particularly for individuals whose latent cognitive--affective
profiles render them sensitive to empathic cues.

\medskip
\noindent
The recasting of Machine Ethics that follows from this is therefore not merely
optional but methodologically motivated. The empirical record indicates that
synthetic systems already participate in moral ecologies—not by reasoning, but by
altering the interpretive conditions under which humans reason~\cite{Speri2023}.
Ethical governance must thus extend from an \emph{agent-centric} model to what
may be called an \textbf{ecological model of synthetic presence}. The pressing
question becomes:

\begin{quote}
	\textit{How do artificial systems, by virtue of their presence, appearance,
		affordances, or outputs, reorganise the structure of moral salience within human
		evaluative fields—and how should such reorganisations be governed?}
\end{quote}

\medskip
\noindent
This ecological reframing captures what the experimental data suggest
consistently:

\begin{itemize}
	\item The dilution of prosocial behaviour under robotic presence was not caused
	by explicit commands or norms, but by a shift in the salience landscape.
	
	\item This shift was trait-contingent: some cognitive--affective ecologies
	showed greater susceptibility to perturbation; others exhibited minimal change.
	
	\item The perturbation was probabilistic and topological rather than
	categorical or rule-like.
	
	\item The behavioural outcome was not reducible to reasoning or deliberation,
	but reflected pre-reflective, intuitive pathways consistent with the Social
	Intuitionist Model of moral judgement~\cite{Haidt2001,Cushman2013}.
\end{itemize}

\medskip
\noindent
Thus, if Machine Ethics continues to focus primarily on the internal logic of
artificial systems while neglecting their pervasive, subtle influence on human
evaluative dynamics, it risks addressing the wrong explanatory level. The moral
effects of synthetic agents arise long before questions of moral reasoning,
explicit choice, or appeals to ethical theory. They arise within the geometry of
the evaluative field itself.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Conceptual Shift: From Ethical Agents to Moral Ecologies]
		Artificial systems shape human moral behaviour not by applying moral rules, but
		by modulating the topology of salience through which moral cues are interpreted.
		Machine Ethics must therefore expand from the design of ``moral agents'' to the
		analysis and governance of the \emph{moral environments} co-created by human and
		synthetic presence.
	\end{tcolorbox}
\end{center}

\noindent
This conceptual shift sets the stage for the final section of the Discussion
chapter, where the empirical, formal, and philosophical insights are integrated
into a broader agenda for computational moral psychology, synthetic presence, and
the normative governance of AI systems. We turn now to that synthesis.


\section{Moral Topology, Synthetic Presence, and the Architecture of Human--Machine Moral Ecosystems}
\label{sec:discussion_synthesis}

\noindent
This final section integrates the empirical, formal, and philosophical strands of
the chapter into a unified account of how synthetic embodied presence may modulate
the pathways through which moral salience becomes action. The aim is not simply
to restate results, but to clarify the conceptual terrain they suggest: a terrain
in which artificial systems influence moral behaviour not through explicit
reasoning or agency, but through their perceptual affordances and their position
within the evaluative ecology of the human observer.


\subsection*{The Empirical Core: A Refracted Path from Salience to Action}

\noindent
Across behavioural contrasts, nonparametric tests, cluster-wise regressions, and
Bayesian estimation, a structurally consistent pattern appears: \textit{prosocial donation tends to be attenuated in the presence of the humanoid robot}. The
attenuation is modest in magnitude, probabilistic rather than categorical, and
concentrated within one dispositional regime—the \textit{Prosocial--Empathic}
cluster—yet it is observable and remains aligned with the theoretical
commitments that motivated the study. Rather than eliminating the Watching--Eye
effect, synthetic presence \emph{refracts} it: the intuitive moral pull of the
infant poster appears partially displaced by the robot’s embodied but
ontologically indeterminate presence.


\subsection*{Relation to the Hypotheses}

\noindent
The full set of hypotheses introduced earlier can now be considered:

\begin{enumerate}
	\item \textit{H1: Evaluative Deformation}: \textbf{Cautiously supported}. Aggregate attenuation and the Bayesian directional
	tendency suggest that the expected mapping
	$\mathbb{E}[f(\Sigma \cup \mathscr{R})] < \mathbb{E}[f(\Sigma)]$ is consistent
	with the patterns observed in this dataset.
	
	\item \textit{H2: Synthetic Normativity}:\textbf{Conceptually supported}. The robot appears to influence moral behaviour despite lacking agency, propositional content, or explicit interaction. Its normative relevance arises from its perceptual ontology at the operative LoA, in a manner consistent with H2’s prediction.
	
	\item \textit{H3: Synthetic Perturbation of Moral Inference}: \textbf{Supported in structure}. The data exhibit refractive modulation of intuitive evaluative pathways—most clearly within the Prosocial--Empathic cluster—
	consistent with the hypothesis that $\gamma_R$ modulates the \emph{transition}
	from moral salience to action rather than motivational baselines alone.
\end{enumerate}

Taken together, the hypotheses form a coherent interpretive structure for the
empirical results. Each highlights a different facet of the same underlying
phenomenon: the pathways from moral salience to action are not fixed, but
conditioned by the informational and perceptual context in which they unfold.
Synthetic presence does not impose new norms or displace existing motives; it
modulates the evaluative conditions under which moral cues are registered,
weighted, and acted upon. In this sense, the hypotheses collectively support a
topological reading of the findings, in which the influence of $\mathscr{R}$
operates at the level of intuitive appraisal rather than explicit reasoning. This
provides the conceptual bridge to the broader synthesis that follows.


\subsection*{The Formal Architecture: Moral Cognition as a Topological Process}

\noindent
The mathematical decomposition
\[
f(\alpha_E, \beta_C, \gamma_R)
\]
did more than provide notation: it oriented the analytic workflow.  
By treating moral action as a mapping over perceptual cues ($\alpha_E$),
dispositional structures ($\beta_C$), and synthetic presence ($\gamma_R$), the
framework suggested:

\begin{itemize}
	\item that attenuation could arise even when explicit justification remains
	unchanged (a deformation of $f$, not of explicit reasoning);
	\item that individual differences would matter primarily when modelled as
	structured ecologies rather than isolated traits;
	\item that any perturbation would likely manifest as \emph{graded} shifts
	across moral topologies, a pattern consistent with the Bayesian posterior.
\end{itemize}

\noindent
In this way, the formalism functioned as both a conceptual and empirical scaffold,
providing the structure within which the data could be interpreted.


\subsection*{The Formal Architecture: Moral Cognition as a Topological Process}

\noindent
The evaluative formalism introduced in Chapters~\ref{chap:moral_primer}–\ref{chap:tools_new},
expressed schematically as
\[
f(\alpha_E, \beta_C, \gamma_R),
\]
served in this thesis not as ornamentation but as a conceptual orientation for
both the empirical modelling and the interpretive analysis. By treating moral
action as a transformation defined over perceptual cues ($\alpha_E$),
dispositional structure ($\beta_C$), and synthetic presence ($\gamma_R$), the
framework clarified in advance what kinds of patterns the data could meaningfully
support.

\medskip
\noindent
Under this lens, attenuation does not require changes in explicit reasoning:
it is understood as a deformation in the evaluative mapping itself.  
Similarly, individual differences become intelligible only when dispositions are
treated as structured configurations rather than as isolated traits.  
And because $f$ is defined over continuous evaluative landscapes, any modulation
is expected to appear not as a categorical shift but as a graded displacement—a
pattern aligned with the statistical profiles observed in the Bayesian posterior
and cluster analyses.

\medskip
\noindent
\noindent
Stepping back from the analyses, the formalism and the findings converge on a
simple but demanding insight: artificial systems matter not because of what
they \emph{are}, but because of how they \emph{enter} the evaluative field in which
human moral life unfolds. At the operative Level of Abstraction, NAO was not a
machine but a perceptual presence—an element in the topology through which
salience flowed and was reshaped. What the study reveals, in the end, is that
moral behaviour is less a sequence of choices than a movement through a field of
affordances, and that synthetic presence can bend that field in ways that escape
deliberation but remain legible in action. The task ahead, for ethics and for
design, is to understand and govern these subtle curvatures.


\subsection*{Alternative Explanations and Inferential Controls}

\noindent
A series of inferential controls was implemented to assess whether the attenuation
of prosocial donation could be attributed to extraneous factors. Demographic
symmetry was verified; no variable differed across conditions. Big Five traits
showed no between-condition differences after FDR correction, nor did they predict
or moderate donation behaviour in any of the models. Cluster structures were
examined through PCA reduction, WCSS elbow analysis, and silhouette scores,
indicating that they reflect latent organisation rather than algorithmic noise.
Distributional artefacts were considered using nonparametric tests and Bayesian
uncertainty modelling.

\medskip
\noindent
Taken together, these controls suggest that the observed attenuation is unlikely to
be a statistical artefact or the byproduct of hidden group asymmetries. Its profile
aligns most closely with the mechanism articulated in
Hypothesis~\ref{hyp:three} (page~\pageref{hyp:three}): a modulation arising from the
structure of the evaluative field rather than from demographic or trait-level
variation.



\subsection*{Levels of Abstraction: Why Ontological Ambiguity Matters}

\noindent
Floridi’s Levels of Abstraction clarify why an entity without agency can still
influence human moral behaviour. Participants do not encounter NAO at the design
LoA of circuitry or code, nor at the intentional LoA of belief and desire. They
encounter it at the perceptual LoA: as a body-shaped, gaze-bearing presence that
activates anthropomorphic expectations while withholding the behavioural cues
that would confirm full agency. It is this ontological ambiguity that appears to
produce a local modulation in the evaluative field. The robot becomes a
\emph{semantic attractor}—a competing locus of salience that may diffuse the pull
of the Watching--Eye cue.

\medskip
\noindent
This interpretation is consistent with the mechanism anticipated in
the second hypothesis~\ref{hyp:two} (page~\pageref{hyp:two}) and in the third~\ref{hyp:three} (page~\pageref{hyp:three}): not the suppression of
moral salience, but its redistribution within a topology sensitive to the
informational structure of the encounter. Ontological ambiguity becomes morally
operative because it reframes the conditions under which perceptual cues acquire
evaluative weight.



\subsection*{Modest Qualifiers: Limits of Scope and Interpretation}

\noindent
The empirical claims advanced in this chapter must be read with proportionate
discipline. The behavioural attenuation associated with synthetic presence is modest
in magnitude (\(d \approx 0.30\); \(\Delta \approx 0.20\)), and the sample—
particularly within clusters—places natural constraints on granularity (see page~\pageref{subsec:participants}). The moral
task examined here is narrow in scope: a single Watching--Eye stimulus linked to a
cost-bearing donation. Likewise, the form of synthetic presence is specific: a
humanoid embodiment performing minimal micro-movements in autonomous life mode.
The conclusions therefore apply to \emph{synthetic embodied systems occupying
	salient perceptual niches}, not to artificial systems in general.

\medskip
\noindent
These qualifications do not detract from the conceptual contribution. They
delineate the empirical boundaries within which the evaluative–topological
interpretation is appropriate.

\subsection*{Implications for Machine Ethics: From Agents to Environments}

\noindent
The findings challenge the agent-centred orientation that continues to shape much
work in Machine Ethics. Modulation of moral behaviour occurred without reasoning,
interaction, intention, or agency. The synthetic system exerted influence
\emph{through the environment itself}: by modulating the perceptual and affective
context in which intuitive moral appraisal unfolded. This shifts the ethical focus
from the design of “moral agents” to the analysis and governance of \emph{moral
	environments} structured by artificial presence.

\medskip
\noindent
In this ecological framing, the operative question becomes:
\begin{quote}
	\textit{How do artificial systems reweight the informational and affective cues
		that guide human moral judgement?}
\end{quote}

\noindent
The present experiment provides controlled evidence that such reweighting is
observable, structured, and measurable within the evaluative field.

\subsection*{Future Directions}

\noindent
Several avenues for further inquiry emerge from these findings. Future experiments
may extend the paradigm to richer moral domains—fairness, harm, loyalty, or
authority—where the topology of salience could differ markedly. The latent
dispositional structure might be modelled using fully Bayesian mixture frameworks
in which uncertainty forms an explicit part of the inference. Different forms of
synthetic presence—vocal, gestural, autonomous, or varying in anthropomorphic
fidelity—could be tested to map the space of perturbational affordances. Finally,
the topological framework developed here may be applied to LLM-mediated
interaction, where salience modulation occurs through linguistic framing rather
than embodied presence.

\medskip
\noindent
Together, these directions outline a broader programme: charting how artificial
systems participate in, and sometimes reorganise, the intuitive substrate of human
moral cognition.



\subsection*{Closing Insight}

\noindent
Moral cognition does not unfold in isolation; it unfolds within a field. This
study suggests that even a minimally active synthetic body can modulate that
field’s geometry, influencing how moral cues are weighted and how meaning moves
toward action. The effect is subtle, but its significance is structural:
artificial systems affect us not by what they \emph{do}, but by the conditions
they create for intuitive appraisal. As such presences become ordinary features of
human environments, mapping these evaluative topologies becomes an essential task
for the ethics of AI.

\bigskip
\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Closing Insight: Synthetic Presence as a Moral Force]
		Synthetic embodied systems may modulate human moral behaviour not through
		explicit agency but by reweighting the evaluative field itself. Their
		influence is contextual, dispositional, and topological. As such presences
		become ordinary elements of human environments, understanding these moral
		topologies—and their limits—will be central to the next generation of AI
		ethics.
	\end{tcolorbox}
\end{center}
\bigskip


\section{Final Synthesis: Moral Topology, Synthetic Presence, and the Boundaries of Interpretation}

\noindent
The empirical, formal, and probabilistic analyses developed throughout this
chapter allow us to return to Question~\ref{q:robot-agent} with a qualified but
informative answer. Across the analytic frameworks employed—frequentist
contrasts, cluster-specific regressions, and Bayesian hierarchical
estimation—a structurally coherent pattern is observed:
\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{The silent co-presence of a humanoid robot is associated with a
			reduction in prosocial donation under specific psychological
			configurations.}
	\end{leftbar}
\end{center}
\bigskip
\noindent
The effect is modest in magnitude, yet \textbf{directionally consistent across analytic approaches} and patterned by the cognitive--affective structure of the observer.


\bigskip
\noindent
\textbf{Behavioural Attenuation and Its Structure.}  
At the behavioural level, the Robot condition exhibits lower donation amounts
than the Control condition. This aggregate attenuation aligns with the Evaluative
Deformation Hypothesis (H1), which anticipated a shift in the expected output of
the evaluative transformation $f(\cdot)$ when $\mathscr{R}$ is present. The Bayesian
posterior further indicates a directional attenuation, while retaining substantial
uncertainty—an uncertainty appropriately handled by a modelling framework that
treats epistemic space as graded rather than binary.

Cluster-specific analyses refine this picture: the attenuation is \textit{most
	pronounced descriptively} in the \textbf{Prosocial--Empathic} profile, minimal in
the \textbf{Analytical--Structured} profile, and negligible in the
\textbf{Emotionally Reactive / Low-Structure} profile. This distribution of
sensitivity is consistent with Hypothesis~3 (Synthetic Perturbation of Moral
Inference at page~\pageref{hyp:three}), which proposed that $\gamma_R$ would
refract the evaluative pathway from salience to action rather than generate a
categorical shift in behaviour.

\bigskip
\noindent
\textbf{Synthetic Normativity Revisited.}  
The findings also refine the Synthetic Normativity Hypothesis (H2). NAO does not
induce new normative structures; it presents no reasons, norms, or evaluative
guidance. Instead, the data suggest that synthetic normativity arises through
\emph{salience modulation}: a subtle reorganisation of the informational field
within which moral cues are interpreted. NAO shifts what is foregrounded, what is
affectively available, and which elements of the scene are treated as
normatively charged. In this sense, H2 is \textit{supported but also constrained}:
synthetic presence appears to shape the interpretive environment without
introducing novel normative affordances.

\bigskip
\noindent
\textbf{Excluding Alternative Explanations.}  
Several competing explanations can now be set aside as less plausible. Descriptive
and inferential symmetry analyses indicate that the two experimental groups were
demographically comparable; Big Five traits show no between-condition differences
after FDR correction; dispositional moderation tests yield no reliable
interactions; and Bayesian modelling incorporates the zero-inflated nature of the
data and the heterogeneity of cluster sizes. The observed attenuation is therefore
unlikely to be an artefact of demographic imbalance, trait asymmetry, or
unmodelled distributional distortions.

\bigskip
\noindent
\textbf{Contribution of the Formal Framework.}  
The mathematical decomposition introduced earlier provided the structural scaffold
for the analysis. The tripartite formulation
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R)
\]
clarified where dispositional structure should enter the model, why moderation was
theoretically plausible, and how cluster-dependent attenuation could be interpreted
as variation in the cognitive--affective landscape through which $\mathscr{R}$ is
encountered. The formalism therefore offered expectations against which the data
could be interpreted, and the major empirical pattern is \textit{consistent with
	the view that perturbation arises not globally but through dispositional
	topologies encoded in $\beta_C$}.

\bigskip
\noindent
\textbf{Boundaries of the Evidence.}  
The inferences presented in this chapter remain constrained by the characteristics
of the dataset: a modest sample size, zero-inflated donation values, uneven cluster
sizes, and the inherent subtlety of moral effects in minimal-interaction
paradigms. These limitations are explicitly accounted for within the Bayesian
modelling, yet they warrant interpretive modesty. The attenuation effect is
probabilistic, not deterministic; trait-contingent, not universal.

\bigskip
\noindent
\textbf{Synthesis.}  
What the chapter ultimately suggests is that \textit{synthetic embodied systems
	occupying salient perceptual niches can modulate the intuitive pathways through
	which moral salience becomes moral action}. This modulation is small but
structured, uncertain but directionally consistent, and contingent on the
evaluative architecture of the observer. NAO functions not as an ethical agent
but as a perturbative presence—a semiotic element that subtly reorganises aspects
of the geometry through which intuitive appraisals flow.

\bigskip
\noindent
\textbf{Towards a Broader Theoretical Horizon.}  
The findings have implications beyond this specific experimental context. They
suggest that artificial systems influence human moral cognition not through
explicit norm transmission, but through shifts in attention, salience, and
interpretive framing. This resonates with research in Social Signal Processing,
Affective Computing, and the emerging ecological turn in Machine Ethics, where
moral influence is understood as distributed, environment-dependent, and often
pre-reflective.

The chapter establishes that moral behaviour is topologically sensitive to
synthetic presence and trait configuration. The next two chapters expand this
insight, integrating the empirical results with the theoretical, methodological,
and ethical commitments of the thesis as a whole.

\bigskip
\textbf{Closing Reflection.}  
What the analyses in this chapter suggest is structurally modest but
conceptually consequential. A synthetic body—silent, minimally animated, and
devoid of agency—may alter the conditions under which moral salience becomes
action. In formal terms, this appears as a deformation of the evaluative mapping
$f(\alpha_E, \beta_C, \gamma_R)$; in behavioural terms, as a small but
directionally stable attenuation of prosocial response. At the operative Level
of Abstraction, however, the phenomenon is encountered neither as mechanism nor
as message, but as \emph{presence}: an element that subtly reorganises what is
foregrounded, what recedes, and what exerts intuitive pull.

\medskip
\noindent
In these terms, this is what it means for synthetic presence to modulate the
topology of moral salience. The evaluative field is not fixed; it appears
sensitive to the perceptual and normative structure of the environment in which
it unfolds. The perturbation observed here is modest in magnitude, yet it is
consistent with a more general property of moral cognition: intuitive appraisal
is shaped by contextual topologies that increasingly include artificial bodies.

\medskip
\noindent
The task of the present chapter has been to render that modulation empirically
tractable and formally interpretable. The task that remains is interpretive. The
chapters that follow take up this responsibility, turning from experimental
analysis to its philosophical, ethical, and normative consequences—asking what
it means to inhabit moral environments in which synthetic presences are no
longer exceptional, but ordinary.


