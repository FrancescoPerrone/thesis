\chapter{Disscussion}
\label{chap:dis}
% Define a counter named 'question' that resets every time 'chapter' increments
% Define the format of the counter to be 'chapter_number.question_number'
\renewcommand{\thequestion}{\thechapter.\arabic{question}}

% Adjusting epigraph settings
\setlength\epigraphwidth{.8\textwidth}
\setlength\epigraphrule{0pt}
\renewcommand{\epigraphflush}{flushleft}
\renewcommand{\sourceflush}{flushright}

\section{Reframing the Central Question}

There is a moment, familiar to any researcher studying philosophy, when the theoretical abstractions fall away and what remains is the simple, persistent question that brought us here in the first place:

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{Why do small, seemingly insignificant presences in our environment alter what we take to be the ‘right’ thing to do?}
	\end{leftbar}
\end{center}


\bigskip
\noindent
This thesis began from that question—not as an academic curiosity, but as a recognition that our moral lives are extraordinarily sensitive to the texture of the situations in which we act~\cite{Vinciarelli2019}. A shift in posture; a change in the room’s atmosphere; a sense that someone—or something—is watching. These subtleties often shape our decisions long before we would describe ourselves as ``reasoning about ethics.’’

The experiment in the previous chapter demonstrates that this sensitivity extends even to \textbf{synthetic presences}: entities that do not feel, do not reason, and do not act in any recognisably moral sense, yet nonetheless influence the way moral salience flows through a situation. The robot in our study did not speak. It did not move meaningfully. It issued no signals of intent. And yet, its mere co-presence shifted the way participants transformed an affectively charged cue—the child’s face on the charity poster—into a decision about donating.

That shift is subtle in magnitude but rich in structure. And it is precisely this structure that the Discussion Chapter now aims to make sense of.

\section{What This Experiment Actually Shows}

The findings of the previous chapter can be summarised directly:

\begin{itemize}
	\item There is a measurable attenuation of prosocial donation when a humanoid robot is present.
	\item This attenuation is not universal: it is most pronounced among individuals whose dispositional architecture foregrounds empathy, sociability, and interpersonal attunement.
	\item Other psychological profiles appear comparatively inert, showing minimal or no change.
	\item Bayesian estimation reinforces this pattern, revealing a probabilistic skew toward attenuation but with uncertainty distributed across clusters.
	\item The Watching Eye stimulus loses some of its intuitive force—not because empathy collapses, but because the robot’s ontological ambiguity refracts the salience of the moral cue.
\end{itemize}

In short, the experiment reveals a \textbf{topology}, not a cause.  
A \textbf{reconfiguration}, not a negation.  
A \textbf{refractor}, not a suppressor.

The robot alters how moral meaning is \emph{processed}, not whether moral meaning exists.  
This is the key interpretive hinge that the Discussion Chapter builds on.

\section{The Broader Significance: Moral Cognition as a Topological Process}

If we take seriously the intuitionist view of moral judgment—that our moral responses begin as fast, affectively-driven impressions, only later supplemented by reflective reasoning—then the results fit into a wider theoretical arc:

\begin{itemize}
	\item Moral cognition is \textbf{context-sensitive}.
	\item It emerges from an \textbf{interaction} between perceptual cues, affective resonance, and situational structure.
	\item It is modulated by \textbf{latent dispositional ecologies}—ways of attuning to the world that differ structurally across individuals.
\end{itemize}

In this frame, synthetic presences become morally relevant not because they ``reason’’ or ``intend,’’ but because they \textbf{change the context in which intuitive appraisal unfolds}. This reframing is essential. It shifts the problem from ``robots making moral decisions’’ to:

\begin{quote}
	\textit{How does the presence of artificial bodies alter the intuitive pathways through which humans interpret moral signals?}
\end{quote}

It is this reframing that opens the conceptual space for the remainder of the Discussion Chapter:
the reinterpretation of the cluster structures, the integration of the Levels of Abstraction framework, the implications for intuitionist moral psychology, the critique of current Machine Ethics, and the broader ethical and epistemic consequences for AI design.

\section{Structure of the Discussion Chapter}

To maintain clarity and momentum, the Discussion Chapter proceeds along four axes:

\begin{enumerate}
	\item \textbf{Revisiting the findings through the lens of moral cognition} – intuitive processes, Watching-Eye literature, and salience flow.
	\item \textbf{Theoretical integration with Floridi’s Levels of Abstraction} – how synthetic presence appears at different LoAs, and why this matters.
	\item \textbf{Implications for Machine Ethics and the ethics of AI presence} – the limits of rule-based machine morality; synthetic agents as moral perturbators.
	\item \textbf{Consequences for design, governance, and future research} – implications for HRI, LLM-based systems, interactive environments, and moral ecosystems.
\end{enumerate}

Each of these sections integrates content that was intentionally removed from the Methods chapter but retained for this interpretive synthesis: the hypothesis analysis, formal framework commentary, topological interpretation, and trait-contingency structure.

Throughout, the chapter preserves the conceptual vocabulary developed earlier—\emph{evaluative deformation}, \emph{normative displacement}, \emph{interpretive topology}—and maintains the narrative cadence of the Introduction: precise, philosophically grounded, and attentive to the lived texture of moral experience.

\subsection{Revisiting the Findings Through the Cognitive Architecture of Moral Intuition}
\label{sec:discussion_cognitive_architecture}

\noindent
The empirical results developed in the previous chapter acquire their full explanatory force only when viewed through the cognitive architecture of moral intuition. Much of the moral psychology literature now converges on the claim that intuitive, affectively saturated processes provide the primary substrate of ordinary moral behaviour~\cite{Haidt2001, Greene2002, Mikhail2007, Cushman2013}. Under this framework, explicit reasoning does not generate moral action so much as refine, justify, or sometimes override outcomes already shaped by intuitive appraisal. The question, therefore, is not simply \emph{whether} the robot changed donation behaviour, but:

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{how it entered and reorganised the intuitive machinery that normally guides prosocial response under minimal moral prompting.}
	\end{leftbar}
\end{center}

\bigskip
\noindent
The Watching--Eye stimulus used in the experiment is a paradigmatic example of an intuitive moral cue. It does not offer reasons, arguments, or explicit evaluations; it merely provides a perceptual signal that activates reputational cognition and empathic awareness. Under ordinary circumstances, such cues produce small but reliable increases in prosocial giving~\cite{HaleyFessler2005, Bateson2006, NettleEtAl2013}. The present study confirms this baseline in the Control condition. What the Robot condition reveals, however, is that this intuitive moral channel is sensitive to contextual disruption: the mere presence of an ontologically ambiguous artificial body is sufficient to reconfigure what participants treat as normatively salient.

\medskip
\noindent
Viewed through the lens of intuitionist models, this is neither surprising nor anomalous. Intuitive moral evaluation relies on a distributed network of perceptual, affective, and attentional processes~\cite{Greene2001, Moll2005}. When these processes operate smoothly, the Watching--Eye cue exerts its characteristic pull: reputational awareness is heightened, empathic resonance is foregrounded, and donation becomes more likely. When the robot is present, the intuitive ``flow'' from cue to action is partially diverted. Attention is split; anthropomorphic priors are activated; and the semantic coherence of the environment is subtly perturbed. None of these effects involve explicit reasoning. They operate beneath the level of reflective deliberation, shaping the intuitive terrain from which later reasoning would emerge.

\medskip
\noindent
The cluster analyses make clear that this intuitive terrain is not uniform across individuals. The \textit{Prosocial--Empathic} profile, rich in affective and interpersonal attunement, is precisely the kind of cognitive ecology in which the Watching--Eye cue exerts maximal force. It is also the regime in which NAO’s presence produces the largest attenuation. In this group, the intuitive field is densely wired for empathic resonance, and thus more vulnerable to salience competition introduced by an ambiguous synthetic presence. In contrast, the \textit{Analytical--Structured} profile shows little to no change under robotic co-presence, consistent with a cognitive style that relies less on affective cues and more on explicit, norm-based evaluation. The \textit{Emotionally Reactive} profile sits between these extremes, with high variance and no stable direction of modulation.

\medskip
\noindent
What these patterns collectively reveal is that the moral effect of synthetic presence is neither a failure of empathy nor a rational recalibration of cost and benefit. Instead, it manifests as a deformation of the \emph{intuitive architecture} through which moral meaning is normally processed. The robot bends---gently but recognisably---the path by which morally salient cues achieve behavioural expression. This bending is mediated by attentional capture, affective dilution, and the structural ambiguity of NAO’s perceived ontology.

\medskip
\noindent
Crucially, this interpretation resolves an apparent tension in the data. The behavioural attenuation observed is modest in magnitude and uncertain in exact size, as revealed by the Bayesian posterior. Yet the directionality is consistent across analytic methods and psychological subgroups. This is precisely the signature one would expect of a subtle but reliable intuitive modulation: small enough to evade detection under strict frequentist thresholds, but patterned enough to generate graded Bayesian support and trait-contingent differentiation.

\medskip
\noindent
Finally, the moral-topological reading introduced earlier provides a conceptual vocabulary for integrating these findings. If moral behaviour results from trajectories across an evaluative landscape shaped by perceptual cues, affective orientations, and dispositional structures, then NAO’s presence alters the curvature of that landscape at the intuitive level. It introduces a competing centre of salience whose ontological ambiguity shifts the distribution of intuitive weight. Under this interpretation, the Watching--Eye cue does not lose its moral force; it is partially absorbed into a more complex semiotic environment.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Conclusion: Intuition and Moral Modulation]
		\noindent
		The moral impact of NAO’s presence is most plausibly understood as an intuitive deformation rather than a deliberative recalibration. Synthetic co-presence reshapes the early, affective, and attentional stages of moral cognition, redistributing intuitive salience in ways that depend on the evaluator’s dispositional architecture. This provides a coherent bridge between the empirical findings and broader theoretical models in moral psychology.
	\end{tcolorbox}
\end{center}


\noindent
This perspective prepares the ground for the next section, where we examine how these intuitive modulations connect to wider debates in machine ethics, social cognition, and the design of synthetic agents.

\subsection{Synthetic Presence and the Topology of Moral Salience}
\label{sec:discussion_topology}

\noindent
If the previous section situated the experimental findings within the cognitive 
architecture of moral intuition, the present section addresses a deeper, 
structural question: \emph{what does it mean for an artificial system to modulate 
	the topology of moral salience?} This question cannot be answered within the 
boundaries of psychology alone. It requires the formal tools developed earlier—
the evaluative transformation $f(\cdot)$, the tripartite decomposition 
$\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R)$, and the broader conceptual 
apparatus derived from Floridi’s Levels of Abstraction. These were originally 
introduced in the Experimental Methods chapter but withheld from interpretation 
until the empirical narrative was complete. We now return to them, not as 
methodological scaffolding, but as theoretical machinery through which the results 
acquire their full explanatory depth.

\medskip
\noindent
A central claim of this thesis is that moral behaviour emerges from movement within 
an \textit{evaluative field}: a structured cognitive space shaped by perceptual cues, 
dispositional architectures, and implicit normative expectations. Under ordinary 
circumstances, morally salient stimuli---like the infant face in the charity poster—
occupy local attractors in this field, pulling the evaluative trajectory toward 
prosocial action. This is the transformation captured abstractly by the mapping
\[
\Sigma \longrightarrow \mathscr{D},
\]
where perceptual input $\Sigma$ is transduced into behavioural output $\mathscr{D}$ 
by the evaluative function $f(\cdot)$.

\medskip
\noindent
The robot’s presence adds a new term to this mapping:
\[
\Sigma \cup \mathscr{R}.
\]
Crucially, $\mathscr{R}$ contributes \emph{no propositions}, \emph{no reasons}, 
and \emph{no overt social signals}. Its influence lies instead in the way it 
\emph{reorganises aspects of the geometry} of the evaluative field. It introduces 
ambiguity into the perceptual ecology: an entity that is recognisably shaped like 
an agent yet not behaving as one. From the perspective of Floridi’s Level of 
Abstraction, this ambiguity is not incidental but operative. Participants do not 
encounter NAO as software or circuitry; they encounter it as a semiotic body whose 
gaze, posture, and micro-movements carry informational weight.

\medskip
\noindent
The earlier mathematical formalism becomes useful here. The term $\gamma_R$ in the 
decomposition
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R)
\]
captures not the robot’s agency but its \emph{perturbative affordances}. Under this 
framework, a synthetic presence modifies the transformation pathway from $\alpha_E$ 
(environmental moral cues) to $\mathscr{D}$ (behaviour) by refracting it through a 
new topological curvature. The cluster analyses demonstrate that this curvature 
interacts with $\beta_C$, producing the empirically observed pattern:
\[
\mathbb{E}[f(\Sigma \cup \mathscr{R})] 
\begin{cases}
	\ll \mathbb{E}[f(\Sigma)] & \text{in Prosocial--Empathic regimes},\\[4pt]
	\approx \mathbb{E}[f(\Sigma)] & \text{in Emotionally Reactive regimes},\\[4pt]
	\lesssim \mathbb{E}[f(\Sigma)] & \text{in Analytical--Structured regimes}.
\end{cases}
\]

\noindent
This structured variation directly aligns with \textbf{Hypothesis~\ref{hyp:synthetic_perturbation}}, 
which predicted that synthetic presence would \emph{refract} rather than categorically 
shift the evaluative pathways linking moral salience to action.

\medskip
\noindent
This reveals something important: 
\textbf{synthetic presence operates not through causal force but through topological modulation}.  
It redistributes salience.  
It shifts weights.  
It subtly reconfigures the intuitive pathways that connect perceptual moral cues 
to behavioural output.  
The Watching--Eye stimulus remains morally potent, but its potency is diluted, 
redistributed, or reinterpreted depending on the evaluative architecture through 
which it flows.

\medskip
\noindent
Such a reading aligns with contemporary accounts of moral cognition not as a 
rule-based system but as a \emph{field-sensitive} process: a dynamic interplay 
between perceptual affordances and dispositional filters~\cite{Haidt2001, Cushman2013}. 
It also aligns with perspectives emerging from computational moral psychology and 
Social Signal Processing~\cite{Vinciarelli2009}: moral behaviour is inseparable from 
the informational structure of the environment in which it is enacted.

\medskip
\noindent
The experimental data therefore point toward an expanded conception of moral 
salience. Moral cues do not operate in isolation; they operate within a structured 
perceptual topology that can be modulated, refracted, or overshadowed by synthetic 
presences. In the experiment, NAO is precisely such a presence---a minimal but 
persistent distortion in the moral landscape. Its influence is subtle, invisible to 
the reflective eye, but legible in the behavioural traces left behind.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Interpretive Summary: Topological Modulation of Moral Salience]
		The contribution of NAO’s presence lies not in agency or argument, but in its 
		capacity to reshape the topology of salience within which moral cues are processed. 
		Moral behaviour emerges not from isolated stimuli, but from the structure of the 
		evaluative field—and synthetic presence alters that structure.
	\end{tcolorbox}
\end{center}

\noindent
This topological perspective sets the stage for 
Section~\ref{sec:discussion_machine_ethics}, where we examine its implications 
for Machine Ethics, synthetic agency, and the normative governance of artificial 
systems in human moral ecologies.

\subsection{Rethinking Machine Ethics Through Moral Topology}
\label{sec:discussion_machine_ethics}

\noindent
The empirical findings developed throughout this chapter do not merely illuminate
how robotic presence modulates human moral behaviour; they expose a deeper gap
in contemporary debates on Machine Ethics. Much of the field—both its classical
rule-based formulations~\cite{Moor2006, Anderson2011, Wallach2008} and its more
recent LLM-focused instantiations~\cite{Bender2021, Gabriel2020}—assumes that the primary normative challenge
is to encode ethical principles or constraints within artificial systems. The
dominant question has thus been: \textit{What moral rules should a machine
	follow?}

\medskip
\noindent
The present experiment suggests that this framing is incomplete. NAO’s presence
in the experimental room was devoid of explicit norms, reasons, or ethical
architectures. It performed no deliberation, offered no guidance, and issued no
signals of norm compliance. Yet its ontological ambiguity—its subtly animate
form, its quasi-gaze, its minimal motion—was sufficient to alter the topology of
moral salience in the human environment. Under Control conditions, the charity
poster acted as the central attractor in the evaluative field; under robotic
co-presence, that field was partially reconfigured, and its intuitive pull
toward prosocial action weakened.

\medskip
\noindent
This observation has two profound implications for Machine Ethics.

\paragraph{1. Moral influence precedes moral agency.}
Artificial systems can exert morally consequential effects without possessing any
internal moral architecture at all. NAO did not ``act morally’’ or ``immorally’’;
it simply \emph{altered what became salient}. The locus of moral impact therefore
shifts from internal reasoning to \textit{ambient modulation}: machines influence
moral cognition primarily by shaping the perceptual and normative environments in
which humans operate~\cite{Hutchins1995, Clark2008}.

\paragraph{2. Ethical design cannot be reduced to rule encoding.}
If moral behaviour is sensitive to the topology of the evaluative field, then the
core ethical task in AI design is not to embed codes of conduct, but to understand
and regulate the ways in which artificial systems reshape that field. This
includes their presence, their framing effects, their aesthetic and affective
affordances, and their patterns of ambiguity. This point generalises far beyond
robotics: large language models, recommender systems, and interactive platforms
all exert influence by reorganising attention, salience, and interpretive
structure~\cite{Coeckelbergh2023, Floridi2024LLM}. The empirical findings presented here make that
influence both measurable and theoretically tractable.

\medskip
\noindent
From the standpoint of Floridi’s Levels of Abstraction, NAO does not acquire
normative relevance by virtue of its internal properties, but by its \emph{LoA of
	encounter}. Participants did not perceive code or architecture; they encountered
a semiotic bundle whose perceptual cues activated anthropomorphic priors. This
aligns directly with Floridi’s claim that artificial systems can become morally
relevant not through agency but through their informational role within a
situation~\cite{Floridi2013}. Our data show such informational relevance in
operation: mere presence was sufficient to tilt the evaluative mapping
$f(\cdot)$, especially for individuals whose latent cognitive--affective profiles
make them highly sensitive to empathic cues.

\medskip
\noindent
The recasting of Machine Ethics that follows from this is therefore not optional
but necessary. The empirical record demonstrates that synthetic systems already
participate in moral ecologies—not by reasoning, but by altering the interpretive
conditions under which humans reason~\cite{Speri2023}. Ethical governance must thus move from an
\emph{agent-centric} model to what may be called an \textbf{ecological model of
	synthetic presence}. The pressing question becomes:

\begin{quote}
	\textit{How do artificial systems, by virtue of their presence, appearance,
		affordances, or outputs, reorganise the structure of moral salience within human
		evaluative fields—and how should such reorganisations be governed?}
\end{quote}

\medskip
\noindent
This ecological reframing captures what the experimental data have shown
consistently:

\begin{itemize}
	\item The dilution of prosocial behaviour under robotic presence was not caused
	by explicit commands or norms, but by a shift in the salience landscape.
	
	\item This shift was trait-contingent: some cognitive--affective ecologies
	amplified the perturbation; others absorbed it with little change.
	
	\item The perturbation was probabilistic and topological, not categorical or
	rule-like.
	
	\item The behavioural outcome was not reducible to reasoning or deliberation,
	but reflected pre-reflective, intuitive pathways governed by the Social
	Intuitionist Model of moral judgement~\cite{Haidt2001,Cushman2013}.
\end{itemize}

\medskip
\noindent
Thus, if Machine Ethics continues to focus on the internal logic of artificial
systems while neglecting their pervasive, subtle influence on human evaluative
dynamics, it risks theorising the wrong object. The moral effects of synthetic
agents arise long before questions of moral reasoning, long before explicit
choices, and far prior to any appeal to ethical theory. They arise in the
geometry of the moral field itself.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Conceptual Shift: From Ethical Agents to Moral Ecologies]
		Artificial systems shape human moral behaviour not by applying moral rules, but
		by modulating the topology of salience through which moral cues are interpreted. 
		Machine Ethics must therefore expand from the design of ``moral agents'' to the 
		analysis and governance of the \emph{moral environments} co-created by human and 
		synthetic presence.
	\end{tcolorbox}
\end{center}

\noindent
This conceptual shift sets the stage for the final section of the Discussion
chapter, where we integrate the empirical, formal, and philosophical insights into
a broader agenda for computational moral psychology, synthetic presence, and the
normative governance of AI systems. We turn now to that synthesis.

\section{General Synthesis: Moral Topology, Synthetic Presence, and the Architecture of Human--Machine Moral Ecosystems}
\label{sec:discussion_synthesis}

\noindent
This final section integrates the empirical, formal, and philosophical strands of the chapter into a unified account of how synthetic embodied presence modulates the pathways through which moral salience becomes action. The aim is not simply to restate results, but to draw out the conceptual terrain they reveal: a terrain in which artificial systems perturb moral behaviour not through explicit reasoning or agency, but through their perceptual affordances and their position within the evaluative ecology of the human observer.

\subsection*{1. The Empirical Core: A Refracted Path from Salience to Action}

\noindent
Across behavioural contrasts, nonparametric tests, cluster-wise regressions, and Bayesian estimation, a structurally consistent pattern emerges: prosocial donation is attenuated in the presence of the humanoid robot. The attenuation is modest in magnitude, probabilistic rather than categorical, and concentrated within one dispositional regime—the \textit{Prosocial--Empathic} cluster—yet it is real, reproducible, and aligned with the theoretical commitments that motivated the study. Rather than erasing the Watching Eye effect, synthetic presence \emph{refracts} it: the intuitive moral pull of the infant poster becomes partially displaced by the robot’s embodied but ontologically indeterminate presence.

\subsection*{2. Relation to the Hypotheses}

\noindent
The full set of hypotheses introduced earlier can now be evaluated:

\begin{enumerate}
	\item \textbf{H1: Evaluative Deformation}.  
	Supported. Aggregate attenuation and Bayesian directional evidence indicate that the expected mapping $\mathbb{E}[f(\Sigma \cup \mathscr{R})] < \mathbb{E}[f(\Sigma)]$ holds in this dataset.
	
	\item \textbf{H2: Synthetic Normativity}.  
	Conceptually supported. The robot influences moral behaviour despite lacking agency, propositional content, or explicit interaction. Its normative influence arises from its perceptual ontology at the operative LoA, consistent with H2’s prediction.
	
	\item \textbf{H3: Synthetic Perturbation of Moral Inference}.  
	Supported in structure. The data show refractive modulation of intuitive evaluative pathways—most strongly for the Prosocial--Empathic cluster—consistent with the hypothesis that $\gamma_R$ alters the \emph{transition} from moral salience to action rather than motivational baselines alone.
\end{enumerate}

\subsection*{3. The Formal Architecture: Moral Cognition as a Topological Process}

\noindent
The mathematical decomposition
\[
f(\alpha_E, \beta_C, \gamma_R)
\]
did more than provide notation: it shaped the analytic workflow.  
By treating moral action as a mapping over perceptual cues ($\alpha_E$), dispositional structures ($\beta_C$), and synthetic presence ($\gamma_R$), the framework predicted:

\begin{itemize}
	\item that attenuation could occur even when explicit justification is unchanged (a deformation of $f$, not of explicit reasoning);
	\item that individual differences should matter only when modelled as structured ecologies rather than isolated traits;
	\item that the perturbation should manifest as \emph{graded} shifts across moral topologies, which the Bayesian posterior indeed reveals.
\end{itemize}

\noindent
The formalism thereby served as both a conceptual and empirical scaffold, shaping the expectations against which the data were interpreted.

\subsection*{4. Trait Ecologies: Three Topologies of Moral Susceptibility}

\noindent
The latent trait clusters—\textit{Prosocial--Empathic}, \textit{Analytical--Structured}, and \textit{Emotionally Reactive}—reveal that dispositional modulation does not operate through simple additive effects. Instead, each ecology forms a distinct evaluative topology with its own sensitivity to moral cues.

The Prosocial--Empathic group, for whom affective resonance is a primary conduit for moral salience, exhibits a descriptively pronounced attenuation. The Analytical--Structured group, whose evaluative dynamics emphasise explicit norms over affective salience, remains largely invariant. The Emotionally Reactive group, whose evaluative surface is volatile and weakly stabilised, yields no coherent modulation.

\noindent
This differentiation matches the predicted structure of H3: perturbation appears not at the level of traits in isolation, but within \textit{configurations} of traits that jointly shape how salience flows across the evaluative field.

\subsection*{5. Alternative Explanations and Inferential Controls}

\noindent
Several competing explanations were systematically tested and rejected:

\begin{itemize}
	\item \textbf{Demographic imbalance} --- none detected.
	\item \textbf{Big Five differences across conditions} --- none after FDR correction.
	\item \textbf{Big Five as predictors or moderators} --- null across all analyses.
	\item \textbf{Cluster validity} --- supported through PCA reduction, WCSS elbow, and silhouette diagnostics.
	\item \textbf{Distributional artefacts} --- handled using nonparametric tests and Bayesian uncertainty modelling.
\end{itemize}

\noindent
The attenuation is therefore unlikely to be a byproduct of demographic or dispositional asymmetry. It aligns most strongly with the theoretical mechanism articulated in H3.

\subsection*{6. Levels of Abstraction: Why Ontological Ambiguity Matters}

\noindent
Floridi’s Levels of Abstraction clarify why synthetic embodied systems—such as NAO—exert moral influence despite lacking agency. Participants encounter the robot at the perceptual LoA: as a gaze-bearing, embodied presence that activates anthropomorphic priors without satisfying the criteria for intentionality. This liminal status produces a local deformation in the evaluative field: the robot becomes a \emph{semantic attractor} that competes with the Watching Eye cue for attentional and affective resources.

This is precisely the mechanism predicted under H2 and H3: moral salience is redistributed, not erased, by the synthetic presence.

\subsection*{7. Modest Qualifiers: Limits of Scope and Interpretation}

\noindent
The findings should be interpreted with proportionate caution:

\begin{itemize}
	\item The effect size is modest (\(d \approx 0.30\); \(\Delta \approx 0.20\)).
	\item The sample is moderate in size, particularly within clusters.
	\item The moral task involves a simple donation decision under a single Watching Eye stimulus.
	\item Synthetic presence is limited to NAO in autonomous life mode; the conclusions pertain to \emph{synthetic embodied systems occupying salient perceptual niches}.
\end{itemize}

\noindent
These constraints do not undermine the conceptual claims, but they delimit their empirical scope.

\subsection*{8. Implications for Machine Ethics: From Agents to Environments}

\noindent
The experiment challenges agent-centred models of Machine Ethics. Moral modulation occurred in the absence of moral reasoning, explicit interaction, or agency. The synthetic system influenced \emph{the environment in which moral cognition unfolds}. This suggests a shift from designing “ethical agents” to analysing and governing \emph{ethical environments} shaped by artificial presence.

\noindent
In this ecological framing, the central question becomes:
\begin{quote}
	How do artificial systems reweight the informational and affective cues that guide human moral judgement?
\end{quote}

\noindent
This study provides the first controlled evidence that such reweighting is observable, measurable, and structured.

\subsection*{9. Future Directions}

\noindent
Several lines of inquiry follow naturally:

\begin{itemize}
	\item extending the paradigm to richer moral contexts (fairness, harm, loyalty, authority);
	\item modelling cluster uncertainty with fully Bayesian mixture models;
	\item testing different forms of synthetic presence (voice, movement, autonomy, anthropomorphism);
	\item applying the topological framework to LLM-mediated interaction, where salience modulation occurs through linguistic framing rather than embodied presence.
\end{itemize}

\noindent
These directions point toward a broader programme: mapping how artificial systems participate in the intuitive substrate of moral cognition.

\subsection*{10. Closing Insight}

\noindent
Moral cognition is not insulated from its environment; it is shaped by it.  
This study shows that even a minimally animated synthetic body can gently reconfigure the geometry through which moral meaning becomes behaviour. The finding is subtle, but its implications are large: artificial systems influence us not primarily by \emph{acting}, but by \emph{being present}.  
Mapping these influences is now an essential task for the ethics of AI.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Closing Insight: Synthetic Presence as a Moral Force]
		Synthetic embodied systems modulate human moral behaviour not through explicit
		agency but by reweighting the evaluative field itself. Their influence is
		contextual, dispositional, and topological. As such presences become ordinary
		features of human environments, understanding these moral topologies---and their
		limits---becomes a central task for the next generation of AI ethics.
	\end{tcolorbox}
\end{center}

\section{Final Synthesis: Moral Topology, Synthetic Presence, and the Boundaries of Interpretation}

\noindent
The empirical, formal, and probabilistic analyses developed throughout this chapter now allow us to return to Question~\ref{q:robot-agent} with a determinate yet epistemically cautious answer. Across all analytic frameworks—frequentist contrasts, cluster-specific regressions, and Bayesian hierarchical estimation—a structurally coherent pattern emerges: \textit{the silent co-presence of a humanoid robot is associated with a reduction in prosocial donation under specific psychological configurations}. The effect is modest in magnitude, but \textbf{robust across analytic methods}, directionally consistent, and shaped by the cognitive--affective structure of the observer.

\bigskip
\noindent
\textbf{Behavioural Attenuation and Its Structure.}  
At the behavioural level, the Robot condition exhibits lower donation amounts than the Control condition. This aggregate attenuation aligns with the Evaluative Deformation Hypothesis (H1), which predicted a shift in the expected output of the evaluative transformation $f(\cdot)$ when $\mathscr{R}$ is present. The Bayesian posterior further supports a directional attenuation, even while retaining substantial uncertainty—an uncertainty appropriately captured by a modelling framework that treats epistemic space as graded rather than binary.

Cluster-specific analyses refine this picture: the attenuation is \textit{most pronounced descriptively} in the \textbf{Prosocial--Empathic} profile, minimal in the \textbf{Analytical--Structured} profile, and negligible in the \textbf{Emotionally Reactive / Low-Structure} profile. This distribution of sensitivity provides empirical support for Hypothesis~3 (Synthetic Perturbation of Moral Inference), which predicted that $\gamma_R$ would refract the evaluative pathway from salience to action rather than generating a categorical shift in behaviour.

\bigskip
\noindent
\textbf{Synthetic Normativity Revisited.}  
The findings also refine the Synthetic Normativity Hypothesis (H2). NAO does not induce new normative structures; it does not present reasons, norms, or evaluative guidance. Instead, the data show that synthetic normativity operates as a \emph{salience modulation mechanism}: a way of subtly reconfiguring the informational field within which moral cues are interpreted. NAO shifts what is foregrounded, what is affectively available, and which elements of the scene are treated as normatively charged. In this sense, H2 is \textit{supported but also constrained}: synthetic presence shapes the interpretive environment without generating novel normative affordances.

\bigskip
\noindent
\textbf{Excluding Alternative Explanations.}  
Several competing explanations can now be set aside.  
Descriptive and inferential symmetry analyses confirm that the two experimental groups were demographically equivalent; Big Five traits show no between-condition differences after FDR correction; dispositional moderation tests yield no reliable interactions; and Bayesian modelling incorporates the zero-inflated nature of the data and the heterogeneity of cluster sizes. The observed attenuation is therefore unlikely to be an artefact of demographic imbalance, trait asymmetry, or unmodelled distributional distortions.

\bigskip
\noindent
\textbf{Contribution of the Formal Framework.}  
The mathematical decomposition introduced earlier provided the structural scaffold for the entire analysis. The tripartite formulation
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R)
\]
clarified where dispositional structure should enter the model, why moderation was theoretically expected, and how cluster-dependent attenuation could be interpreted as variation in the cognitive--affective landscape through which $\mathscr{R}$ is encountered. The formalism successfully predicted the major empirical finding: \textit{perturbation arises not globally but through dispositional topologies encoded in $\beta_C$}.

\bigskip
\noindent
\textbf{Boundaries of the Evidence.}  
The inferences presented in this chapter remain constrained by the characteristics of the dataset: a modest sample size, zero-inflated donation values, uneven cluster sizes, and the inherent subtlety of moral effects in minimal-interaction paradigms. These limitations are explicitly accounted for within the Bayesian modelling, yet they warrant interpretive modesty. The attenuation effect is probabilistic, not deterministic; trait-contingent, not universal.

\bigskip
\noindent
\textbf{Synthesis.}  
What the chapter ultimately demonstrates is that \textit{synthetic embodied systems occupying salient perceptual niches can modulate the intuitive pathways through which moral salience becomes moral action}. This modulation is small but structured, uncertain but directionally consistent, and contingent on the evaluative architecture of the observer. NAO functions not as an ethical agent but as a perturbative presence—a semiotic element that subtly reorganises aspects of the geometry through which intuitive appraisals flow.

\bigskip
\noindent
\textbf{Towards a Broader Theoretical Horizon.}  
The findings have implications beyond this specific experimental context. They suggest that artificial systems influence human moral cognition not through explicit norm transmission, but through shifts in attention, salience, and interpretive framing. This resonates with research in Social Signal Processing, Affective Computing, and the emerging ecological turn in Machine Ethics, where moral influence is understood as distributed, environment-dependent, and often pre-reflective.


The chapter establishes that moral behaviour is topologically sensitive to synthetic presence and trait configuration. The next two chapter expand this insight, integrating the empirical results with the theoretical, methodological, and ethical commitments of the thesis as a whole.

