%\chapter{An Experimental Study of Moral Displacement: From Normative Hypothesis to Experimental Topology}
\chapter{Experimental Methods}
\label{chap:exp_methods}
\thispagestyle{pprintTitle}


% Define a counter named 'question' that resets every time 'chapter' increments
\newcounter{question}[chapter]
% Define the format of the counter to be 'chapter_number.question_number'
\renewcommand{\thequestion}{\thechapter.\arabic{question}}

% Adjusting epigraph settings
\setlength\epigraphwidth{.8\textwidth}
\setlength\epigraphrule{0pt}
\renewcommand{\epigraphflush}{flushleft}
\renewcommand{\sourceflush}{flushright}

% Setting the font and spacing for the epigraph
%\epigraph{\itshape \setstretch{1.2}But one thing is the thought, another thing is the deed, and another thing is the idea of the deed. The wheel of causality doth not roll between them.}{\small{Friedrich Nietzsche, \textit{Thus Spoke Zarathustra} (1883)}}
%
%

\section{From Conceptual Architecture to Empirical Test}

The preceding chapters established a theoretical claim with both philosophical depth and empirical ambition: \textit{that moral behaviour emerges from a topologically structured evaluative field, and that synthetic agents can perturb this field by altering the conditions under which moral salience becomes action}. The present chapter marks the transition from conceptual architecture to empirical adjudication. Here, every assumption must be operationalised, every construct measured, and every inference anchored in explicit experimental procedure.

This section begins with the precise research question that animates the experiment:
\bigskip
\noindent
\begin{center}
	\begin{questionbox}[label={q:robot-agent}]{Inferential Displacement} 
		Does the silent presence of a humanoid robot---perceptually social yet ontologically indeterminate---alter the evaluative process that transforms moral perception into prosocial behaviour? 
	\end{questionbox} 
\end{center}
\bigskip
\noindent
This question is not a rhetorical prompt but a methodological commitment. It situates the experiment within the evaluative--topological model developed earlier, in which moral action is expressed as:
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R),
\]
where $\alpha_E$ denotes morally salient environmental cues, $\beta_C$ the dispositional manifold quantified through psychometric tools, and $\gamma_R$ the perturbation operator instantiated by the robot’s presence. The purpose of the experiment is to determine whether $\gamma_R$ induces a measurable deformation in the mapping from $\alpha_E$ to observable moral action.

\subsection{Why the Question Matters}

Although behaviourally simple, the question reaches beyond classical experimental paradigms in moral psychology. It does not ask whether robots communicate norms, nor whether they persuade or instruct. It asks whether synthetic \textit{presence} alone---minimal, silent, behaviourally neutral---modifies the inferential pathway through which moral salience produces action. Within the broader research programme of social signal processing and moral AI, this constitutes a stringent and foundational test:

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{can an artificial agent operate as a perturbation operator on the moral field even in the absence of agency?}
	\end{leftbar}
\end{center}

Embedding a humanoid robot into a moral environment thus serves as a direct empirical probe of the thesis developed in earlier chapters: namely, that moral cognition is not solely a matter of internal reasoning or personality structure, but a dynamic, context-sensitive transformation governed by the topology of situational cues.

\subsection{Operationalising Moral Action: Prosocial Donation as Behavioural Endpoint}

To render this transformation empirically measurable, the experiment operationalises moral action through a cost-bearing behavioural choice: voluntary donation of a portion of the participant’s monetary compensation to a children’s medical charity. This measure, extensively validated in behavioural ethics and moral psychology, captures the endpoint of the evaluative trajectory: the point at which moral salience is either converted into action or allowed to dissipate.

Costly charitable donation has been repeatedly validated across moral psychology, behavioural economics, evolutionary anthropology, and developmental science as the most reliable behavioural proxy for prosocial moral action~\cite{Batson1991,FehrGachter2002,FehrFischbacher2003,WarnekenTomasello2006,Andreoni1990}. It satisfies the three criteria required at the Level of Abstraction adopted in this 
thesis: it is elicited by morally salient cues~\cite{Haley2005,Bateson2006,Pfattheicher2015}; it incurs real cost~\cite{Andreoni1990,Gintis2000}; and it expresses the 
action-guiding force of moral evaluation~\cite{Cushman2013,Greene2014,Decety2004}. 
Its long-standing use as the behavioural termination point of moral cognition~\cite{Batson1991,FehrGachter2002,WarnekenTomasello2006} justifies its role here as the measurable endpoint of the evaluative trajectory under synthetic perturbation.


The independent variable is equally minimal: the presence or absence of a humanoid robot autonomously animating in \textit{life-mode}: NAO does not speak, instruct, or engage. Its movements are restricted to micro-gestures---simulated breathing, subtle postural adjustments, and gaze-orienting behaviours triggered only by human eye contact. These micro-movements, while non-agentic, replicate the perceptual features known to activate the Watching-Eye effect, thereby introducing a controlled form of synthetic social salience into the evaluative environment.

\subsection{Why a Humanoid Robot?}

The choice of a humanoid robot reflects a deliberate methodological position. As established in Chapter~\ref{chap:moral_primer}, synthetic agents occupy an unstable location in our social ontology: they possess perceptual salience and humanoid morphology, yet lack the moral-evaluative capacities ordinarily ascribed to observers. This combination creates the precise form of perturbation the experiment seeks to test: a perceptibly social presence whose normative meaning is ambiguous.

The question is therefore not whether participants think the robot is judging them; rather, it is whether the robot’s presence alters the field of salience within which morally relevant cues exert their behavioural pull.


\bigskip
\noindent
\begin{center}
	\begin{questionbox}[label={q:robot-agent}]{Inferential Displacement}
		Can the mere presence of a synthetic observer---lacking agency, intention, and moral standing---perturb the inferential transformation that converts morally salient cues into prosocial action?
	\end{questionbox}
\end{center}
\bigskip
\noindent

\subsection{From Question to Design: Why We Do Not Begin with a Hypothesis}

Framing the study around a research question rather than a directional hypothesis is intentional. In interdisciplinary work spanning philosophy, psychology, neuroscience, and HRI, a premature hypothesis risks narrowing the interpretive field and smuggling in unexamined assumptions about how synthetic presence ought to behave. The methods must therefore preserve epistemic openness: \textit{the design must reveal whether perturbation occurs, not assume that it does}.

This methodological humility is continuous with the philosophical commitments articulated earlier. If moral behaviour arises from a dynamic integration of environmental cues, dispositional structure, and social presence, then the experiment must be sensitive to field-level deformations that cannot be anticipated a priori.

\subsection{The Logic of the Experimental Test}

In practical terms, the experiment leverages the integrated measurement framework developed in the previous chapter. The Watching-Eye paradigm constructs a baseline of elevated prosocial salience ($\alpha_E$). The EQ, SQ, and BFI quantify the structure of the dispositional manifold ($\beta_C$). The robot enacts the perturbation operator ($\gamma_R$). The donation task measures the resulting behavioural transformation $\mathscr{P}(\delta_m)$.

The empirical question is therefore precise:


\bigskip
\noindent
\begin{center}
	\begin{questionbox}[label={q:emp_que}]{Empirical Question}
		Does $\gamma_R$---the silent, perceptually social presence of a humanoid robot---systematically deform the evaluative mapping from $\alpha_E$ to $\mathscr{P}(\delta_m)$ across the dispositional manifold $\beta_C$?
	\end{questionbox}
\end{center}
\bigskip
\noindent

If the answer is affirmative, the findings reveal a foundational claim: that artificial agents, even when behaviourally minimal, exert moral influence not by persuasion or instruction but by reshaping the topological conditions under which moral salience becomes action.

What follows in this chapter details the machinery by which this question is tested: the design logic, the structure of the experimental task, the observational conditions, the psychometric integration, and the analytic strategies used to detect perturbation.

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{The conceptual framework provided the variables.  
			The empirical design now tests their transformation.}
	\end{leftbar}
\end{center}


\section{Experimental Design and Behavioural Paradigm}

To address Question~\ref{q:robot-agent} (p.~\pageref{q:robot-agent}), we implemented a controlled behavioural experiment~\cite{RosenthalRosnow2008,ReisJudd2000,Kazdin2017} grounded in the \textit{Watching–Eye} paradigm~\cite{HaleyFessler2005,Bateson2006,NettleEtAl2013,BatesonEtAl2013_EyesLittering,PfattheicherKeller2015,ContyGeorgeHietanen2016,DearDuttonFox2019}. The scientific objective was not simply to measure donation behaviour, but to determine whether $\gamma_R$, the silent perceptual presence of a humanoid robot, systematically deforms the evaluative mapping 
\[
\alpha_E \longmapsto \mathscr{P}(\delta_m)
\]
across the dispositional manifold $\beta_C$.

\noindent
Participants were recruited individually into a lab environment under the pretext of participating in a personality study in exchange for monetary compensation. This cover task served two methodological purposes. First, it provided a psychologically neutral framing for the room-based task. Second, it elicited trait-level measurements (EQ, SQ, BFI) necessary for modelling the dispositional manifold ($\beta_C$) within the evaluative–topological framework.

\medskip

\noindent
Embedded within this setting was a morally salient cue: a prominently placed charity poster depicting a child in medical need. Decades of evidence (see Chapter~\ref{chap:tools_new}) demonstrate that such stimuli reliably activate prosocial dispositions through implicit monitoring, empathic resonance, and affiliative concern~\cite{Haley2005,Conty2016}. Within the formalism introduced in earlier chapters, this stimulus increases $\alpha_E$, the environmental salience input, steepening the prosocial attractor in the evaluative field.

\subsection{Experimental Manipulation: Presence as the Only Ontological Difference}

\noindent
Participants were randomly assigned to one of two conditions.

\begin{enumerate}
	\item \textbf{Control Condition}: the participant completed the questionnaires alone in the room.
	\item \textbf{Robot Condition}: a humanoid NAO robot~\cite{Aldebaran2013} was present, operating in \textit{autonomous life mode}.
\end{enumerate}

\noindent
NAO emitted no speech and performed no task-directed actions. Its behaviour consisted solely of the minimal embodied micro-cues characteristic of this mode: simulated breathing, subtle shifts of posture, and head-orientation responses triggered only by direct eye contact. These are precisely the class of low-dimensional social cues shown to activate or modulate the Watching–Eye effect: movement, gaze potentiality, and the perceptual suggestion of observation.

\begin{figure}[H]
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{/home/francesco/Desktop/research/appunti/images/robot.png}
		\caption{Experimental condition: robot present.}
		\label{fig:robot}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=\linewidth]{/home/francesco/Desktop/research/appunti/images/control.png}
		\caption{Control condition: robot absent.}
		\label{fig:control}
	\end{subfigure}
	\caption{Top–down view of the experimental and control configurations.
		Both layouts are spatially and visually identical; the humanoid robot is the
		only ontological difference between conditions.  
		In the evaluative–topological framework developed in this thesis, this
		equivalence is essential: the geometry of the environment (desk positions,
		donation box placement, participant orientation) is held constant so that any
		change in prosocial behaviour can be attributed to a deformation of the
		evaluative field induced by synthetic presence.
		Formally, the figure depicts two instantiations of the same environmental input
		$\alpha_E$, differing only by the activation of the perturbation operator
		$\gamma_R$.  
		The robot’s placement maps onto a local modification of the salience
		landscape—an additional source of perceived observation—while the control
		condition represents the unperturbed topology.}
	\label{fig:experimental-topology}
\end{figure}


\noindent
Crucially, both experimental rooms were geometrically and visually identical (Fig.~\ref{fig:experimental-topology}). The \emph{only} manipulated variable was the presence or absence of the humanoid robot. Spatial layout, lighting, informational content, and the moral cue ($\alpha_E$) were held constant.

\medskip

\noindent
In this design, the robot does not “do” anything in a behavioural sense. Instead, its minimal perceptual affordances present the participant with an ontologically ambiguous entity—perceptually social, morally inert, and semantically potent. The manipulation therefore isolates \textit{presence as such} as the epistemic and experimental variable.

\subsection{Why Minimal Presence Matters: Ontological Ambiguity as Cognitive Perturbation}

\noindent
The overwhelming majority of HRI and HMI studies assume that moral modulation arises through interaction: overt communication, feedback, adaptive behaviour, or explicitly framed expectations~\cite{Malle2016,VanStraten2020,Arnold2017,Groom2010,Leidner2019}. The present design rejects this assumption deliberately.

\noindent
Rather than investigating how robots \emph{act}, we investigate how they \emph{appear}—how their mere existence within a perceptual field alters the evaluative pathway from moral salience to moral action. The experimental focus is therefore on \textbf{pre-reflective permeability}: the extent to which minimal agent-like cues reshape inferential structure prior to conscious deliberation~\cite{Husserl1913,Zahavi2005,Gallagher2005,Bargh1994}.

\noindent
This approach isolates a structural vulnerability of norm-sensitive cognition: humans routinely over-ascribe agency in contexts of uncertainty~\cite{Guthrie1993,Waytz2010,Dennett1987}. By placing NAO precisely at the boundary between objecthood and agenthood, the design probes whether anticipation—not interaction—is sufficient to distort the evaluative topology.

\subsection{Levels of Abstraction: Why the Robot Can Matter Without Doing Anything}

\noindent
Floridi’s Levels of Abstraction (LoA)~\cite{Floridi2008,Floridi2010,Floridi2013} provide the formal justification for treating NAO’s silent presence as epistemically potent.

\noindent
At the operative LoA of the participant, what is visible are \emph{informational affordances}: posture, eyes, symmetry, subtle biological motion, the inert promise of mutual gaze~\cite{Emery2000,Hietanen2002,CarneyCuddyYap2010,Argyle1975,Rhodes2006,Johansson1973,Saygin2012,ChaminadeOhnishi2007}. These cues are sufficient to trigger the primitives of social monitoring, even when the entity producing them is known to be non-human.

\noindent
Thus, at this LoA, NAO functions as a \emph{semantic perturbator}: not a moral agent, nor a communicative partner, but an informational presence that reshapes the participant’s evaluative background conditions. If the robot were interactive, the LoA would shift (introducing agency, reciprocity, intentional stance). If the robot were inert, the social affordance would vanish. Autonomous life mode occupies the narrow space between these extremes.

\noindent
This design choice aligns with Floridi and Sanders’ analysis of artefactual moral agency~\cite{FloridiSanders2004}. Their 2004 account does not attribute consciousness, intentionality, or moral reasoning to artificial systems. Rather, it identifies moral relevance at the \emph{Level of Abstraction} at
which an artefact can contribute causal or informational influence within a given environment~\cite{Floridi2008,Floridi2011}. At this LoA, an artefact may count as a “moral agent” in the minimal and operational sense that its presence supplies, modifies, or filters morally relevant information.

This perspective is directly compatible with contemporary discussions of large language models (LLMs), which similarly operate as \emph{artefactual sources of semantic perturbation} rather than as bearers of intrinsic moral status~\cite{Mittelstadt2019,Bender2021}. In both cases—the embodied robot tested here and the disembodied LLM—moral relevance arises not from interior capacities but from how the system reshapes the informational and social conditions under which human agents form evaluations and make decisions. Related arguments in HRI emphasise that robots exert moral and social
influence through their perceived agency, morphology, and communicative affordances, not through any intrinsic mental properties~\cite{Malle2016,Zlotowski2015,Banks2020}.

\noindent
For this reason, Floridi’s account is particularly well suited to the present experimental context: it licenses the treatment of NAO’s minimal, non-interactive presence as an epistemically potent variable without implying any claim about the robot’s inner ontology. At the LoA operative for the participant, the
robot is a \emph{semantic perturbator}: a structured informational presence capable of altering the evaluative field through which moral salience becomes behaviourally operative. This conceptual continuity also clarifies why the findings developed in this thesis generalise to other classes of artificial systems—including LLM-based agents—whose moral significance likewise depends
on the informational roles they play rather than on their metaphysical constitution~\cite{Coeckelbergh2010,Gunkel2012}.


\subsection{Behavioural Paradigm: Donation as Moral Action}

\noindent
After completing the questionnaires, each participant received £10 in £1 coins and encountered a voluntary donation option: a charity box positioned near the exit. They could donate any subset of their compensation. The amount donated served as the behavioural measure of prosocial action.

\noindent
This operationalisation follows a long-established tradition in moral psychology, moral economics, and behavioural ethics in which cost-bearing prosocial behaviour tracks the practical expression of moral salience~\cite{Batson2011,FehrGachter2002,Henrich2005,Tomasello2016,Warneken2015,Baumard2013,Crockett2016,Scanlon1998,Darwall2006}. As demonstrated in Chapter~\ref{chap:tools_new}, donation behaviour reliably expresses the terminal point of a moral evaluative trajectory.

\subsection{Preliminary Findings}

\noindent
Initial analyses revealed a robust and theoretically coherent effect: participants in the Robot condition donated \emph{significantly less} than those in the Control condition. Personality data (EQ, SQ, BFI) showed no meaningful differences between conditions, ruling out dispositional confounds and providing strong initial support for a field-level perturbation induced by synthetic presence.

\noindent
These results motivate the next step: formalising the evaluative structure through which this behavioural displacement must be interpreted.


\subsection{From Behavioural Setup to Evaluative Structure}

\noindent
The experimental setup provides the behavioural substrate. What remains is to
specify the evaluative architecture through which any behavioural modification
must be interpreted. In moral philosophy, action is often treated as the
terminus of deliberation~\cite{Aristotle_nicomachean,Anscombe1957,
	Korsgaard1996}. Yet the present study does not investigate deliberation itself.
It examines the \emph{transformation} that precedes deliberation’s endpoint:
the cognitive--affective process by which morally salient cues become
behaviourally operative~\cite{Nussbaum2001,Korsgaard2009}.  

\noindent
Donation, within this design, is therefore not an isolated act but the
\emph{observable boundary condition} of an evaluative process. The Watching--Eye
stimulus renders moral salience explicit; the robotic manipulation introduces a
synthetic perturbation; the donation behaviour provides the measurable output
of the transformation. This ensures that what is being tested is not
trait-level generosity, but the \textit{susceptibility of moral appraisal to
	synthetic co-presence}.

\medskip
\noindent
Classic variants of the Watching--Eye paradigm rely on pictorial cues or
supernatural primes~\cite{Bateson2006,Shariff2007}. The present experiment
instead embeds an embodied but minimally active humanoid robot. This shift is
critical: it replaces a two-dimensional prime with a three-dimensional presence
whose \emph{perceived ontology} is neither inert object nor full social agent.
This ambiguity is precisely the condition under which moral salience may be
refracted or displaced.

\medskip
\noindent
To formalise what the experiment tests, we treat moral action as the output of
an evaluative function integrating environmental cues, dispositional structure,
and perturbational affordances:

\[
\mathbb{E}[f(\Sigma \cup \mathscr{R})] \neq \mathbb{E}[f(\Sigma)],
\]

\noindent
where:
\begin{itemize}
	\item $\Sigma$ is the morality-salient perceptual field (the Watching--Eye cue),
	\item $\mathscr{R}$ is the synthetic co-presence,
	\item $f$ is the evaluative transformation linking perception to action,
	\item $\mathbb{E}[f(\cdot)]$ denotes the expected behavioural output.
\end{itemize}

\bigskip
\noindent
Read informally: \emph{the expected moral behaviour differs when the robot is
	added to the perceptual--moral environment}. This yields our first empirical
hypothesis:
\bigskip
\noindent
\begin{center}
	\nextstatement
	\begin{hypobox}{Evaluative Deformation Hypothesis}
		\label{hyp:evaluative_deformation}
		The expected outcome of moral behaviour, as computed through the evaluative
		process \( f \), is altered when the robot is present within the
		perceptual--moral environment.
	\end{hypobox}
\end{center}

\medskip
\noindent
To clarify the structure of this transformation, we decompose the probability
of a deviation in moral action into its constituent determinants:

\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R),
\]

\medskip
\noindent
where:
\begin{itemize}
	\item $\alpha_E$ represents the environmental moral cue (Watching--Eye),
	\item $\beta_C$ encodes the dispositional structure measured by EQ, SQ, and BFI,
	\item $\gamma_R$ denotes the perturbational effect of robotic co-presence.
\end{itemize}

\medskip
\noindent
In plain language: \emph{the probability of observing a change in moral
	behaviour depends jointly on the moral cue, the agent’s dispositional profile,
	and the presence of the robot}. This is the operative logic of the experimental
design: the robot is not treated as a moral agent, but as a \emph{topological
	perturbation}—a factor that reshapes the evaluative field within which moral
cues are processed.

\medskip
\noindent
Why should a robot be capable of such perturbation? The answer lies in the
notion of \textit{moral salience}. Across cognitive science and moral
philosophy, moral salience refers to the way certain features of the
environment become normatively charged prior to explicit reasoning~\cite{
	Korsgaard2009,Nussbaum2001,Greene2001,Moll2005}. It is a
pre-reflective gatekeeper: what is foregrounded, what stands out, and what
demands attention.

\noindent
A synthetic presence may influence this salience not by speaking or acting, but by altering the perceptual and inferential background against which moral cues are interpreted. NAO’s form, gaze orientation, and subtle embodied motions evoke the minimal conditions associated with social monitoring. They place the participant in a borderline space between being \textbf{alone} and being \textbf{observed}. This ontological ambiguity---central to human--robot interaction research---is precisely what makes NAO a semantically potent perturbation of the moral field.

\bigskip
\noindent
\begin{center}
	\nextstatement
	\begin{hypobox}{Synthetic Normativity of Moral Displacement}
		\label{hyp:synthetic_normativity}
		Synthetic presences, though devoid of sentience, may acquire \textit{normative
			affordances} by virtue of their perceived ontology. When situated within
		morality-salient environments, such presences may disrupt, refract, or displace
		the evaluative machinery through which moral judgments are ordinarily formed.
	\end{hypobox}
\end{center}
\bigskip
\noindent

This hypothesis extends the behavioural prediction into the normative domain: the robot may change not only what people \emph{do}, but the conditions under which moral meaning becomes actionable. The Watching--Eye paradigm thus becomes
a conceptual probe—a way of examining the \emph{structural elasticity} of norm-sensitive cognition in the presence of synthetic observers.

\noindent
Under this interpretation, generosity is not a simple expression of stable virtue or personality; it is the \textit{emergent property} of a cognitive--affective system embedded in a structured moral environment. Robotic presence, by virtue of its ontological ambiguity, acts as a refractive affordance: it bends the
path from moral perception to moral action, attenuating the behavioural expression of prosocial salience.

\medskip
\noindent
This notion of an \textit{emergent property} deserves clarification, for it plays an important explanatory role in how the experiment should be interpreted. In the present context, emergence does not denote mysterious or irreducible behaviour; it describes a structural fact about norm-sensitive cognition \cite{Greene2001,Haidt2001,Cushman2013}. Prosocial donation arises here not from any single component of the experimental system---neither from the moral cue alone ($\alpha_E$), nor from the dispositional architecture ($\beta_C$), nor from the robot’s presence ($\gamma_R$) taken in isolation. Rather, generosity appears as the \textit{behavioural output of an interaction} \cite{Decety2004,Conty2016}:
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R).
\]
Under fixed dispositions, the output can change simply because the evaluative field in which those dispositions operate has been deformed \cite{Pentland2007,Vinciarelli2009}. This is precisely what the data reveal: the robot produces a \emph{uniform directional shift} in donation behaviour despite stable trait profiles \cite{Bremner2022,Kuchenbrandt2011,Malle2016}. In this sense, prosocial behaviour is emergent: it is a property of the \emph{system} formed by dispositions, environmental cues, and contextual topology, not a direct expression of any one part \cite{FehrFischbacher2003,WarnekenTomasello2006}.

\medskip
\noindent
A helpful comparison can be drawn---carefully---with contemporary discussions of emergent capacities in large language models. In LLMs, emergence refers to capabilities that arise from the interaction of many parameters without being explicitly encoded \cite{Mittelstadt2019,Bender2021}. Here, too, the behavioural effect reflects an interactional architecture: moral action is generated by the coupling of perceptual salience, affective readiness, and contextual priors \cite{Greene2014,Crockett2016}. Yet, unlike in LLMs, the emergence observed here is phenomenological and contextually scaffolded: the evaluative field itself is altered, and behaviour shifts even though the underlying dispositions remain constant \cite{Zlotowski2015,Banks2020}.

\medskip
\noindent
This also clarifies the function of the mathematical formalism introduced in the preceding chapters. The equations do not quantify moral agency in any metaphysical sense; they provide an explicit epistemic schema for locating the point of deformation \cite{Konovalov2016,Shenhav2017}. By decomposing the evaluative transformation into $\alpha_E$, $\beta_C$, and $\gamma_R$, the formalism makes it possible to rule out trait-level explanations and demonstrate that the behavioural shift originates at the level of the mapping:
\[
f(\alpha_E, \beta_C, \gamma_R) \neq f(\alpha_E, \beta_C).
\]
In this respect, the mathematics functions as a conceptual microscope: it enables the isolation of the structural point at which synthetic presence exerts influence. Without such decomposition, the uniform attenuation might be mistakenly attributed to personality differences, random noise, or implicit experimental demand \cite{Dear2019,Pfattheicher2015}.

\medskip
\noindent
Thus, when the analysis later reports that moral behaviour changed while traits did not, the claim is not that generosity ``collapsed'', nor that personality ``failed'' to predict behaviour. The claim is that the \textit{evaluative topology} was reconfigured by an ontologically ambiguous presence---yielding an emergent behavioural pattern that no component of the system could produce alone \cite{Haley2005,Bateson2006}. This, in turn, is what lends the experiment its broader philosophical significance: it demonstrates that synthetic agents can perturb the moral field not by thinking, or by acting, but simply by \textit{being present} within the perceptual architecture through which moral salience becomes action \cite{Zlotowski2015,Malle2016,Bremner2022}.


\medskip
\noindent
With this evaluative architecture established, the next section examines how this deformation manifests empirically—first in behavioural data, and then in its interaction (or lack thereof) with dispositional structure. The question (\ref{q:emp_que}), as framed at the outset, demanded a yes/no answer. The analysis to follow now
supplies the evidential basis for that answer.

%%% HERE THE PROBLEM STARTED %%%
%%% NEW CONTENT WAS ADDED %%%
%%% MUCH OF THE STATISTICS IS LOST BUT WE GAIN CLARITY %%%
%%% OLD CONTENT CAN BE RESUMED FROM TXT IN DESKTOP %%%

\section{Synthetic Perturbation of Moral Inference}

\noindent
Before entering the empirical phase, we require a precise \emph{mechanistic anchor}:\footnote{In this context, ``mechanistic’’ refers not to physical causation but to the minimally specified, testable account of \emph{where} in the evaluative process a perturbation is expected to act. It identifies the locus of influence within the mapping from moral salience to behavioural output.} a statement that links the evaluative–topological model developed in the preceding chapters to the behavioural analyses that follow. Without such an anchor, the experiment would risk degenerating into a mere behavioural vignette, detached from the normative and computational structure established earlier. The present section therefore identifies the precise inferential target against which all subsequent statistical results must be interpreted.

\medskip
\noindent
Chapters~\ref{chap:moral_primer}--\ref{chap:tools_new} articulated the evaluative 
architecture through which moral salience (\(\alpha_E\)) is transformed into behavioural output (\(\mathscr{P}(\delta_m)\)), modulated by dispositional structure (\(\beta_C\)) and,potentially, by synthetic perturbation (\(\gamma_R\)). The central empirical question (Question~\ref{q:robot-agent}) asked whether the mere presence of a humanoid robot systematically deforms the mapping from salience to action. The role of the present hypothesis is to turn that question into a testable inferential claim: it specifies \emph{how} and \emph{where} the perturbation is expected to manifest within the evaluative transformation.

\medskip
\noindent
In the experimental setting, the Watching–Eye stimulus structures the moral field 
\(\Sigma\); the dispositional manifold \(\beta_C\), measured through EQ, SQ, and the BFI, provides each participant’s cognitive–affective baseline; and the robot’s presence \(\mathscr{R}\) introduces a perceptually social, ontologically ambiguous affordance. The crucial question is whether \(\mathscr{R}\) modulates the internal transformation that links perceptual–affective inputs to prosocial action.

\[
\Sigma \longrightarrow \mathscr{D}
\]

\noindent
Under ordinary conditions, this transition is driven by the salience of the moral cue.
When the robot is present, however, its ambiguous social ontology may refract or suppress
the affective and reputational components that ordinarily support prosocial decision-making.
This motivates the mechanistic hypothesis.

\begin{center}
	\nextstatement
	\begin{hypobox}{Synthetic Perturbation of Moral Inference}
		\label{hyp:synthetic_perturbation}
		The humanoid robot NAO does not function as a passive observer, but as a 
		perturbative presence that refracts the transition from moral salience to 
		prosocial action. Its ontological ambiguity displaces the affective and 
		reputational cues that ordinarily support donation, thereby modulating the 
		evaluative pathway by which moral stimuli gain behavioural expression.
	\end{hypobox}
\end{center}

\noindent
This hypothesis identifies the mechanistic level at which synthetic presence is expected 
to operate. The claim is not that NAO exerts coercive influence or that participants 
attribute moral authority to it. Rather, the prediction is that NAO’s perceptually 
social yet ontologically indeterminate presence alters the \emph{topology} of the 
evaluative field: shifting which features are foregrounded, how moral cues are weighted, 
and how affective resonance is integrated into action. In this sense, the robot 
functions as a \emph{semantic perturbation}---a presence that reconfigures the 
informational structure through which salience becomes behaviour.

\medskip
\noindent
With this mechanistic hypothesis established, we can now transition to the empirical 
analysis. The next section evaluates whether the two experimental groups were equivalent 
in their demographic and dispositional structure, ensuring that any subsequent 
behavioural divergence can be attributed to the perturbative role of \(\mathscr{R}\) 
rather than to background variation within \(\beta_C\). The behavioural results 
that follow then provide the evidential basis for adjudicating whether the deformation 
predicted here is indeed observed.





\section{Inferential Analysis of Experimental Data}
\label{sec:inferential_analysis}

\noindent
Before we enter the empirical phase of the argument, it is crucial to clarify
what this section contributes to the architecture of the thesis. Up to this
point, the chapter has operated at the level of \emph{evaluative structure}:
we have identified the components of the perceptual--moral field, specified the
variables of the evaluative transformation 
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R),
\]
and articulated the mechanistic hypothesis governing how synthetic presence
($\gamma_R$) may refract the mapping from moral salience ($\alpha_E$) to
behavioural output ($\mathscr{P}(\delta_m)$).

\medskip

\noindent
What follows changes register.  
This section inaugurates the \emph{inferential} phase of the thesis: the point
at which conceptual commitments must submit to statistical adjudication.  
If the preceding sections drew the topology of the evaluative field, the
analyses to follow measure its curvature.

\medskip

\noindent
Two principles govern the transition.

\begin{enumerate}
	\item \textbf{Inferential validity requires structural symmetry.}  
	Before testing whether the perturbation $\gamma_R$ deformed the evaluative
	mapping, we must first establish that the two experimental groups were
	equivalent with respect to demographic and dispositional structure.  
	Without this symmetry, any behavioural divergence would be uninterpretable
	at the level of mechanism.
	
	\item \textbf{Statistical analysis is not a post-hoc addition, but the
		operational expression of the theoretical model.}  
	The inferential pipeline---from distributional checks to regression
	modelling and cluster analysis---implements the evaluative framework
	developed in earlier chapters. Each statistical test corresponds to a
	theoretical question: Does $\gamma_R$ shift the distribution of prosocial
	action? Does $\beta_C$ moderate that shift? Is the effect uniform across
	the dispositional manifold?
\end{enumerate}

\medskip

\noindent
The present section therefore serves a dual purpose.  
First, it validates the experimental precondition of group comparability.  
Second, it establishes the methodological pathway through which the mechanistic
hypothesis introduced above will be empirically evaluated.

\bigskip
\noindent
\begin{center}
	\begin{leftbar}
		\textit{From this point onward, every claim is grounded not in conceptual
			plausibility, but in statistical evidence.}
	\end{leftbar}
\end{center}

\bigskip
\noindent
We begin by demonstrating the demographic and dispositional equivalence of the
two participant groups. Only once this foundational condition is met can we
proceed to analyse whether synthetic presence introduced a systematic
deformation in the evaluative mapping from moral salience to observable moral
action.

\subsection{Demographic Equivalence as a Symmetry Condition}
\label{subsec:dem_equivalence}

Before any inferential claims can be drawn from the behavioural data, we must
establish that the two experimental groups were demographically comparable.  
Within the evaluative–topological framework developed earlier, demographic
symmetry functions as a foundational \emph{inferential constraint}: only when
the underlying populations exhibit similar baseline characteristics can any
observed behavioural divergence be attributed—within the limits of the design—to
the perturbative presence of the robot $\mathscr{R}$ rather than to sampling
asymmetries in the human substrate.

\medskip
\noindent
To this end, we examined three demographic variables that plausibly influence
prosocial responsiveness in field and laboratory studies: gender, age, and
educational background. Each was tested across the \textbf{Control} and
\textbf{Robot} conditions using standard inferential procedures, with
Benjamini--Hochberg False Discovery Rate (FDR) correction applied to guard
against spurious equivalence due to multiple comparisons.

\begin{itemize}
	\item \textbf{Gender distribution}: a chi-squared test revealed no
	significant difference between conditions ($p = 1.00$, FDR-corrected).
	
	\item \textbf{Age}: an independent-samples \emph{t}-test detected no
	difference in mean age between groups ($p = 1.00$, FDR-corrected).
	
	\item \textbf{Educational background}: a chi-squared test again showed no
	reliable difference ($p = 1.00$, FDR-corrected).
\end{itemize}

\noindent
The convergence of these results under strict FDR control allows us to draw the
following methodological conclusion:

\begin{quote}
	\textbf{The two experimental groups are demographically equivalent.}
\end{quote}

\noindent
This symmetry condition is essential for the analyses that follow. It ensures
that the behavioural differences later observed cannot be attributed to
demographic imbalance or hidden stratifications in the participant pool.
Instead, under the architecture developed in the preceding sections, any
systematic divergence in prosocial behaviour becomes attributable to the
semiotic and perceptual perturbation introduced by the robot, $\mathscr{R}$,
after holding $\alpha_E$ constant and before considering variation in the
dispositional manifold $\beta_C$.

\begin{table}[H]
	\centering
	\includegraphics[width=\textwidth]{tables/demographic_balance_table.pdf}
	\caption{Demographic balance tests across experimental conditions.  
		Values shown include original and FDR-corrected $p$-values for gender, age,
		and educational background. No comparison reached significance after
		correction, supporting the assumption of demographic equivalence required
		for subsequent inferential interpretation of behavioural effects.}
	\label{tab:dem_balance}
\end{table}

\medskip
\noindent
With demographic symmetry established, the analysis proceeds to the next
inferential layer: the behavioural effects of synthetic presence. Subsequent
sections will assess donation outcomes directly, and only \emph{thereafter}
will the dispositional structure—encoded via EQ, SQ, and BFI—be examined for
potential interactions with $\mathscr{R}$. This ordering preserves the logic of
the evaluative–topological framework: baseline equivalence first, behavioural
effects second, dispositional modulation third.

% ============================================================
\subsection{Data Preparation and Preprocessing Workflow}
\label{subsec:data_preprocessing}
% ============================================================

Because the inferential analyses that follow rely on contrasts across
experimental conditions, dispositional variables, and behavioural outputs, a
principled preprocessing pipeline is an epistemic prerequisite rather than a
technical convenience. The aim of this stage is to ensure that the dataset
constitutes a coherent and interpretable representation of the experimental
structure, free from syntactic artefacts, coding inconsistencies, or latent
category imbalances. Only under such conditions can the subsequent statistical
models be taken to track the evaluative transformations at issue in this
chapter.

The dataset comprises demographic descriptors, psychometric measures (EQ, SQ,
BFI), and the behavioural outcome (donation magnitude). These variables differ
in type, scale, and inferential role; they therefore require tailored
preprocessing steps to preserve their semantic integrity.

\paragraph{Standardisation of variable names.}
All variable names were converted to lowercase, whitespace-trimmed, and
harmonised to eliminate discrepancies introduced through manual data entry.
This ensures referential consistency throughout the analysis.

\paragraph{Encoding of behavioural outcome.}
The binary variable \texttt{donated\_anything} was created ($1=$ donated at
least one coin; $0=$ donated nothing). This permits modelling of prosocial
behaviour at two complementary levels: (i) the full distribution of donation
amounts and (ii) the threshold decision to donate at all.

\paragraph{Encoding of experimental condition.}
The variable \texttt{condition\_bin} was constructed ($0=\text{Control}$,
$1=\text{Robot}$) to allow direct incorporation into regression frameworks and
to maintain a clear contrast between conditions.

\paragraph{Verification of categorical coherence.}
Categorical fields (e.g., \texttt{gender}) were inspected for irregularities
such as collapsed, duplicated, or misspelled levels. No anomalies requiring
recoding were identified.

\paragraph{Preliminary distributional checks.}
Initial visual inspections (histograms, density plots, boxplots) revealed no
anomalous values requiring removal or recoding. Age distributions and donation
distributions are shown in Figures~\ref{fig:age_distribution_by_group}
and~\ref{fig:donation_distribution_by_condition}, respectively, illustrating the
distributional structures to be analysed in the inferential sections that
follow.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{new_plots/age_distribution_by_group.png}
	\caption{Age distribution across experimental conditions. The histograms
		illustrate the demographic structure of the sample to be examined in later
		analyses.}
	\label{fig:age_distribution_by_group}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{new_plots/donation_distribution_by_condition.png}
	\caption{Distribution of donation behaviour by condition. The plot presents
		the behavioural data whose inferential assessment constitutes the next stage
		of analysis.}
	\label{fig:donation_distribution_by_condition}
\end{figure}

\medskip
\noindent
Taken together, these preprocessing steps establish the analytic coherence
required for valid inferential modelling. With demographic equivalence confirmed
in the previous subsection and the present transformations ensuring structural
stability of the data, the chapter now proceeds to the statistical models that
evaluate whether the perturbation introduced by $\mathscr{R}$ manifests in the
transition from moral salience to moral action.

%%% START FROM THIS SECTION BELOW %%%

\subsection{Preliminary Descriptive Patterns: Indications of Inferential Displacement}

\noindent
The initial descriptive statistics presented in Table 6.4 below offers a first empirical glimpse into the behavioural topology of the experiment. Consistent with the theoretical expectation that robotic presence $\mathscr{R}$ functions as an interpretive refractor rather than a neutral co-presence, the mean donation in the \textit{Control} condition (£1.89) exceeds that of the \textit{Robot} condition (£1.17). 

Although superficially modest, this divergence is conceptually aligned with the proposed displacement mechanism: if $\mathscr{R}$ attenuates the inferential weight of morally salient cues, then the perceptual–affective force of the charity stimulus ($\alpha_E$) should translate into reduced behavioural output. What the descriptive statistics therefore index is not merely a numerical contrast, but a preliminary deformation in the evaluative mapping from moral cue to prosocial act.

\noindent
Beyond donation behaviour, several secondary variables exhibit patterned differences: the Control group reports slightly higher Empathizing Quotient scores (M = 45.94 vs.\ 42.82) and higher Openness to Experience (M = 1.86 vs.\ 1.32). The Robot group, by contrast, is marginally older on average and shows increased Systemizing Quotient scores. While none of these contrasts are yet statistically decisive, they signal structured heterogeneity in cognitive–affective profiles that may later serve as moderators in the inferential analysis.

These preliminary divergences should be read cautiously. At this stage, they are \textit{exploratory markers} rather than inferential claims. Their value lies not in establishing differences, but in helping to delineate the psychological architecture through which robotic presence may exert its perturbative influence.

\begin{table}[H]
	\label{tab:descriptive-stats}
	\centering
	\includegraphics[width=\textwidth]{tables/descriptive_highlights_table.pdf}
	\caption{Summary of central tendencies for key behavioural and psychometric variables. The Robot condition shows numerically lower donation amounts and empathizing scores, suggesting potential attenuation effects of passive robotic presence.}
\end{table}

% FROM HERE
%%% =======================
%%%  NEW CONTENT N4 — REVISED
%%% =======================

\subsection{Inferential Assessment of Attenuation: Behavioural Evidence for Perturbation}
\label{subsec:inferential_attentuation}

\noindent
Having established the structural integrity of the dataset and the epistemic symmetry of the experimental groups, we now turn to the first inferential evaluation of whether the presence of the humanoid robot $\mathscr{R}$ modulates prosocial donation behaviour. This analysis directly bears on the \textit{Evaluative Deformation Hypothesis} introduced earlier (see Hypothesis~\ref{hyp:evaluative_deformation}), which predicts that the expected behavioural output $\mathbb{E}[f(\Sigma \cup \mathscr{R})]$ will diverge from $\mathbb{E}[f(\Sigma)]$ under otherwise identical environmental conditions.

\noindent
A chi-squared test on aggregated donation totals revealed a statistically significant difference across conditions ($\chi^2 = 4.25$, $p = .039$). Although modest in magnitude, this result provides preliminary support for the claim that robotic presence exerts a measurable perturbative influence at the level of group-level moral output.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,title=Conclusion: Aggregate Attenuation of Prosocial Output]
		At the aggregate level, participants exposed to the humanoid robot donated less overall than those in the Control condition, indicating a measurable attenuation in prosocial behavioural output under synthetic co-presence.
	\end{tcolorbox}
\end{center}

\noindent
It is important to emphasise the conceptual modesty of this conclusion. The inference concerns \emph{behavioural outcomes}, not motivational states: it does not license any direct claim about reduced empathy, diminished altruism, or altered moral character. A richer ethical interpretation of the donation act will be developed subsequently in the dedicated chapter on charitable giving and moral agency.

\noindent
To complement the chi-squared test, a Mann–Whitney U test was applied to the full distribution of donation amounts. This test did not reach statistical significance ($U = 777$, $p = .194$), indicating that although the group means diverge, the individual-level distributions remain substantially overlapping. This distributional overlap suggests that the perturbative influence of $\mathscr{R}$ is not uniformly expressed across participants, but may depend on latent cognitive–affective structures captured in the trait vector $\beta_C$.

\noindent
A nonparametric bootstrap estimate of the mean donation difference ($\Delta M = £0.71$) reinforced the directional pattern, yet its 95\% confidence interval included zero (CI = [–£0.33, £1.79]). This epistemic indeterminacy is itself theoretically consistent with the overarching framework: the robot functions not as a deterministic suppressor of moral behaviour, but as a \textbf{subtle modulator of the normative field}, whose influence becomes most visible at the level of aggregated tendencies rather than individual-level deterministic shifts.

\noindent
Taken together, these results support the philosophical characterisation of $\mathscr{R}$ as a \textit{semiotic perturbator}—an entity whose ontological ambiguity refracts the inferential trajectory from moral salience to behavioural output. The attenuation observed at the aggregate level, coupled with the distributional overlap at the individual level, points toward a heterogeneous responsiveness within the participant population, motivating the more refined modelling strategies introduced in the sections to follow. \textit{In particular, the potential interaction between robotic presence $\gamma_R$ and individual traits $\beta_C$ warrants further investigation through regression modelling, interaction analyses, and Bayesian estimation procedures.}

\begin{table}[H]
	\centering
	\includegraphics[width=\textwidth]{tables/statistical_tests_table.pdf}
	\caption{Inferential comparisons of donation behaviour across conditions. The chi-squared test identifies a significant difference in aggregate donation totals, while the Mann–Whitney U test and bootstrapped mean difference indicate substantial distributional overlap and a diffuse, heterogeneous perturbative effect.}
	\label{tab:statistical_tests}
\end{table}

\vspace{0.3cm}
\noindent
Inferential statistical testing corroborates the initial descriptive trends, albeit with nuanced gradations in evidential strength. As shown above, a chi-squared test applied to the aggregate donation sums across experimental conditions yielded a statistically significant divergence ($\chi^2 = 4.25$, $p = .039$), in line with the Evaluative Deformation Hypothesis that the presence of a synthetic co-presence $\mathscr{R}$ deforms the expected behavioural output of the evaluative function $f$. 

However, this aggregate significance attenuates when the full distributions of donation amounts are examined. A Mann–Whitney U test did not detect a reliable shift in the overall donation distributions ($U = 777$, $p = .194$), indicating substantial overlap in individual-level variability across the Control and Robot conditions. A bootstrapped estimation of the mean difference in donation ($\Delta M = £0.71$) reinforced the directional pattern, but the 95\% confidence interval (CI = [–£0.33, £1.79]) encompassed the null, \textit{thereby underscoring the epistemic fragility and structural subtlety of the observed effect.}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{new_plots/donation_effect_by_condition.png}
	\caption{Mean donation amounts by experimental condition, with 95\% bootstrapped confidence intervals. Participants in the Control condition donated more on average than those in the Robot condition, aligning with the hypothesis that robotic presence attenuates the inferential mapping from moral salience to prosocial action. The overlapping confidence intervals highlight substantial individual-level variability and the probabilistic nature of the perturbation.}
	\label{fig:donation_effect_by_condition}
\end{figure}
\noindent

\noindent
Beyond establishing that a statistically detectable attenuation emerges at the level of group aggregates, it is epistemically important to quantify the magnitude of this perturbation. The effect is not only small in absolute monetary terms, but also structurally modest in inferential terms: it does not collapse the transformation from moral salience to action, but appears to bend it. The following analyses therefore introduce both parametric and nonparametric effect size metrics, in order to characterise how strongly the robotic co-presence $\gamma_R$ modulates the evaluative function $f(\alpha_E, \beta_C, \gamma_R)$ and how this modulation scales across heterogeneous configurations of the trait vector $\beta_C$.

% ---------------------------------------------------------------------
\subsection{Interim Evaluation of the Hypotheses and Formal Framework}

\noindent
At this stage, the behavioural and inferential results allow for a provisional assessment of the hypotheses and the formal apparatus introduced earlier. These are not isolated claims, but components of a single explanatory architecture that tracks how moral salience is transformed into observable behaviour under synthetic co-presence.

\noindent
The \textbf{Evaluative Deformation Hypothesis} (Hypothesis~\ref{hyp:evaluative_deformation} p.~\pageref{hyp:evaluative_deformation}) asserts that the expected outcome of moral behaviour, as computed by the evaluative transformation $f$, is altered when the robot is present within the perceptual–moral environment. The chi-squared analysis of aggregate donation totals, together with the bootstrapped mean difference, supports this claim: the pattern
\[
\mathbb{E}[f(\Sigma \cup \mathscr{R})] < \mathbb{E}[f(\Sigma)]
\]
is empirically instantiated, albeit modestly and with heterogeneous individual-level expression. This hypothesis is therefore \textbf{retained} as an operative empirical statement about the deformation of group-level moral output under robotic co-presence.

\medskip
\noindent
The \textbf{Synthetic Normativity of Moral Displacement} hypothesis (Hypothesis~\ref{hyp:synthetic_normativity}, p.~\pageref{hyp:synthetic_normativity}) provides the ontological and conceptual groundwork for interpreting this deformation. It claims that synthetic presences, though devoid of sentience, may acquire normative affordances by virtue of their perceived ontology. The present evidence neither confirms nor disconfirms this hypothesis in a narrow statistical sense; rather, it shows that a non-interactive yet semantically rich artefact, \textbf{positioned at the appropriate Level of Abstraction}, can exert measurable influence on prosocial behaviour without issuing commands, arguments, or reasons. This is exactly the pattern one would expect if normative affordances were grounded in informational presentation at a given LoA, rather than in intrinsic moral status. The hypothesis is thus \textbf{retained} as the principal conceptual lens through which the behavioural results are interpreted.

\noindent
The \textbf{Synthetic Perturbation of Moral Inference} hypothesis (Hypothesis~\ref{hyp:synthetic_perturbation},  p.~\pageref{hyp:synthetic_perturbation}) specifies the mechanism connecting the previous two: the robot does not merely co-occur with lowered donations; it perturbs the inferential transition from moral salience to prosocial action by refracting the affective–empathic cues that would otherwise support donation behaviour. The combined pattern of (i) significant aggregate attenuation, (ii) overlapping individual-level distributions, and (iii) non-trivial yet fragile effect sizes is coherent with this mechanistic reading: the evaluative mapping is not destroyed, but \textbf{its topology is altered}. This hypothesis is therefore \textbf{retained} as a working account of how the deformation is instantiated at the level of moral inference.
\noindent
In sum, all three hypotheses remain live and mutually reinforcing:

\begin{itemize}
	\item Hypothesis~\ref{hyp:evaluative_deformation}, (p.~\pageref{hyp:evaluative_deformation}) identifies the \emph{empirical signature} of deformation at the level of expected behaviour.
	\item Hypothesis~\ref{hyp:synthetic_normativity}, (p.~\pageref{hyp:synthetic_normativity}) explains the \emph{ontological possibility} of such deformation within Floridi’s informationalist framework and its Levels of Abstraction.
	\item Hypothesis~\ref{hyp:synthetic_perturbation}, (p.~\pageref{hyp:synthetic_perturbation}) articulates the \emph{inferential pathway} through which robotic presence reshapes the transition from moral salience to action.
\end{itemize}

No hypothesis introduced thus far is contradicted by the current evidence; rather, the data suggest that the deformation is subtle, probabilistic, and mediated—exactly the kind of effect one would expect when perturbation occurs at the level of semantic encoding rather than at the level of explicit instruction or coercion.

% ---------------------------------------------------------------------
\subsubsection{Status of the Mathematical Formalism}

\noindent
The mathematical formalism developed earlier has not remained abstract scaffolding; it has directly structured both the analysis and the interpretation of the behavioural findings.

\paragraph{(a) The evaluative transformation function \(f(\cdot)\).}
This function encodes the cognitive–affective transformation through which perceptual–moral cues are converted into behavioural output.  
\textbf{Contribution so far:} it clarifies why a non-interactive, minimal-behaviour robot can nonetheless influence donation behaviour: what is being perturbed is not the presence of reasons or arguments, but the transformation process itself.

\paragraph{(b) Expected behavioural distributions \(\mathbb{E}[f(\Sigma)]\) vs.\ \(\mathbb{E}[f(\Sigma \cup \mathscr{R})]\).}
These expectations formalise the contrast between Control and Robot conditions.  
\textbf{Contribution so far:} they provide a principled representation of the observed attenuation pattern, making it possible to express the empirical result as an inequality over expected moral output, rather than as an ad hoc numerical difference.

\paragraph{(c) The tripartite decomposition}
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R).
\]
This expression disaggregates environmental cues (\(\alpha_E\)), dispositional factors (\(\beta_C\)), and robotic presence (\(\gamma_R\)).  
\textbf{Contribution so far:} it justifies the joint consideration of (i) the Watching Eye stimulus, (ii) psychometric traits and demographics, and (iii) robotic co-presence as distinct yet interacting contributors to moral behaviour. The current behavioural results speak primarily to the \(\gamma_R\) component, while leaving open the possibility that its effect is modulated by structured configurations of \(\beta_C\)—a possibility that will be examined through regression and interaction models in the analyses that follow.

Together, these formal elements ensure that the experiment is not interpreted as a mere collection of empirical regularities, but as a controlled perturbation of a well-specified evaluative system situated at a particular Level of Abstraction.

% ---------------------------------------------------------------------
\subsection{Interim Conclusion to Question~\ref{q:robot-agent}}

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,title=Partial Conclusion to Question~\ref{q:robot-agent}]
		The behavioural evidence obtained thus far indicates that the silent co-presence of a humanoid robot, operating with minimal but perceptually salient behavioural affordances, systematically attenuates aggregate donation behaviour under a Watching Eye paradigm. This attenuation is modest, probabilistic, and heterogeneously distributed across individuals, but it is empirically detectable and statistically non-trivial.
		
		\medskip
		Within the formal and philosophical architecture developed in this chapter, these findings support the plausibility of \emph{evaluative deformation}: the robot perturbs the inferential transformation from morally salient cues to observable moral action. Floridi’s Levels of Abstraction framework explains why such perturbation is possible—because the robot’s \emph{perceived ontology} and informational encoding render it normatively relevant at the operative LoA, even in the absence of sentience or interaction. The Synthetic Perturbation of Moral Inference hypothesis then specifies \emph{how} this relevance is instantiated, by refracting the evaluative pathway rather than overriding it.
		
		
		\medskip
		The role of individual traits, represented by the vector \(\beta_C\), and their interaction with robotic presence \(\gamma_R\), remains an open and theoretically salient question. The next sections therefore move from aggregate contrasts to trait–context modelling, in order to determine whether moral displacement is uniformly distributed or preferentially expressed in specific psychological profiles.
	\end{tcolorbox}
\end{center}

\noindent
In summary, the results to this point justify the claim that robotic co-presence modifies the evaluative conditions under which morally salient cues become behaviourally actionable, in a manner that is fully consistent with the informational and topological commitments of the Floridian framework. The retained hypotheses and formalism together provide the conceptual, ontological, and mechanistic scaffolding for the more fine-grained analyses that follow.

%%% NEW CONTENT N7
Beyond establishing the statistical significance of the observed differences, it is epistemically imperative to quantify the magnitude of behavioral perturbation induced by robotic presence. The following analyses introduce both parametric and nonparametric effect size metrics to characterise the structural modulation of moral decision-making.

\subsection{Quantification of Behavioural Modulation: Parametric and Nonparametric Effect Sizes}

\noindent
To complement the inferential analyses reported above, the magnitude of the behavioural modulation induced by robotic co-presence was quantified using both parametric and nonparametric effect size metrics. Whereas significance tests assess whether an effect is detectable relative to sampling variability, effect sizes characterise the \textit{structural amplitude} of the perturbation introduced by $\mathscr{R}$. In keeping with the dual statistical and philosophical commitments of this chapter, we employ metrics that capture both standardised differences in central tendency and ordinal differences in the full behavioural distribution.

\noindent
Two complementary measures were selected:

\begin{itemize}
	\item \textbf{Cohen’s $d$} — a parametric index of standardised mean difference;
	\item \textbf{Cliff’s $\Delta$} — a nonparametric ordinal effect size quantifying the probability that a randomly selected individual in one group donates more or less than a randomly selected individual in the other.
\end{itemize}

These metrics jointly assess whether robotic presence reshapes the evaluative output distribution in a manner consistent with the deformation posited in the preceding hypotheses.

\vspace{0.3cm}
\noindent\textbf{Cohen’s \( d \):}
\[
d = \frac{\bar{x}_1 - \bar{x}_2}{s_p}
\quad\text{where}\quad
s_p = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}
\]

\noindent
Where:
\begin{itemize}
	\item $\bar{x}_1, \bar{x}_2$ = group means (Control, Robot),
	\item $s_1, s_2$ = group standard deviations,
	\item $n_1, n_2$ = group sizes.
\end{itemize}

\medskip
\noindent\textbf{Cliff’s Delta \( \Delta \):}
\[
\Delta = 
\frac{\#(x>y) - \#(x<y)}{n_x n_y}
\]
Where:
\begin{itemize}
	\item $\#(x>y)$ counts all pairwise comparisons where a Control donation exceeds a Robot donation,
	\item $\#(x<y)$ counts the inverse.
\end{itemize}

\vspace{0.3cm}
\noindent
The empirical results yield:
\[
d \approx 0.30, \qquad \Delta \approx 0.20.
\]

\noindent
Both indices fall within the range typically interpreted as \textit{small to modest} behavioural modulation. Yet as argued earlier, the theoretical significance of these values does not lie in their magnitude alone, but in the fact that they instantiate a reproducible \textit{directional deformation} of the evaluative transformation $f(\cdot)$ under controlled manipulation of $\mathscr{R}$.

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{new_plots/donation_density_by_condition.png}
	\caption{Kernel density estimates of donation distributions across conditions. The Control group exhibits higher central mass and a heavier rightward extension relative to the Robot group, consistent with a directional attenuation of high-value prosocial acts in the presence of the synthetic co-presence $\mathscr{R}$.}
	\label{fig:donation_density}
\end{figure}

\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.8\textwidth]{new_plots/donation_mean_with_se.png}
	\caption{Mean donation amounts with standard error bars by condition. The Control group donates more on average (£1.89) than the Robot group (£1.17), corroborating the hypothesis that robotic presence modulates—rather than eliminates—the evaluative pathway from moral salience to action.}
	\label{fig:mean_donation}
\end{figure}

\noindent
Taken together, these effect sizes indicate that robotic presence does not suppress moral action in any deterministic sense. Instead, it exerts a statistically coherent but modest refractive influence: it alters the \textit{amplitude} with which moral salience transitions into overt prosocial behaviour, without erasing the underlying evaluative architecture. The moral field remains operative, but its expression becomes probabilistically dampened under synthetic co-presence.

This pattern resonates with the broader theoretical framing developed throughout this chapter. Within the informational ontology of Floridi’s Levels of Abstraction, the robot functions as a \textit{semantic perturbator}: its perceived ontology introduces a shift in the evaluative topology at the LoA where moral cues acquire salience. 

\noindent
The effect sizes observed here are therefore best interpreted not as behavioural weakness, but as evidence that moral displacement operates as a \textit{graded transformation} within the evaluative function $f$, rather than a \textit{binary switch} between generosity and withholding.

\noindent
To capture this insight with conceptual precision, the following conclusion is offered:


\nextdiv
\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Conclusion: Amplitude of Moral Refraction]
		 \label{conc:amplitude_moral_refactor}
		Synthetic co-presence does not operate as a binary suppressor of moral behaviour but as a \textbf{probabilistic refractor} that modulates both the amplitude and direction of evaluative processing. Rather than displacing the normative orientation of the agent, the robotic presence perturbs the strength with which morally salient cues are transduced into prosocial action, yielding a graded attenuation consistent with its ambiguous ontological encoding at the operative Level of Abstraction.
	\end{tcolorbox}
\end{center}

\noindent
This conclusion follows coherently from the statistical, philosophical, and formal analyses developed thus far: robotic presence acts not as a moral veto, but as a structurally subtle deformation of the evaluative mapping from salience to action.

\section{Dispositional Baseline: Big Five Personality Traits Across Conditions}

\noindent
A foundational requirement for attributing the observed attenuation of prosocial behaviour to the presence of the humanoid robot is the establishment of \emph{dispositional equivalence} between the two experimental groups. If participants in the Robot condition were, for example, systematically lower in Agreeableness or Empathizing, then differences in donation behaviour could be trivially explained by trait imbalance rather than by the perturbative effect of $\mathscr{R}$. The question addressed in this section is therefore epistemically prior to all subsequent modelling:

\begin{quote}
	\textit{Do the Big Five personality traits differ between the Control and Robot conditions, and thus constitute a potential confound for interpreting the displacement of prosocial behaviour?}
\end{quote}

\subsection{Between-Condition Differences in Big Five Personality Traits}

\noindent
To examine this possibility, we compared Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism between conditions using the Mann--Whitney $U$ test. This analytic choice follows directly from the structure of the data: Big Five scores are bounded, ordinally coded psychometric measures, exhibit mild skew, and are measured with $N \approx 70$, a regime in which parametric assumptions cannot be guaranteed. The Mann–Whitney framework therefore offers the correct inferential granularity: it is distribution-free, variance-robust, and sensitive to monotonic rather than strictly linear differences.

Because examining five traits entails five simultaneous hypothesis tests, we applied the Benjamini–Hochberg False Discovery Rate (FDR) correction---a principled safeguard against Type~I inflation when multiple, correlated psychological constructs are assessed in parallel. This aligns with the epistemic architecture of the experiment: the question is not whether \emph{any} uncorrected difference might be found, but whether a \emph{reliable} dispositional asymmetry exists that could invalidate the interpretation of robotic presence as the causal perturbator.

\noindent
The results are unambiguous. After FDR correction, none of the Big Five traits differ significantly between the Control and Robot groups. Directional tendencies (e.g., slightly higher Openness and Agreeableness in the Control condition) fail to approach corrected thresholds, and visual inspection of the distributions reveals substantial overlap across all five traits.



\noindent
This permits a crucial inferential step: \textbf{the two groups can be treated as dispositionally equivalent}. The attenuation in donation behaviour cannot be attributed to pre-existing personality differences but must instead be interpreted as a perturbation arising from the ontological and semiotic properties of $\mathscr{R}$ itself.

\begin{figure}[H]
	\centering
	\begin{minipage}{0.98\linewidth}
		\centering
		\includegraphics[width=\linewidth]{new_plots/per_trait/bigfive_row_kde.png}
		\caption{Kernel density estimates for each Big Five trait across experimental conditions, demonstrating substantial distributional overlap.}
		\label{fig:bigfive_kde}
	\end{minipage}
\end{figure}


\subsection{Predictive and Moderating Roles of Big Five Traits}

\noindent
Establishing between-group equivalence does not settle a further question of theoretical importance:

\begin{quote}
	\textit{Even if the groups are balanced, do the Big Five traits nonetheless predict donation behaviour, or modulate the displacement effect of robotic presence?}
\end{quote}

To address the predictive dimension, we computed Spearman rank correlations between each Big Five trait and donation amount. Spearman’s $\rho$ is epistemically suited to this dataset: donation values are zero-inflated, non-normal, and bounded, while the trait scores arise from ordinal psychometric instruments that do not guarantee interval-level structure. Scatterplots with monotonic regression overlays were inspected for nonlinear tendencies that numeric coefficients might conceal.

For the moderation question, interaction models of the form
\[
\text{donation} \sim \text{condition} \times \text{trait}
\]
were estimated. This is the correct operationalisation of the theoretical claim that synthetic presence may act as a \textit{moral refractor}: an entity whose semiotic and ontological ambiguity differentially perturbs evaluative processing depending on the agent’s dispositional architecture.


\noindent
The findings are striking in their restraint. None of the Big Five traits significantly predict donation magnitude, nor do they moderate the difference between Control and Robot conditions. The behavioural divergence remains visible at the aggregate level, but its amplitude is not amplified or diminished at low versus high levels of any trait. The displacement effect of $\mathscr{R}$ is therefore \textbf{not trait-specific within the Big Five taxonomy}. 

\begin{figure}[H]
	\centering
	\begin{minipage}{0.98\linewidth}
		\centering
		\includegraphics[width=\linewidth]{new_plots/per_trait/bigfive_row_scatter.png}
		\caption{Scatter plots with fitted regression lines for each Big Five trait against donation amount. 
			Each panel displays individual participant scores alongside a smoothed linear trend. 
			No clear predictive relationships emerge, reinforcing the conclusion that the Big Five traits do not meaningfully predict prosocial donation within this experimental context.}
		\label{fig:bigfive_scatter}
	\end{minipage}
\end{figure}

\subsection{Interpretive Synthesis}

\noindent
These results yield a theoretically consequential conclusion: \emph{conventional trait psychology does not capture the dispositional dimensions along which synthetic presence modulates moral behaviour}. This does not imply that personality is irrelevant—indeed, our clustering analysis reveals precisely the latent dispositional regimes that matter—but rather that the Big Five, as a coarse-grained taxonomy, operates at a LoA too abstract to register the fine structure of cognitive–affective ecologies through which $\gamma_R$ refracts moral salience.

In other words, robotic presence perturbs moral action at a layer beneath the Big Five: a layer where traits combine into \emph{latent evaluative topologies}, not scalar predictors. This is why the Big Five show no predictive or moderating power, while the cluster-derived ecologies—Emotionally Reactive, Prosocial–Empathic, Analytical–Structured—display precisely the differential moral susceptibility that the Big Five cannot resolve.

These analyses therefore perform an indispensable gatekeeping role in the chapter’s argumentative arc: they clear the dispositional ground, justify the move toward structural trait models, and reinforce the interpretation of NAO’s presence as an ontologically driven perturbation rather than a byproduct of trait imbalance.

\noindent
Taken together, these findings compel a decisive interpretive transition. The Big Five analysis demonstrates that the classical trait taxonomy---as a coarse, high-level behavioural abstraction---is insufficiently granular to register the finer cognitive--affective structures through which robotic presence $\mathscr{R}$ exerts its perturbative force. In Floridi’s terms, the Big Five operate at a Level of Abstraction too distant from the operative informational interface at which moral salience is encoded, refracted, or displaced. Their scalar nature masks the latent relational geometries among traits that constitute an individual's evaluative topology. Consequently, the null results obtained here are not theoretically disappointing but theoretically clarifying: they reveal that dispositional factors relevant to moral modulation do not reside in isolated trait magnitudes, but in the \emph{configuration space} formed by their interaction.

\noindent
This insight aligns seamlessly with the ontological reading of NAO’s presence developed throughout this chapter. If $\mathscr{R}$ functions as an ambiguous semantic body---a synthetic agent whose minimal behavioural expressivity is nonetheless morally charged---then its impact is unlikely to map onto additive trait scores. Instead, it should refract through the structural organisation of cognitive--affective dispositions: the latent ecologies that position each participant differently relative to the moral field and its salient cues. The absence of main effects or trait-by-condition interactions within the Big Five framework thus strengthens, rather than weakens, the overarching argument. It demonstrates that the robot’s influence does not depend on conventional personality differences, but on deeper evaluative architectures that the Big Five only partially and indirectly approximate.

\noindent
This justificatory work also prepares the conceptual ground for the analyses that follow. Having ruled out personality imbalance as a confound and shown that the Big Five do not predict or moderate prosocial behaviour, the inquiry must now shift to a more structurally sensitive representation of $\beta_C$. The question becomes not whether traits matter, but \emph{how they combine} into latent dispositions that modulate the flow of moral salience under conditions of ontological ambiguity. It is precisely this transition---from scalar traits to configurational ecologies---that motivates the move toward clustering and latent-structure modelling in the next section.



\subsection{Latent Trait Structures and Individual Modulation of Moral Perturbation}

\noindent
The analyses conducted thus far establish that robotic co-presence $\mathscr{R}$ exerts a modest but coherent attenuation of prosocial donation at the aggregate level. However, such group-level effects leave open a critical question: \textit{is this perturbation uniformly distributed across individuals, or is it contingent upon underlying cognitive–affective structures encoded in} $\beta_C$? If robotic presence operates as a semantic perturbator at the operative Level of Abstraction, then its impact may be differentially refracted through distinct personality configurations rather than applied homogeneously to all participants.

To investigate this possibility, we moved beyond treating individual differences as simple additive covariates and instead modelled them as \textbf{latent psychological regimes}. Concretely, participants were clustered according to their standardised psychometric profiles, thereby refining the $\beta_C$ term in the operational model
\[
\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R)
\]
from a mere vector of trait scores into a set of structurally defined personality constellations.

Seven variables were included in the initial psychometric space: Empathizing, Systemizing, Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism. Each participant’s score vector was $z$-standardised and submitted to Principal Component Analysis (PCA). Two orthogonal principal components were retained, capturing the most informative axes of variance in the trait space while reducing dimensionality and mitigating redundancy among correlated measures.

The resulting two-dimensional representation was then subjected to $k$-means clustering with $k = 3$, yielding three psychologically interpretable personality clusters. These clusters were visualised in the reduced PCA space to assess structural separability and interpretative coherence (Figure~\ref{fig:personality-clusters-pca}).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.95\linewidth]{new_plots/personality_clusters_pca.png}
	\caption{Participants clustered in PCA-reduced psychometric space, coloured by cluster identity and shaped by experimental condition. The clustering reveals three latent personality regimes, each representing a distinct cognitive–affective configuration encoded in $\beta_C$.}
	\label{fig:personality-clusters-pca}
\end{figure}

\noindent
This procedure provides a structural lens through which to examine the interaction between moral perturbation and trait-defined cognitive–affective style. Rather than treating traits as independent predictors, the clustering approach models them as \textit{emergent regimes} that may stabilise or destabilise the inferential transmission of moral salience under the perturbation introduced by $\gamma_R$.

\medskip
\noindent
The choice of $k = 3$ was not arbitrary. It was justified through a combination of quantitative and conceptual criteria. First, the within-cluster sum of squares (WCSS) was inspected across candidate values of $k$, revealing a clear elbow in the inertia curve at $k = 3$. This elbow indicates a point of diminishing returns: additional clusters beyond three yield only marginal improvements in within-cluster homogeneity, at the cost of increased model complexity and reduced interpretability.

Second, the silhouette coefficient was computed for multiple candidate $k$ values. While a local maximum in the silhouette profile was observed at $k = 9$, this peak is best interpreted as an artefact of over-partitioning a relatively small dataset. At such resolutions, high silhouette values often reflect the tightness of very small clusters rather than psychologically meaningful structure. In contrast, $k = 3$ corresponds both to the elbow in the inertia curve and to clusters of interpretable size and composition (Figure 6.8).

\begin{figure}[H]
	\centering
	\includegraphics[width=0.95\linewidth]{new_plots/cluster_elbow_silhouette.png}
	\caption{Elbow plot of within-cluster sum of squares (left axis) and silhouette coefficients (right axis) across candidate values of $k$. The elbow at $k = 3$ and interpretable silhouette profile support the selection of three clusters as a parsimonious and psychologically meaningful solution.}
	\label{fig:cluster_elbow_silhouette}
\end{figure}

\noindent
From a conceptual standpoint, the $k = 3$ solution aligns with the broader theoretical expectation that robotic perturbation may be differentially refracted through a small number of discrete cognitive–affective configurations, each constituting a distinct normative filter through which $\alpha_E$ and $\gamma_R$ are jointly interpreted. Accordingly, we retain $k = 3$ as the optimal clustering solution on both methodological and interpretive grounds.

\noindent
Cluster-specific analyses of donation behaviour reveal heterogeneous responses to moral cues across these latent regimes (Figure~\ref{fig:donation-by-cluster}). In one cluster (Cluster 1), the presence of the robot appears to strongly attenuate donation amounts, whereas in the remaining clusters (Clusters 0 and 2), the difference between Control and Robot conditions is negligible or comparatively weak. Inspection of the underlying psychometric profiles suggests that \textit{Cluster 1 is characterised by relatively higher systemising} and lower empathising scores, in line with a cognitive–affective style that privileges structural or rule-based processing over affective resonance.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.85\linewidth]{new_plots/donation_by_cluster_and_condition.png}
	\caption{Mean donation amount by experimental condition within each personality cluster, derived from $k$-means analysis on psychometric trait profiles. Error bars represent standard deviation. Cluster 1 shows a marked attenuation of donation under robotic presence, whereas Clusters 0 and 2 exhibit minimal or modest differences. This pattern suggests that the perturbative effect of $\gamma_R$ is contingent upon latent cognitive–affective regimes encoded in $\beta_C$.}
	\label{fig:donation-by-cluster}
\end{figure}

\subsection{Psychometric Interpretation and Semantic Labelling of Latent Personality Clusters}

\noindent
The identification of three latent personality clusters through PCA reduction and $k$-means partitioning raises a conceptually prior question: \textit{What psychological architectures do these clusters instantiate, and how do these architectures illuminate the differential moral impact of robotic presence?} Clustering partitions participants into structurally coherent groups, but it does not automatically disclose the dispositional logic underpinning those partitions. This section therefore provides the interpretive grounding required for integrating the latent trait configurations with the moral-topological framework developed throughout the chapter.

From an epistemic standpoint, interpretation requires a return from the abstract PCA space to the original psychometric dimensions. The unscaled cluster centroids perform this bridging function: they reveal each cluster’s mean position along Empathizing, Systemizing, and the Big Five dimensions, thereby reconstituting the mathematical solution in explicitly psychological terms. Radar plots offer a visual gestalt of these relational structures, and when presented jointly, they highlight the contrastive organisation of personality ecologies more effectively than isolated representations.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.32\linewidth]{new_plots/cluster_0_radar.png}
	\includegraphics[width=0.32\linewidth]{new_plots/cluster_1_radar.png}
	\includegraphics[width=0.32\linewidth]{new_plots/cluster_2_radar.png}
	\caption{Comparative radar profiles of the three latent personality ecologies.  
		\textbf{Emotionally Reactive / Low-Structure Profile} (left): elevated Neuroticism with reduced Conscientiousness and Systemizing.  
		\textbf{Prosocial–Empathic / Warm–Sociable Profile} (centre): high Openness, Extraversion, Agreeableness, and Empathizing.  
		\textbf{Analytical–Structured / High-Systemizing Profile} (right): high Systemizing and Conscientiousness with lower Empathizing.}
	\label{fig:radar_three_panel}
\end{figure}

\noindent
\textbf{Emotionally Reactive / Low-Structure Profile.}  
This ecology, corresponding to the first extracted cluster, is characterised by elevated Neuroticism, reduced Conscientiousness, and diminished Systemizing, complemented by moderate values across Openness, Extraversion, and Agreeableness. This constellation reflects an \textit{affectively volatile and structurally diffuse} cognitive ecology. Individuals belonging to this regime likely experience greater internal variability, weaker evaluative stability, and heightened sensitivity to subtle environmental perturbations. Within the moral-topological framework of this chapter, their evaluative surface is best described as \textit{loosely stabilised}: moral cues propagate through a field with low structural coherence, making contextual distortions—such as the ontological ambiguity of a subtly animated robot—especially salient.

\vspace{0.4cm}
\noindent
\textbf{Prosocial–Empathic / Warm–Sociable Profile.}  
This ecology exhibits high Openness, Extraversion, Agreeableness, and Empathizing, forming a \textit{warm, sociable, affectively attuned, exploratory} personality architecture. These participants show the canonical prosocial configuration in moral psychology: they are dispositionally inclined toward interpersonal resonance and empathic attunement. Under classical Watching Eye frameworks, this ecological type would be expected to amplify donation behaviour in the presence of a moral-salience stimulus such as the charity poster. Their attenuation under robotic presence therefore becomes diagnostic: it indicates that $\gamma_R$ may refract or dilute empathic pathways, moderating the evaluative transition from moral salience to prosocial output precisely where that transition would otherwise be strongest.

\vspace{0.4cm}
\noindent
\textbf{Analytical–Structured / High-Systemizing Profile.}  
This ecology is defined by high Systemizing, high Conscientiousness, and comparatively reduced Empathizing—a \textit{rule-based, analytical, orderly} psychological regime. These individuals privilege structural clarity and formal coherence over affective immediacy. Moral stimuli embedded in implicit or ambiguous contexts—such as the subtle moral affordance of the child-beneficiary poster—may exert weaker motivational force. Likewise, the ontological ambiguity of the robot is likely processed as a structurally neutral environmental feature rather than a socially meaningful presence. In LoA terms, this group operates with a higher abstraction threshold: cues must be explicitly norm-encoded to penetrate their evaluative architecture.

\vspace{0.5cm}
\noindent
\textbf{Interpretive Integration.}  
These semantic labels are not optional descriptive flourishes; they are \textit{epistemically necessary} for making the cluster solution theoretically legible. Without them, the clustering results would remain mathematically partitioned yet psychologically opaque. By identifying one ecology as affectively volatile, one as prosocial–empathic, and one as analytical–structured, we obtain a principled account of how moral salience interacts with latent cognitive architectures. This alignment allows the latent ecologies to interface directly with earlier behavioural findings: attenuation of prosocial donation is most pronounced where empathic pathways should be strongest (the Prosocial–Empathic profile), weak in the Analytical–Structured group, and context-dependent in the Emotionally Reactive profile.

\vspace{0.5cm}
\noindent
\textbf{Connection to Floridi’s Levels of Abstraction.}  
At the operative LoA of each participant, these ecologies function as distinct \textit{semantic filters}. The Prosocial–Empathic type foregrounds affective cues, the Analytical–Structured type foregrounds structural clarity, and the Emotionally Reactive type foregrounds affective volatility. The presence of a synthetic agent—whose ontology is ambiguous, neither fully inert nor fully social—thus perturbs a different aspect of the evaluative interface for each ecology. This explains why the moral perturbation induced by $\gamma_R$ is neither global nor homogeneous, but topologically refracted through the architecture of each ecological type.
 
This interpretive reconstruction provides the conceptual bridge between latent personality architecture and the heterogeneous behavioural effects documented earlier. It reveals three structurally distinct evaluative ecologies, each with its own susceptibility profile to moral salience and robotic ambiguity. Their integration into the broader analytic narrative elucidates why attenuation under robotic presence is concentrated in the Prosocial–Empathic group, weak in the Analytical–Structured group, and variable in the Emotionally Reactive group. This interpretive foundation prepares the ground for the Bayesian estimation framework developed in the next section, where uncertainty, heterogeneity, and differential susceptibility are modelled as epistemic gradients.

\noindent
These findings deepen the interpretation of robotic presence $\gamma_R$ as a \textit{contextually realised} perturbator rather than a uniformly applied suppressor. The robot’s influence is not globally fixed, but \textbf{contingently instantiated through latent cognitive structures}. The same synthetic presence that weakens the evaluative transmission from moral salience to action in one psychological regime may have negligible impact in another. In this sense, the clustering analysis gives empirical shape to the idea that the evaluative function $f(\alpha_E, \beta_C, \gamma_R)$ is structurally modulated by $\beta_C$ rather than merely shifted in its intercept.

\medskip
\noindent
This motivates the following conceptual conclusion, which summarises the trait-contingent character of the observed perturbation:

\nextdiv
\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Conclusion: Contingent Structure of Cognitive Modulation]
		\label{conc:clustered_moral_refraction}
		The moral impact of robotic presence is not globally uniform but emerges through contingent interactions between artificial co-presence and latent psychological regimes. Personality clustering shows that synthetic moral perturbation is structurally modulated: its amplitude and behavioural expression are refracted through cognitive–affective configurations that define the subject’s interpretive topology. In Floridian terms, $\gamma_R$ does not act upon a neutral substrate, but upon agents whose operative Levels of Abstraction are themselves shaped by trait-dependent informational filters.
	\end{tcolorbox}
\end{center}

\noindent
Interpreted through the lens of the three latent personality ecologies identified earlier, this conclusion acquires a further layer of structural specificity. The \textit{Prosocial–Empathic / Warm–Sociable} profile is the regime in which the refractive impact of $\gamma_R$ is most pronounced: here, empathic pathways are ordinarily the most fluid, and thus the ontological ambiguity of the robotic presence most effectively perturbs the evaluative mapping from salience to action. By contrast, the \textit{Analytical–Structured / High-Systemizing} profile exhibits a comparatively rigid interpretive topology—one in which affective cues carry diminished epistemic weight and where the robot is recoded as a structurally neutral environmental feature rather than a moral affordance. The \textit{Emotionally Reactive / Low-Structure} profile occupies an intermediate position: its evaluative landscape is marked by volatility, rendering it sensitive to contextual shifts, yet not in a manner that yields a stable pattern of attenuation. Together, these ecologies demonstrate that the deformation induced by $\gamma_R$ is not a global displacement but a trait-contingent refractor: the moral field bends most sharply where empathic vectors dominate, remains nearly inert where systemizing structure prevails, and oscillates unpredictably in affectively unstable regimes. In this sense, the clusters make explicit the topological heterogeneity of the human moral interface, revealing that \textit{robotic presence engages different Levels of Abstraction depending on the cognitive–affective filters through which it is perceived.}


\subsection{Interim Synthesis: Moral Attenuation, Topological Deformation, and Trait-Contingent Modulation}

\noindent
The analyses completed thus far allow us to articulate a coherent intermediate synthesis of the empirical and conceptual structure of the experiment. Two principal results have emerged with consistency:

\begin{enumerate}
	\item[(1)] A measurable attenuation of prosocial donation under robotic co-presence (\cref{conc:amplitude_moral_refactor});  
	\item[(2)] A structurally heterogeneous, cluster-contingent modulation of this attenuation (\cref{conc:clustered_moral_refraction}).
\end{enumerate}

\noindent
Together, these findings show that robotic presence $\gamma_R$ does not function as a uniform suppressor of moral action, but as a \textbf{probabilistic refractor} that perturbs the inferential trajectory by which moral salience is transformed into behaviour. The robot’s effect is both \textit{topologically distributed}—reshaping the evaluative field at the aggregate level—and \textit{psychologically conditional}, emerging only within specific latent cognitive–affective regimes encoded in $\beta_C$.

\bigskip

% ----------------------
% Hypotheses
% ----------------------

\subsubsection{Status of the Hypotheses}

\paragraph{H1. Evaluative Deformation Hypothesis.}
\emph{The expected outcome of moral behaviour, formalised by the transformation $f(\cdot)$, is altered when a humanoid robot is present within the perceptual–moral environment.}

\textbf{Status: Retained.}  
The aggregate attenuation in donation amounts supports this claim. All empirical analyses converge on the conclusion that $\mathbb{E}[f(\Sigma \cup \mathscr{R})] < \mathbb{E}[f(\Sigma)]$.

\paragraph{H2. Synthetic Normativity of Moral Displacement.}
\emph{Synthetic presences may acquire normative affordances by virtue of their perceived ontology.}

\textbf{Status: Retained (Conceptual Foundation).}  
This hypothesis explains \textit{why} a non-interactive robot can perturb moral cognition. The data do not test it directly, but every behavioural pattern observed is \textit{consistent} with this ontological grounding.

\paragraph{H3. Synthetic Perturbation of Moral Inference.}
\emph{The robot refracts the transition from moral salience to prosocial action.}

\textbf{Status: Retained (Mechanistic).}  
The observed attenuation at the aggregate level, together with the trait-contingent cluster effects, supports the mechanistic claim that $\gamma_R$ modifies the evaluative mapping rather than merely shifting motivational baselines.

\paragraph{H4. (Implied) Trait-Contingent Modulation Hypothesis.}
\emph{The perturbative effect of $\gamma_R$ varies as a function of latent cognitive–affective regimes encoded in $\beta_C$.}

\textbf{Status: Provisionally Supported.}  
Cluster-specific patterns strongly suggest regime-dependent responsiveness. This hypothesis will be tested more formally in the regression and interaction analyses that follow.


% ----------------------
% Mathematical Summary
% ----------------------

\subsubsection{Condensed Status of the Formal Framework}

The mathematical apparatus introduced earlier has now been substantively activated:

\begin{itemize}
	\item The transformation function $f(\cdot)$ provided a principled way of interpreting behavioural attenuation as deformation of the evaluative mapping.
	\item The expected-value contrast $\mathbb{E}[f(\Sigma)]$ vs.\ $\mathbb{E}[f(\Sigma \cup \mathscr{R})]$ captured the aggregate attenuation signature, now empirically supported.
	\item The tripartite decomposition  
	\[
	\mathscr{P}(\delta_m) = f(\alpha_E, \beta_C, \gamma_R)
	\]
	has proven essential:  
	– $\alpha_E$ held constant (Watching Eye),  
	– $\beta_C$ refined via PCA and clustering,  
	– $\gamma_R$ isolated as the only experimental manipulation.  
\end{itemize}

\noindent
In short, the formalism has not merely annotated the behavioural results but \textbf{structured the empirical horizon} of the experiment: it dictates what counts as evidence for deformation, where individual differences should enter the model, and how perturbation effects should be interpreted.

\bigskip

% ----------------------
% Topological / Ontological Interpretation
% ----------------------

\subsubsection{Topological and Ontological Interpretation}

\noindent
The combined results illuminate a deeper philosophical point: the perturbation induced by the robot is best understood as a \textbf{topological deformation} of the moral field rather than a unidirectional causal force. At the operative Level of Abstraction (LoA) relevant to participants, the NAO robot presents itself neither as an inert object nor as a full agent; instead, it occupies an ontologically ambiguous middle-ground whose semantic affordances penetrate the participant’s normative perception.

Under this LoA, $\mathscr{R}$ functions as a \textbf{semiotic operator}—a presence that modifies the structure of evaluative attention by refracting the moral salience of $\alpha_E$ before it becomes behaviourally actionable. The attenuation of prosocial donation thus reflects not a collapse of empathy, nor a motivational deficit, but a reconfiguration of the interpretive schema that governs the mapping
\[
\Sigma \xrightarrow{f} \mathscr{D}.
\]

\noindent
The second major result extends this insight: the deformation is \textit{not} uniform across individuals. Instead, it is \textbf{contingently realised} through latent cognitive–affective structures. In some clusters, the presence of $\gamma_R$ yields substantial attenuation; in others, its impact is negligible. This cluster-contingent pattern confirms that the perturbation does not operate on a neutral cognitive substrate but on \textit{trait-defined normative filters}, each instantiating a distinct interpretive topology.

\bigskip

% ----------------------
% Interim Conclusion Box
% ----------------------

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,title=Interim Conclusion: Topological and Trait-Dependent Moral Modulation]
		Robotic co-presence attenuates prosocial donation through a deformation of the evaluative pathway that links moral salience to action. This attenuation is neither uniform nor deterministic: it emerges as a probabilistic refractor of moral cognition whose amplitude varies across latent cognitive–affective regimes. The empirical findings thus far support all three foundational hypotheses—evaluative deformation, synthetic normativity, and perturbation of moral inference—and provisionally support the trait-contingent modulation hypothesis. At the operative Level of Abstraction, the humanoid robot acts as a semiotic agent whose ontological ambiguity reshapes the topology of moral evaluation. Subsequent analyses will test the stability, depth, and interaction structure of this modulation through cluster-specific regression modelling.
	\end{tcolorbox}
\end{center}


\subsection{The Dilution of the Watching Eye Effect under Robotic Co-Presence}

\noindent
Within the present experimental design, the morally salient cue was instantiated through the photograph of an infant in need, prominently displayed on the Operation Smile brochure. As established earlier (see \cref{chap:watching_eye}), such pictorial stimuli operate as \textit{implicit moral surveillance cues}: they trigger affective empathy, reputational sensitivity, and the pre-reflective sense of “being observed” that underlies the classical Watching Eye effect \cite{Bateson2006, NettleEtAl2013, ContyGeorgeHietanen2016}. 

\noindent
The interim results now allow us to articulate a critical interpretive point: \textbf{the presence of the humanoid robot systematically dilutes the potency of the Watching Eye stimulus}. This dilution does not reflect a suppression of empathy nor a negation of moral motivation. Instead, it emerges as a topological deformation of the evaluative field in which the Watching Eye cue is embedded.

\noindent
At the operative Level of Abstraction, the robot introduces a second semiotic centre—an ontologically ambiguous presence whose social affordances compete with, refract, or partially occlude the normative signal emitted by the infant's face. The moral salience encoded in the pictorial cue no longer operates within a clean perceptual–affective channel; it is instead filtered through a perturbed interpretive topology shaped by $\gamma_R$. 

\noindent
In this sense, the dilution of the Watching Eye effect is not a psychological epiphenomenon but the behavioural signature of the Evaluative Deformation Hypothesis (\ref{hyp:evaluative_deformation}). The attenuation in donation behaviour reflects an altered mapping from 
\[
\Sigma_{\text{eye}} \longrightarrow \mathscr{D},
\]
where $\Sigma_{\text{eye}}$ denotes the moral-affective perceptual space dominated by the infant’s image. Under robotic co-presence, this mapping becomes
\[
\Sigma_{\text{eye}} \cup \mathscr{R},
\]
and its expected output $\mathbb{E}[f(\Sigma_{\text{eye}} \cup \mathscr{R})]$ is weakened relative to the control condition.

\noindent
Thus, the Watching Eye stimulus does not lose its moral force; rather, its \textit{evaluative amplitude} is refracted by the semiotic presence of the robot, producing a diluted conversion of moral salience into prosocial action. This interpretation coheres with both the ‘Amplitude of Moral Refraction’ conclusion (\cref{conc:amplitude_moral_refactor}) and the ‘Contingent Structure of Cognitive Modulation’ conclusion (\cref{conc:clustered_moral_refraction}), and it reinforces the central claim of this chapter: synthetic presences modulate moral cognition by altering the topology through which normative cues are interpreted, not by erasing those cues.



%%% NEW CONTENT N10
\subsection{Cluster-Specific Regression Analysis of Robotic Perturbation}

\noindent
To determine whether specific cognitive–affective regimes exhibit differential sensitivity to robotic presence, we conducted a stratified linear regression analysis within each of the three latent personality clusters identified through PCA reduction and $k$-means partitioning. Donation amount served as the dependent variable, while experimental condition (Control vs.\ Robot) functioned as the primary predictor. This design allows us to test whether the perturbative effect of $\gamma_R$ is uniformly distributed across the population or selectively amplified within particular psychological ecologies.

\vspace{0.3em}
\noindent
\textbf{A sharply asymmetric pattern emerges.}  
Within the \textbf{Prosocial–Empathic / Warm–Sociable} profile, robotic presence exerts a marked attenuation effect: the regression coefficient for the Robot condition is substantially negative (\(\beta = -1.33\)), approaching conventional significance (\(p = .091\)) and accounting for a non-trivial proportion of variance (\(R^2 = 0.087\)). This regime—dispositionally characterised by high Empathizing, elevated Agreeableness, and strong sociability—is theoretically the most responsive to the Watching Eye stimulus, because its evaluative architecture privileges affective resonance as the primary conduit for moral salience. The significant drop in donation under $\gamma_R$ therefore reveals a targeted deformation of the empathic pathway: the robot refracts, rather than merely weakens, the affective-to-behavioural mapping that ordinarily sustains prosocial output in this group.

\vspace{0.4em}
\noindent
By contrast, the \textbf{Emotionally Reactive / Low-Structure} profile (\(\beta \approx 0\), \(p > .70\)) and the \textbf{Analytical–Structured / High-Systemizing} profile (\(\beta = -0.28\), \(p > .70\)) exhibit negligible perturbation. For the former, affective volatility introduces noise that may obscure subtle contextual modulation; for the latter, the affective Watching Eye cue already carries limited normative weight, and the robot is likely recoded as a structurally neutral artefact rather than a socially meaningful presence. The absence of attenuation in these two ecologies confirms that robotic presence does not impose a uniform moral influence across participants.

\vspace{0.4em}
\noindent
These findings consolidate the theoretical shift advanced in earlier sections: individual differences must not be conceptualised as additive covariates but as \textbf{distinct cognitive–affective topologies}. Each cluster constitutes an internal evaluative landscape whose geometry determines the stability, amplitude, and direction of moral salience transmission under perturbative conditions. Within this framework, the Watching Eye cue and $\gamma_R$ do not operate as independent forces; rather, they interact within a structured evaluative manifold whose topology differs across psychological regimes.  

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\linewidth]{new_plots/cluster_regression_coefficients.png}
	\caption{Regression coefficients for the Robot condition within each personality cluster (95\% confidence intervals). The Prosocial–Empathic profile shows a pronounced attenuation effect, while the Emotionally Reactive and Analytical–Structured profiles exhibit negligible or non-significant coefficients. This pattern demonstrates that robotic presence exerts a differentiated moral influence, contingent on latent cognitive–affective ecologies.}
	\label{fig:cluster-regression}
\end{figure}

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Conclusion: Differentiated Moral Sensitivity to Robotic Presence]
		\label{conc:regression_cluster_specific}
		Robotic presence does not exert a uniform moral influence. Instead, its perturbative effect emerges selectively through the structured configurations of latent psychological regimes. Cluster-specific regression analysis demonstrates that moral attenuation is concentrated within particular cognitive–affective ecologies—notably the Prosocial–Empathic profile—confirming that the ethical salience of synthetic agents is not globally encoded but \textbf{contextually realised through trait-dependent evaluative topologies}.
	\end{tcolorbox}
\end{center}

\noindent
This cluster-level analysis thus advances the broader conceptual arc of the chapter. The perturbative force of $\mathscr{R}$ is neither binary nor homogeneous. It refracts through psychological architectures that differ in their susceptibility to moral cues, their interpretive stability in the face of ontological ambiguity, and their capacity to integrate artificial co-agents into the evaluative apparatus of practical reasoning.

The differentiated regression patterns reported above can be expressed in a compact
mathematical form by examining how the evaluative transformation function,
$f(\cdot)$, behaves across the three latent cognitive–affective regimes.

For the \textbf{Emotionally Reactive / Low-Structure Profile}, donation behaviour remains
effectively unchanged across conditions. This corresponds to an evaluative mapping
in which robotic presence introduces no meaningful perturbation:
\[
\mathbb{E}\big[f(\Sigma \cup \mathscr{R})\big] \;\approx\; \mathbb{E}\big[f(\Sigma)\big].
\]

For the \textbf{Prosocial–Empathic / Warm–Sociable Profile}, robotic presence produces a
marked attenuation in prosocial action, consistent with a refracted or collapsed
transformation pathway:
\[
\mathbb{E}\big[f(\Sigma \cup \mathscr{R})\big] \;\ll\; \mathbb{E}\big[f(\Sigma)\big].
\]

For the \textbf{Analytical–Structured / High-Systemizing Profile}, the perturbation is milder
but still directionally negative, suggesting a partially disrupted evaluative mapping:
\[
\mathbb{E}\big[f(\Sigma \cup \mathscr{R})\big] \;<\; \mathbb{E}\big[f(\Sigma)\big].
\]

\noindent
Together, these expressions provide a compact formal summary of the
cluster-dependent structure of moral perturbation: the same environmental input
$(\Sigma \cup \mathscr{R})$ is transduced into different expected behavioural outputs
depending on the latent cognitive–affective topology governing the evaluative
function $f(\cdot)$. This reinforces the central finding of the cluster analysis:
\textit{synthetic presence is not a uniform causal factor, but a structure-sensitive
	modulator whose influence is enacted only through particular psychological regimes.}

\noindent
 What remains is to examine whether these findings persist when classical linear assumptions are relaxed, and when the inferential dynamics are modelled within probabilistic frameworks capable of representing uncertainty, interaction structures, and epistemic gradients.

\subsection{Bayesian Estimation and Epistemic Gradient Framing}

\noindent
The analyses conducted thus far—chi-squared tests, Mann–Whitney comparisons, and cluster-specific OLS regressions—have established an initial empirical profile of moral attenuation under robotic presence. Yet these methods, by virtue of their frequentist foundations, impose restrictive epistemic commitments. They require data to conform to assumptions of normality, homoscedasticity, and independent errors, and they compress inferential uncertainty into binary decisions: significant versus non-significant. In a dataset of modest size (\(N \approx 70\)), and in an experimental design explicitly concerned with subtle perturbations of moral salience, these constraints obscure more than they reveal.

\vspace{0.4em}
\noindent
\textbf{The epistemic limitations of frequentism are not merely statistical; they are conceptual.}  
Frequentist procedures treat uncertainty as an error term, not as a structured property of knowledge. They cannot express graded belief, asymmetric plausibility, or the ways in which ontological ambiguity—such as that introduced by NAO—propagates through an evaluative system. Nor can they incorporate hierarchical structure emerging from latent cognitive–affective profiles. In short, they fail to capture the topology of inference itself.

\vspace{0.4em}
\noindent
To address these limitations, we employed \textbf{Bayesian estimation}, specified as a hierarchical model that incorporates (i) group-level variation between the Control and Robot conditions, and (ii) cluster-level variation across the three latent personality ecologies: the \textit{Emotionally Reactive / Low-Structure} profile, the \textit{Prosocial–Empathic / Warm–Sociable} profile, and the \textit{Analytical–Structured / High-Systemizing} profile. This hierarchical framing allows the posterior distribution to reflect not only uncertainty in the donation means, but also the structural heterogeneity of the population—an essential requirement for interpreting moral perturbation within a multi-layered evaluative topology.

\vspace{0.5em}
\noindent
\textbf{Posterior estimation.}  
Under weakly informative priors, the posterior mean of the donation difference (\texttt{Control – Robot}) was approximately £0.70, with a 95\% credible interval spanning –£1.75 to +£0.30. While the interval includes zero, its mass is asymmetrically skewed toward negative values, indicating \textit{directional probabilistic evidence} that robotic presence attenuates prosocial output. Unlike p-values, which collapse inferential nuance into a discontinuous threshold, the posterior distribution provides a graded representation of epistemic support: attenuation is neither confirmed nor refuted categorically, but represented as a structured probability over moral space.

\begin{figure}[H]
	\centering
	\includegraphics[width=0.75\linewidth]{new_plots/posterior_donation_difference.png}
	\caption{Posterior distribution of the estimated donation difference between the Control and Robot conditions. The density skews toward negative values, indicating directional probabilistic evidence that robotic co-presence attenuates prosocial behaviour. The vertical dashed line denotes the point of no effect. Bayesian inference renders the effect size and its uncertainty as a continuous epistemic field rather than a binary verdict.}
	\label{fig:posterior-difference}
\end{figure}

\vspace{0.5em}
\noindent
\textbf{Epistemic value of the Bayesian approach.}  
The Bayesian framework offers three advantages directly relevant to the interpretive architecture of this chapter:

\begin{enumerate}
	\item \textbf{Uncertainty as structure, not noise.}  
	The posterior distribution reflects graded belief over effect magnitudes, aligning with the chapter’s emphasis on moral topologies rather than discrete behavioural outputs.
	
	\item \textbf{Compatibility with ontological ambiguity.}  
	Robotic presence operates as a \textit{semiotic perturbator} whose influence is subtle, non-deterministic, and context-dependent. Bayesian inference accommodates such phenomena by modelling effect strength as a distribution across epistemic space.
	
	\item \textbf{Hierarchical alignment with trait-dependent regimes.}  
	The differential sensitivities observed in the Prosocial–Empathic versus Analytical–Structured profiles, and the near-invariance of the Emotionally Reactive profile, are naturally represented within a Bayesian hierarchical model. Each cluster inherits a partial-pooling structure that respects its latent topology while sharing information across the population.
\end{enumerate}

\vspace{0.4em}
\noindent
\textbf{Connection to Floridi’s Levels of Abstraction.}  
At the operative LoA of the participant, Bayesian estimation better captures the epistemic footprint of $\gamma_R$ because it represents uncertainty as an ontologically meaningful property of the evaluative system. Just as NAO’s ambiguous ontology introduces interpretive indeterminacy, the Bayesian posterior encodes inferential indeterminacy: both operate as gradients rather than binary categories. In this sense, Bayesian inference does not simply analyse the data—it mirrors the very cognitive structure by which participants register moral salience under conditions of uncertainty.



\subsubsection{Epistemic Interpretation of the Bayesian Results}

\noindent
Bayesian inference may appear unfamiliar to readers accustomed to classical statistics, yet its relevance to this chapter is not merely methodological but philosophical. Whereas frequentist tests force evidence into a binary verdict—``significant’’ or ``not significant’’—Bayesian estimation represents uncertainty as a \textit{graded belief}. It asks how plausible an effect is, given the data and our modelling assumptions, and it expresses that plausibility as a continuous distribution rather than a categorical judgment.

\vspace{0.4em}
\noindent
In practical terms, the posterior distribution shown in Figure~\ref{fig:posterior-difference} does \textbf{not} claim that robotic presence definitely reduces donation behaviour. Instead, it says that—given the observed data—the reduction is \textit{more likely than not}. The most plausible magnitude of this attenuation is located around £0.70, but with substantial uncertainty surrounding it. This uncertainty is not a flaw; it is a feature of the Bayesian framework, which makes visible the epistemic limits of the evidence rather than compressing them into a single thresholded output.

\vspace{0.4em}
\noindent
Readers familiar with p-values may recall that some classical tests, especially the Mann–Whitney \(U\) test, did not reach conventional significance. This does not contradict the Bayesian findings. Rather, it reflects two different epistemic logics. Frequentist tests ask whether the data cross a pre-defined threshold under strict distributional assumptions. Bayesian analysis asks how the evidence updates our degree of belief about a hypothesis, even when the effect is small, variable, or distributed unevenly across psychological subgroups.

\vspace{0.4em}
\noindent
In this sense, the Bayesian model does not ``rescue’’ non-significant results; it \textit{reframes} them. It allows us to articulate the structure of uncertainty explicitly, acknowledging that our dataset is modest in size and that the moral field under investigation is inherently noisy. Where classical statistics provide a verdict, Bayesian inference provides a \textbf{map of epistemic gradients}—a representation of how belief should shift in light of the available evidence.

\vspace{0.4em}
\noindent
This is particularly appropriate for the present study, where the effect of NAO’s presence is theorised to arise from \textit{ontological ambiguity} and \textit{trait-dependent refractive pathways}. Such perturbations are not deterministic; they unfold across the different cognitive–affective ecologies identified earlier (Emotionally Reactive, Prosocial–Empathic, Analytical–Structured). A modelling framework that treats uncertainty as structured and meaningful is therefore better aligned with the moral-topological interpretation guiding the chapter.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Conclusion: Gradient of the Impact of Moral Refraction]
		The Bayesian analysis supports a cautiously framed but epistemically credible claim: in some contexts, and for some psychological profiles, the presence of a humanoid robot reduces the likelihood that morally salient cues will be converted into prosocial behaviour. This conclusion is inherently graded rather than definitive, reflecting the probabilistic structure of both the evidence and the underlying cognitive processes.
	\end{tcolorbox}
\end{center}

\noindent
For a comparison with the non-Bayesian (frequentist) version of this claim, see Conclusion~\ref{conc:impact_moral_refactor}. Together, the two perspectives offer complementary lenses: one categorical and conservative, the other probabilistic and epistemically transparent.

% =====================================================================
% INTERIM CONCLUSION — TOPOLOGICAL RECONFIGURATION OF MORAL ACTION
% =====================================================================

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Interim Conclusion: Topological Reconfiguration of Moral Action Under Synthetic Co-Presence]
		The empirical and probabilistic results obtained thus far permit the first integrated assessment of Question~\ref{q:robot-agent}. Taken together, the behavioural attenuation, the cluster-specific regression patterns, and the Bayesian posterior distribution converge on a coherent interpretative claim: \textbf{the silent co-presence of a humanoid robot reshapes the evaluative topology through which morally salient cues become actionable for human agents}. This reshaping is neither universal nor deterministic; it is a graded, structure-dependent perturbation whose amplitude and direction emerge from the interplay of ontological ambiguity, individual trait configuration, and the Level of Abstraction at which the robot is cognitively encountered.
	\end{tcolorbox}
\end{center}

\noindent
The mechanism by which robotic presence exerts its influence is best understood in topological rather than causal terms. The NAO robot, operating in autonomous life mode, introduces a \textit{semiotic curvature} into the moral field: it subtly alters the evaluative geometry through which agents perceive, weight, and transform morally charged cues. This deformation is confirmed at the aggregate level through reduced prosocial donation, yet its structure becomes explicit only when viewed through the lens of latent trait ecologies.

Across the three identified psychological architectures, the perturbative influence of $\gamma_R$ refracts in distinct ways.  
The \textbf{Prosocial–Empathic profile}—marked by warmth, sociability, and heightened empathic attunement—exhibits the strongest attenuation under robotic presence. Theoretically, this group should be most responsive to the Watching Eye stimulus; their reduced prosocial output therefore indicates a displacement or dilution of empathic salience by the robot’s ontological ambiguity.  
The \textbf{Emotionally Reactive–Low-Structure profile} shows negligible modulation, suggesting that their evaluative field is already volatile and weakly integrated, leaving little room for additional deformation.  
The \textbf{Analytical–Structured profile} likewise remains comparatively invariant, consistent with a cognitive style that filters moral cues through explicit norms rather than affective resonance, rendering the robot semantically inert at their operative LoA.

\noindent
Bayesian estimation further clarifies the nature of this modulation. The posterior distribution does not license categorical claims, but instead renders visible an \textit{epistemic gradient}: the attenuation effect is probabilistically credible, directionally consistent with the behavioural and regression analyses, yet embedded in uncertainty that reflects the heterogeneity of human evaluative architectures. The robot’s moral impact is thus best read not as an on/off switch, but as a probabilistic refractor whose influence varies across psychological topologies.

Viewed through Floridi’s Levels of Abstraction, each cluster manifests a distinct \textit{semantic filter} through which the robot is interpreted. For the Prosocial–Empathic cluster, the operative LoA foregrounds social cues and affective salience; the robot therefore functions as a morally confusing signal, displacing the Watching Eye stimulus. For the Analytical–Structured cluster, the operative LoA highlights rule-based structure, making the robot semantically inert. For the Emotionally Reactive group, the LoA is affectively saturated yet structurally unstable, producing negligible behavioural change. In all cases, the robot’s ambiguous ontology is processed at the LoA that is dispositional to each group, generating a differentiated moral topology across the population.

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,
		title=Provisional Answer to Question~\ref{q:robot-agent}]
		The cumulative evidence supports a cautiously affirmative answer: \textbf{yes, the mere presence of a synthetic, non-agentic entity can perturb the evaluative transformation through which moral salience becomes moral action}. This perturbation does not manifest uniformly; it emerges through the interaction of robotic ontology with latent cognitive–affective structures. The Evaluative Deformation Hypothesis, the Synthetic Normativity of Moral Displacement, and the Synthetic Perturbation of Moral Inference are empirically and conceptually supported. The trait-contingency hypothesis is provisionally validated, pending further hierarchical modelling.
	\end{tcolorbox}
\end{center}

\noindent
Thus, the NAO robot’s presence in the room—silent, minimally animated, ontologically ambiguous—modulates moral action not by interrupting reflective deliberation, but by reconfiguring the \emph{interpretive topology} within which morally salient cues acquire behavioural force. The charity poster depicting a child beneficiary of medical aid—our operationalisation of the Watching Eye stimulus—normally functions as an affectively loaded reputational cue, activating empathic concern and third–party moral vigilance~\cite{HaleyFessler2005, Bateson2006, NettleEtAl2013, ContyGeorgeHietanen2016}. In the Robot condition, however, this prime is \textbf{perceptually and semantically diluted}: attentional and inferential resources are partially displaced from the poster toward the robot’s embodied but ontologically indeterminate presence. In effect, $\mathscr{R}$ acts as a \emph{semantic competitor}, weakening the intuitive channel through which the Watching Eye paradigm ordinarily promotes prosocial giving.

\noindent
This pattern is theoretically coherent within the \textit{Social Intuitionist Model} of moral judgment~\cite{Haidt2001, HaidtBjorklund2008, Cushman2013}, which holds that moral behaviour is driven primarily by rapid, affect-laden intuitions rather than by reflective cost–benefit deliberation~\cite{Greene2001, Greene2002, Moll2005}. Under this model, the Watching Eye stimulus shapes behaviour because it elicits immediate, intuitive appraisals of reputational accountability. Our findings indicate that NAO’s ambiguous ontology disrupts this intuitive pathway: for individuals in the \textit{Prosocial–Empathic} profile—whose evaluative architecture relies heavily on affective resonance and interpersonal attunement—the robot’s presence refracts moral salience away from the poster, thereby reducing the likelihood that intuitive concern is translated into donation behaviour. For the \textit{Analytical–Structured} and \textit{Emotionally Reactive} profiles, whose evaluative dynamics depend respectively on rule-based structure or affective volatility, the robot registers as normatively inert or affectively irrelevant, leaving donation patterns largely unaffected.

\noindent
These results therefore support an intuitionist, rather than rationalist, interpretation of moral action in this environment. The attenuation effect does not emerge as a failure of explicit reasoning, but as a deformation of the intuitive evaluative processes that precede it. In topological terms, $\mathscr{R}$ alters the curvature of the moral field: it bends the trajectories along which intuitive appraisals propagate, thereby shifting the probability that moral cues achieve behavioural expression. At the operative \emph{Level of Abstraction}~\cite{Floridi2008, Floridi2010, Floridi2013}, the robot functions as a semiotic intrusion—an entity whose perceived ontology modifies what the agent treats as salient, credible, or normatively relevant.

\noindent
From a methodological perspective, this interpretation has direct implications for the study of moral cognition. If moral behaviour is mediated by affectively grounded intuitions that are sensitive to environmental structure, then behavioural traces—such as donation decisions—become legitimate datasets for inferring moral evaluations. This aligns with the premises of \textit{Social Signal Processing}~\cite{Vinciarelli2009, Vinciarelli2012} and \textit{Affective Computing}~\cite{Picard1997, CalvoDMello2010}, which treat observable behaviour as an informational interface through which latent cognitive–affective states may be estimated, modelled, and formalised. The present findings demonstrate that synthetic co-presence can systematically reshape this interface: by altering the distribution of intuitive salience, the robot modifies the behavioural signatures from which moral inference is drawn.

\noindent
This also intersects directly with the ambitions of \textit{Machine Ethics}~\cite{Moor2006, FloridiSanders2004, AndersonAnderson2007, Coeckelbergh2010}, which seek to formalise the conditions under which artificial systems may (or may be perceived to) participate in moral contexts. Our results show that even non-interactive robots can perturb moral cognition simply by being \emph{present}—suggesting that artificial agents need not act, speak, or decide in order to exert normative influence. Their moral relevance may emerge from their mere ontological profile, as processed through the observer’s cognitive ecology.

\noindent
In this respect, the experiment provides an empirically grounded demonstration that \textbf{synthetic presence can deform the moral field}, not by commanding behaviour, but by bending the intuitive pathways through which moral meaning becomes action. Moral cognition is revealed as both structurally sensitive to ontological ambiguity and computationally tractable through the behavioural signatures it leaves behind. This establishes a promising bridge between empirical moral psychology, formal models of moral topology, and the computational disciplines—Social Signal Processing, Affective Computing, and Machine Ethics—that seek to analyse, predict, or ethically regulate human–machine moral ecosystems.

\subsection{Final Synthesis: Moral Topology, Synthetic Presence, and the Limits of Machine Ethics}

\noindent
Taken together, the behavioural, inferential, and Bayesian results presented in this chapter yield a coherent and theoretically significant picture of how synthetic presence modulates human moral behaviour. The NAO robot’s inclusion—silent, minimally animated, ontologically indeterminate—functions not as an agent issuing commands, nor as a passive background object, but as a \emph{semiotic perturbator} that reorganises the interpretive topology through which moral salience becomes behaviourally actionable.

At the behavioural level, we observed a clear attenuation of prosocial donation in the Robot condition. At the aggregate scale, the attenuation is statistically identifiable; at the individual level, Bayesian estimation reveals a skewed but uncertain probability distribution favouring reduced prosocial output. Cluster-specific analyses show that this attenuation is far from uniform: it is concentrated within the \textbf{Prosocial–Empathic} profile, muted within the \textbf{Analytical–Structured} profile, and largely absent within the \textbf{Emotionally Reactive} profile. These findings reinforce the core claim that robotic presence refracts moral salience through \emph{trait-dependent evaluative topologies} rather than altering behaviour in a direct, causal, or homogeneous manner.

From the standpoint of the \textit{Social Intuitionist Model} of moral judgment~\cite{Haidt2001,Greene2001,Cushman2013}, this pattern is theoretically coherent. Moral action, in this model, is driven primarily by rapid, affectively grounded intuitions rather than reflective deliberation. Our charity poster—operationalising the Watching Eye stimulus—serves precisely as such an intuitive moral prime, designed to trigger empathic concern and reputational awareness. Yet the robot’s ambiguous presence dilutes this intuitive channel: the locus of social attention partially shifts from the moral cue to the synthetic body occupying the room, thereby weakening the intuitive pull that ordinarily supports prosocial donation. In topological terms, $\mathscr{R}$ alters the local curvature of the moral field, redirecting the intuitive flows along which salience is converted into action.

This interpretation is strengthened by Floridi’s theory of \textit{Levels of Abstraction}~\cite{Floridi2008,Floridi2010}. At the operative LoA of the participant, the robot is encoded not as a machine, nor as a full moral agent, but as an entity whose perceptual affordances (eyes, posture, subtle motion) activate anthropomorphic priors without fulfilling the semantic criteria for agency. In this sense, $\mathscr{R}$ occupies a liminal ontological position: too animate to be ignored, not animate enough to be treated as an intentional other. The deformation we observe is thus a \emph{semantic deformation}, produced by a presence that inserts ambiguity into the participant’s perceptual-moral ecology.

This result has substantial implications for the study of moral cognition. First, it provides empirical support for the thesis that \textbf{moral meaning is environmentally scaffolded}: small shifts in perceptual context can reorganise the evaluative machinery that underpins prosocial action. Second, it demonstrates that \textbf{moral behaviour is accessible through behavioural signatures}, a fact that aligns with the methodological aims of Social Signal Processing~\cite{Vinciarelli2009} and Affective Computing~\cite{Picard1997}. If moral action can be systematically perturbed by manipulating environmental affordances—including synthetic presences—then moral reasoning becomes partially tractable through the modelling of behavioural traces, opening the door to computational approaches for mapping moral intuition as a dynamic, context-sensitive process.

\medskip
\noindent\textbf{A Critical Note on Machine Ethics.}  
The present findings also cast a critical light on the current state of Machine Ethics. Much of the Machine Ethics literature has historically been driven by the ambition to design “ethical agents” endowed with explicit moral rules, reasoning procedures, or decision architectures~\cite{Moor2006,Anderson2011,Boddington2017}. In the era of LLMs, this ambition has often been rearticulated as the attempt to “align” models with moral norms via fine-tuning datasets, reinforcement feedback, or rule-based guardrails.

Yet the empirical evidence presented here strongly suggests that \textbf{such approaches misunderstand the locus of moral influence}.  
Synthetic systems influence human moral behaviour not by engaging in propositional reasoning or ethical deliberation, but by subtly reshaping the perceptual and normative topology of the environments in which humans act. Their moral impact is \emph{interpretive, affective, and topological}, not rule-based, representational, or algorithmic. A robot that barely moves can dilute intuitive moral cues; an LLM that outputs contextually structured language can shift a user’s evaluative frame long before any explicit reasoning occurs.

In this light, the classical project of Machine Ethics—focused on the construction of explicit, internally encoded ethical principles—appears increasingly inadequate. It offers no tools for capturing the kind of \textbf{ambient moral modulation} demonstrated here, and provides little insight into how synthetic entities shape moral cognition not through agency but through presence, salience, and interpretive displacement. In the context of LLMs, whose moral influence operates primarily at the level of framing, narrative structure, and socio-informational priming, this limitation becomes starkly visible. A model’s ethical behaviour cannot be reduced to its output rules; it must be understood in terms of the cognitive topologies it induces in its users.

\medskip
\noindent\textbf{Synthesis.}  
The experiment thus demonstrates three consequences of immediate relevance to contemporary moral psychology and AI ethics:

\begin{enumerate}
	\item \textbf{Moral behaviour is topologically modulated.}  
	The presence of a synthetic agent reshapes the evaluative terrain through which moral salience is processed, producing measurable behavioural effects.
	
	\item \textbf{This modulation is trait-dependent.}  
	The Prosocial–Empathic profile is most susceptible to attenuation; the Analytical–Structured and Emotionally Reactive profiles exhibit greater topological resilience.
	
	\item \textbf{Machine Ethics must fundamentally reconceive its object.}  
	Ethical AI cannot be meaningfully approached through rule-lists or moral logics alone. It must instead account for the subtle ways in which artificial systems reorganize human evaluative architectures at the perceptual, affective, and intuitive levels.
\end{enumerate}

\noindent
In closing, this chapter provides an empirically grounded demonstration that \textbf{synthetic presence can deform the moral field}, not by reasoning, commanding, or acting, but by bending the intuitive pathways through which moral meaning becomes behaviour. The implications extend far beyond robotics: they compel a reconceptualisation of how artificial systems participate in, perturb, and co-structure the topology of human moral cognition.


\subsection{Synthesis: Moral Topology, Synthetic Presence, and the Limits of Machine Ethics}

\noindent
The empirical and formal work developed in this chapter allows us to return to Question~\ref{q:robot-agent} with a more determinate answer. The evidence now supports the following claim: \textit{the silent co-presence of a humanoid robot can, under specific psychological configurations, attenuate the conversion of morally salient cues into prosocial action}. This attenuation is modest in magnitude, probabilistic rather than deterministic, and concentrated within particular evaluative regimes—most notably the Prosocial–Empathic profile—yet it is real, structured, and epistemically tractable.

\noindent
Topologically, the NAO robot functions as a local deformation of the moral field. The charity poster depicting a child in need, originally introduced as a canonical Watching Eye stimulus, constitutes an affectively loaded attractor in the evaluative landscape: under ordinary circumstances, it pulls intuitive appraisals towards prosocial donation through mechanisms of reputational concern, empathic resonance, and implicit monitoring~\cite{HaleyFessler2005,Bateson2006,ContyGeorgeHietanen2016}. Our results indicate that the introduction of $\mathscr{R}$ partially redistributes this moral salience. For participants in the Prosocial–Empathic regime, the robot operates as a competing focus of attention and an ontologically ambiguous social cue; the intuitive channel that would normally connect the poster to donation behaviour is weakened, re-routed, or locally disrupted.

\noindent
This pattern aligns with Social Intuitionist accounts of moral judgement, according to which moral action is driven primarily by fast, affect-laden intuitions, with explicit reasoning playing a largely post-hoc justificatory role~\cite{Haidt2001,Greene2001,Cushman2013}. In this frame, the Watching Eye effect is not a matter of explicit calculation but of intuitive salience. The robot’s presence does not ``argue against'' giving; rather, it changes what is experientially foregrounded as normatively relevant. For those whose moral cognition is heavily scaffolded by empathic and reputational cues, NAO’s ambiguous status as quasi-agent and quasi-object suffices to dilute the intuitive force of the poster. For the Analytical–Structured profile, by contrast, the same presence appears to be normatively inert, processed more as a stable environmental feature than as a moral signal. The experiment thus vindicates an ecological, intuitionist interpretation of moral modulation: synthetic presence bends the trajectories of intuitive appraisal rather than intervening at the level of explicit principle application.

\noindent
Floridi’s theory of Levels of Abstraction (LoA) provides the metaphysical and methodological vocabulary to articulate this deformation~\cite{Floridi2008,Floridi2010,Floridi2013}. At the operative LoA of the participant, NAO does not appear as a set of internal states or source code, but as a semiotic bundle: body, gaze, posture, micro-movements. These features instantiate \emph{semantic affordances} that are picked up by different evaluative ecologies in different ways. For the Prosocial–Empathic regime, the robot is encoded as a kind of morally pregnant presence that competes with the child’s image for attentional and normative priority; for the Analytical–Structured regime, the same presence is filtered as structurally irrelevant to the donation decision. The experiment thus realises, in a controlled setting, Floridi’s claim that artefacts can acquire moral salience via their informational role, without being moral agents in any robust sense~\cite{Floridi2013}. NAO is not a locus of \emph{moral agency} here; it is a perturbation in the \emph{informational environment} that reconfigures the mapping from salience to action.

\noindent
Framed in this way, the present study also exposes a set of limitations in the prevailing discourse of \emph{Machine Ethics}. Much of that literature has centred on the design of explicitly ``moral'' or ``ethical'' machines—systems that implement deontological rules, compute consequences, or learn norms, in order to make or justify decisions in ethically acceptable ways~\cite{Allen2006,Wallach2008,Moor2006,Moor2011,Moor2023}. In its canonical formulations, machine ethics presupposes a relatively sharp boundary between human users and artificial moral agents, and locates the core normative challenge in the internal architecture of the latter. Our findings suggest that this focus is, at best, incomplete.

\noindent
First, the experimental results show that synthetic systems can exert morally relevant influence \emph{without} possessing any explicit ethical architecture at all. NAO neither represents moral principles nor optimises outcomes; it simply occupies space, moves minimally, and is seen. Yet this is sufficient to alter the aggregate pattern of prosocial giving, and to do so selectively across latent cognitive--affective regimes. A research agenda that concentrates on endowing machines with codified moral theories, while neglecting their role as perturbative presences within human evaluative topologies, risks a kind of \emph{conceptual hollowing}: the label ``machine ethics'' is retained, but the most pervasive moral effects of machines—those mediated through human intuition and social cognition—are left untheorised~\cite{Allen2006,Wallach2008,Floridi2013}.

\noindent
Second, the canonical architectures of machine ethics were developed with relatively transparent, modular systems in mind: rule-based agents, deliberative planners, or learning systems whose internal representations could, in principle, be inspected and constrained~\cite{Wallach2008,Winfield2019,Santoro2018}. Contemporary large language models, recommender systems, and socio-technical platforms do not fit this template. As Coeckelbergh has argued, current AI increasingly generates \emph{simulacra of ethical deliberation}: outputs that \emph{look} like moral reasoning, yet lack robust ties to accountability, context, or genuine normative commitment~\cite{Coeckelbergh2023}. In such an environment, the question ``how do we encode ethics into a machine?'' becomes technically underdetermined and politically misleading. What our data illustrate instead is a different, and arguably more urgent, question: \textit{how do artificial systems and environments shape the informational fields within which human moral cognition operates?}

\noindent
Third, the experiment suggests a reorientation of methodological priorities. Rather than treating moral content as something to be injected into artificial agents, we can treat moral behaviour as an empirically tractable outcome of norm-sensitive informational ecologies. Within this reconceptualisation, tools from Social Signal Processing and Affective Computing become central: they treat behaviour, interaction patterns, and expressive cues as data structures from which latent evaluative states can be inferred~\cite{Vinciarelli2009,Picard1997}. Our findings show that the same apparatus can be used not only to analyse human moral action, but to detect and quantify how that action is modulated by synthetic co-presence. The relevant question for machine ethics then becomes not ``what principles shall we encode?'', but ``how do specific technological affordances reshape the signal-to-inference mapping through which moral salience becomes behaviour?''

\noindent
Taken together, the chapter’s results therefore support a shift from \emph{agent-centric machine ethics} to an \emph{ecological ethics of synthetic presence}. The NAO robot, as deployed here, is not a moral agent to be judged, but a designed perturbation that reveals structural vulnerabilities in human evaluative systems. Its impact is LoA-dependent, personality-contingent, and epistemically graded. For an ethics of AI and robotics that aspires to be both philosophically serious and empirically grounded, the appropriate research goal is not the engineering of artificially virtuous minds, but the mapping and regulation of the moral topologies in which human and artificial systems are jointly embedded~\cite{Floridi2013,DeBrigard2021,Malle2016}. In this sense, the experiment does not solve the problem of machine ethics; it reframes it. Rather than asking whether robots can be moral, it asks how their mere presence redistributes moral salience, and how such redistributions can be measured, understood, and normatively governed in a world increasingly saturated with synthetic others.

%%%THE END!!!

