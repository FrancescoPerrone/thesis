\chapter{General Synthesis}
\label{chap:general_discussion}

\section{Introduction: Why the Experiment Requires a Structural Interpretation}

The preceding chapters developed three interconnected strands: (i) a cognitive–affective account of moral judgment, (ii) a normative–philosophical reconstruction of ethical theory through the lenses of Level-of-Abstraction discipline and evaluative topology, and (iii) an empirical demonstration that robotic co-presence systematically attenuates prosocial donation under morally salient conditions. 

\noindent
Before turning to the integrative task, it is necessary to articulate the
higher-order insight guiding the trajectory of this thesis. Situated within the
cognitive, philosophical, and formal analyses of the preceding chapters, the
empirical study indicates that \textit{moral decision-making is, at root, a
	practical phenomenon}, grounded in the structures of agency and practical
reason \cite{Anscombe1957,Korsgaard2009,Wallace2020,Audi2015,Hursthouse1999}.
Moral events are not abstract judgements suspended in conceptual space; they are
situated transitions from perception to action embedded in a socially organised
environment, consistent with empirical models that treat moral cognition as
perceptual, affective, and socially modulated \cite{Haidt2001,Cushman2013,Young2012,Buon2016,Fedyk2017}.
Because such events culminate in observable behavioural outputs, they are
empirically tractable and available to systematic measurement and analysis
\cite{ReisJudd2000,Kazdin2017,RosenthalRosnow2008}. Their structural and
methodological precision is rarely recognised in the prevailing discourse of
Machine Ethics and Computational Morality, which has long been criticised for
its limited integration of empirical findings \cite{Moor2006,Wallach2008,Cervantes2020,Coeckelbergh2023}.

This sequence is methodologically significant. Across both philosophy and moral
psychology, ethical inquiry typically proceeds not by legislating the quality of
actions from a priori first principles, but by beginning with the existence of 
\textit{moral events} themselves—episodes in which agents respond to cues, 
saliences, and social affordances—and then seeking theoretical structures that 
best explain these patterns of behaviour 
\cite{Hursthouse1999,Audi2015,Richardson2018,Doris2010,Haidt2007}. 
This bottom-up orientation stands in sharp contrast to much of the historical
trajectory of Machine Ethics, which has principally advanced top-down models
that attempt to encode or implement normative theories prior to securing an
empirical understanding of how moral cognition unfolds in practice.

A large body of Machine Ethics scholarship exemplifies this top-down,
normative-first orientation. Early and influential work sought to engineer
explicit ethical rules or principles for artificial agents~\cite{Moor2006,Wallach2008,Anderson2011}, often drawing upon deontological,
utilitarian, or virtue-theoretic frameworks whose normative structure was taken
as directly implementable in computational systems~\cite{Arkin2009,Lin2008,Atkinson2007,Atkinson2006,Hjelmblom2008,Horn1951, Kowalski1976}. Subsequent developments reinforced this tendency by constructing logical architectures intended to represent moral constraints, permissibility conditions, or value hierarchies independently of empirical models of human moral agency~\cite{Pereira2014,Honarvar2009,Battaglino2013,Sergot2007,Montague1975,Carnap2012}. Even approaches motivated by psychological plausibility, such as computational models of ethical reasoning~\cite{McLaren2006,Guarini2006,Pereira2007b}, largely inherit the same structural assumption that normative content can be specified in advance of empirical measurement.

Critiques of this methodological inversion are now widespread. Authors working
within both ethics of AI and social-robotics research argue that designing moral
agents without grounding in empirical evidence about cognition, affect, social
interaction, or developmental patterns of moral behaviour is epistemically
unstable and risks constructing systems whose ‘moral’ outputs lack psychological
validity~\cite{Cervantes2020,Nath2020,Mcdermid2019,Howard2017, Coeckelbergh2023,Moor2023}. On these accounts, moral behaviour cannot be
treated as an externally specifiable target for implementation; rather, it
emerges from structured interactions among cognitive, affective, embodied, and
social-signalling processes~ \cite{Decety2004,Buon2016,Pantic2014,Pentland2007,Fedyk2017}. These processes
must therefore be empirically characterised before any attempt at normative
codification. Only through such empirically informed grounding can normative
theory enter the analysis in a methodologically stable and scientifically
responsible manner.

The present work therefore advances a methodological reversal. It shows that
moral salience, moral displacement, and the perturbation of prosocial behaviour
are empirically measurable phenomena that \textit{must} be mapped before being
codified, an approach supported by behavioural studies of attentional and
prosocial modulation \cite{HaleyFessler2005,Bateson2006,Dear2019,Greene2001,Cushman2013,Decety2008}.
Because these phenomena are embedded within attentional, affective, and
dispositional architectures, they admit rigorous experimental design,
statistical modelling, and formal reconstruction \cite{ReisJudd2000,Kazdin2017,GriffithsBeake2022}.
Accordingly, the experimental study is not an auxiliary illustration but the
epistemic anchor of the thesis. Only once the structure of moral events is
empirically established can normative theory enter the analysis—precisely the
reverse of the methodological sequence characteristic of Machine Ethics,
normative-first LLM evaluation, and much of Affective Computing
\cite{Moor2006,Wallach2008,Bender2021,Mittelstadt2019,Whittlestone2019,Picard2000Book,Calvo2015}.

\noindent
The task of the present chapter is not to repeat these analyses, but to integrate them. It offers a theoretical synthesis that explains \emph{why} the experimental effect occurs, \emph{what} its ethical significance is, and \emph{how} it reshapes the methodological landscape for research in Human–Robot Interaction, moral psychology, and the emerging field of Computational Morality.

\noindent
In this sense, the experiment is not an isolated behavioural result but a \textit{probe} into the architecture of moral cognition. The observed attenuation of prosocial behaviour is theoretically meaningful only when interpreted through the structures developed earlier: dual-process architectures, the Social Intuitionist Model, evaluative topology, and the reconstructed normative frameworks of deontology, consequentialism, virtue ethics, sentimentalism, contractualism, and particularism. The present chapter therefore provides a synoptic interpretation in which the behavioural signature revealed by the data becomes a lens through which the nature of moral cognition—and its vulnerability to perturbation—is rendered theoretically transparent.

\subsection{From Behaviour to Structure: Why a Higher-Level Interpretation is Required}

\noindent
The experimental paradigm—Watching-Eye moral cue embedded within a silent synthetic presence—does not merely generate a difference in donation behaviour; it reveals a deformation of the evaluative field that links moral salience to action. Classical interpretations of donation differences (e.g., generosity, altruism, compliance) lack the conceptual resources to capture this phenomenon. A purely behavioural description would record that participants donated less in the Robot condition, with the Prosocial–Empathic cluster showing the numerically steepest decline. But such a description omits the structural logic that makes the result scientifically and philosophically significant.

\noindent
The central claim developed throughout the thesis is that \emph{moral behaviour is not invariant under changes to the perceptual–social environment}. The robot’s presence does not overwrite moral norms nor impose new ones; instead, it modifies the cognitive–affective conditions under which evaluative forces act. It shifts attentional allocation, alters affective resonance, and modifies the perceived sociality of the space. In topological terms, the robot introduces a perturbation $\gamma_R$ that deforms the curvature of the evaluative manifold, thereby weakening the salience gradient induced by the Watching-Eye stimulus.

A simple behavioural difference thus reflects a deeper structural transformation in the evaluative field. As demonstrated by the regression models and Bayesian estimation, the attenuation effect was uniform in direction across participants, indicating that the perturbation introduced by the robot operates at the field level rather than through trait-specific pathways. Yet this uniformity does not imply psychological homogeneity.The PCA–$k$-means clustering revealed three coherent dispositional ecologies—distinct configurations of empathic resonance, affective volatility, and structural–analytical processing. These ecologies are consistent with the established dimensions of empathizing and systemizing~\cite{BaronCohen2003}, personality variation captured by the
BFI-10 \cite{Rammstedt2007}, and broader accounts of moral-psychological “ecologies” that organise evaluative processing \cite{Fedyk2017,Haidt2001}:

\begin{itemize}
	\item the \textbf{Emotionally Reactive / Low-Structure Profile},
	\item the \textbf{Prosocial–Empathic / Warm–Sociable Profile},
	\item the \textbf{Analytical–Structured / High-Systemizing Profile}.
\end{itemize}

\noindent
These clusters instantiate different evaluative topologies—distinct attractor formations, sensitivities to perceptual and affective salience, and pathways of modulation—consistent with multidimensional models of affective valuation and moral cognition~\cite{Churchland2011,Nussbaum2001,Greene2004,Haidt2001}. Within this framework, the Prosocial–Empathic cluster exhibits the steepest affective gradients and the strongest baseline responsiveness to Watching-Eye cues. This ecological structure aligns with theoretical expectations: Watching-Eyes primes amplify empathic accountability~\cite{Francey2012,Kawamura2017}, and empathic resonance is known to be highly sensitive to contextual modulation~\cite{Zaki2012}.

\noindent
That this cluster nevertheless showed the same directional attenuation as the others is therefore theoretically significant. Rather than reflecting a trait-dependent shift, the humanoid robot’s ambiguous social presence perturbs the salience structure itself, weakening the amplification mechanisms on which empathic ecologies depend~\cite{Malle2016}. In other words, the perturbation operates \emph{upstream} of individual dispositional pathways: it modifies the evaluative field within which those pathways are embedded. The displacement observed in the experiment is thus best understood as a \emph{field-level suppression of moral salience}, overriding the ordinarily divergent dispositional trajectories that shape prosocial behaviour.

\bigskip
\noindent
\textbf{Ethical Interpretation: Why the Attenuation Matters Normatively.}  
The ethical significance of this finding becomes visible only when the result is interpreted through the reconstructed normative frameworks developed in Chapter~\ref{chap:ethics_s}. Each theory identifies a different locus of normative structure, and each provides a distinct—yet convergent—reading of the deformation caused by $\mathscr{R}$:

\begin{itemize}
	\item \emph{Deontological perspective.}  
	The Watching-Eye cue implicitly invokes deontic expectations of reciprocity, fairness, and beneficence. The robot’s presence attenuates donation precisely by dulling this sensitivity. Normatively, this appears as a disruption of the agent’s capacity to track \emph{ought-constraints} in the environment—an interference with the cognitive substrate on which deontic responsiveness relies.
	
	\item \emph{Consequentialist perspective.}  
	The moral field includes gradients of anticipated social evaluation. Watching-Eye cues steepen these gradients; synthetic presence flattens them. The robot therefore functions as a \emph{gradient-suppressor}, reducing the perceived payoff of prosocial action. In topological terms: it alters the vector field governing welfare-oriented trajectories.
	
	\item \emph{Virtue-ethical perspective.}  
	The three clusters correspond to differing dispositional configurations. The strongest attenuation occurring within the Prosocial–Empathic cluster implies that the robot disrupts precisely those virtues—empathy, warmth, prosocial orientation—that ordinarily stabilise prosocial attractors. The perturbation thus interacts with \emph{character topology} rather than bypassing it.
	
	\item \emph{Sentimentalist (Humean) perspective.}  
	The attenuation reflects a dampening of empathic vector fields: $\delta \mathbf{A}(x;\mathscr{R}) < 0$. The robot selectively reduces affective resonance with the Watching-Eye cue. Normatively, this implies that the moral valence of the situation is felt less intensely, weakening the motivational energy required for prosocial action.
	
	\item \emph{Contractualist perspective.}  
	The moral event of donation under observation involves tacit justifiability relations: “What could reasonably be expected of me in the eyes of others?” The ambiguous presence of a synthetic observer destabilises this justificatory equilibrium. The subject no longer clearly apprehends \emph{to whom} justifiability is owed.
	
	\item \emph{Particularist perspective.}  
	Moral appraisal depends on local saliences. The robot modifies the salience landscape: the morally relevant cue (the child in need) becomes less perceptually dominant. Thus, the attenuation is interpreted as a shift in the pattern of reasons that obtain in this particular context.
\end{itemize}

\bigskip
\noindent
\textbf{LoA Interpretation: Why the Perturbation Occurs at the Wrong Level for Machine Ethics.}  
Floridi’s Level-of-Abstraction analysis clarifies the structural error revealed by the experiment. The attenuation does \emph{not} occur at the normative LoA (where duties, values, or justifiability live), but at the cognitive–affective LoA (where salience, resonance, and attention are regulated). Machine Ethics traditionally operates at the wrong LoA: it attempts to implement high-level normative constructs while ignoring the low-level substrates on which moral responsiveness depends.

\noindent
The experiment shows why this is untenable. Ethical responsiveness is mediated by:
\begin{itemize}
	\item attentional allocation (Who or what do I notice?)
	\item affective resonance (What emotional weight does this carry?)
	\item perceived social ontology (Who counts as the observer?)
	\item dispositional pathways (How does my cognitive ecology integrate this cue?)
\end{itemize}

\noindent
Synthetic presence perturbs all of these upstream mechanisms. Thus, even perfect normative reasoning at a reflective LoA cannot salvage moral action when the lower-level architecture of moral cognition has been deformed.  
In Floridi’s terms:

\begin{quote}
	\emph{Normative correctness is orthogonal to causal efficacy. A system may know what is right and yet fail to act rightly if the cognitive LoA is perturbed.}
\end{quote}

\bigskip
\noindent
\textbf{Integrative Insight.}  
The field-level suppression observed in the experiment therefore reveals a principle of broad ethical and psychological importance:

\begin{quote}
	\textit{Moral failure under synthetic presence is not a failure of principle but a failure of salience. Ethical norms lose their grip not because agents reject them, but because the evaluative machinery that normally brings them to bear is disrupted.}
\end{quote}

\noindent
This insight is the conceptual hinge on which the whole thesis turns. It unifies:
\begin{itemize}
	\item the cognitive architecture (moral judgments arise from salience → appraisal → integration),
	\item the topological formalism (moral cues define gradients and attractors),
	\item the normative frameworks (moral theories describe different structural aspects of the evaluative field),
	\item and the empirical results (synthetic presence suppresses these structures at the field level).
\end{itemize}

\noindent
With these interpretive tools in place, we can now proceed to the cluster-by-cluster integrative analysis that further refines the ethical and cognitive significance of the experimental findings.



\subsection{Why This Chapter Cannot Be Pure “Discussion” in the Conventional Sense}
\noindent
Traditional discussion chapters in empirical theses typically emphasise methodological limitations, alternative interpretations, and directions for future work. While such elements remain relevant here, they are insufficient for the present project. The experiment developed in this thesis sits at the intersection of cognitive science, social robotics, computational modelling, and normative ethics. The behavioural effect it reveals—reduced prosocial donation under synthetic co-presence—is only the observable trace of a deeper structural transformation: a perturbation of the evaluative machinery through which agents convert moral salience into action. Because this transformation engages multiple theoretical layers—cognitive–affective processing, dispositional topology, normative interpretation, and Level-of-Abstraction analysis—a standard discussion section cannot capture its full conceptual significance. What is needed instead is a structural synthesis that explains not merely \emph{what} happened, but \emph{why} it happened and \emph{what it reveals} about the nature of moral cognition and its vulnerability to synthetic perturbation.

\noindent
To articulate this phenomenon requires a conceptual integration that cannot be confined to standard “discussion” categories. Instead, the chapter must synthesise:
\begin{enumerate}
	\item the \textbf{cognitive architecture} (dual-process, SIM, dynamic integration);
	\item the \textbf{evaluative geometry} (topology, curvature, gradient flow);
	\item the \textbf{normative reconstruction} (deontic invariants, consequentialist gradients, dispositional attractors, sentimentalist vector fields, contractualist justificatory structure, and particularist salience responsiveness);
	\item and the \textbf{empirical structure} of the data (cluster-specific susceptibility, Bayesian attenuation, topological deformation of the Watching-Eye effect).
\end{enumerate}

\noindent
The present chapter therefore functions as an \emph{interpretive pivot}: it translates the empirical findings into philosophical insight, and reinterprets philosophical frameworks in light of empirical constraints.

\subsection{A Structural Reading of the Core Experimental Result}

\noindent
The empirical pattern can be summarised as follows:
\begin{itemize}
	\item The humanoid robot NAO is perceptually salient but ontologically ambiguous.
	\item The Watching-Eye cue ordinarily induces an empathic salience gradient that increases donation.
	\item The robot introduces a perturbation $\gamma_R$ that competes with, and partially overrides, this empathic amplification.
	\item Attenuation is strongest in the Prosocial–Empathic cluster, weaker in the Analytical–Structured cluster, and statistically negligible in the Emotionally Reactive cluster.
\end{itemize}

\noindent
Interpreted through the cognitive framework developed earlier, this pattern shows that moral appraisal begins with intuitive and affective resonance \cite{Haidt2001,Greene2001}. Synthetic presence disrupts this resonance by altering attention, salience, and perceived sociality \cite{Phelps2006,Zaki2012,Malle2016,Bremner2022}. Different dispositional structures absorb this disruption in systematically different ways, consistent with established dimensions of empathizing, systemizing, and moral-schema variability \cite{BaronCohen2003,Narvaez2005}. The resulting behavioural output reflects not a change in moral principle, but a deformation of the evaluative field.

\noindent
Interpreted through the normative framework, the same pattern yields multiple structurally coherent readings:
\begin{itemize}
	\item a \textbf{deontological reading}: synthetic presence weakens the implicit deontic expectations cued by the Watching-Eye stimulus \cite{Korsgaard1996};
	\item a \textbf{consequentialist reading}: synthetic presence flattens the perceived payoff gradient of helping behaviour \cite{Mill1863};
	\item a \textbf{virtue-ethical reading}: synthetic presence suppresses prosocial attractors associated with empathic or cooperative dispositions \cite{Hursthouse1999};
	\item a \textbf{sentimentalist reading}: synthetic presence dampens empathic vector fields that ordinarily drive prosocial action \cite{Slote2010};
	\item a \textbf{contractualist reading}: synthetic presence destabilises the justificatory relations normally activated by social observation \cite{Scanlon1998};
	\item a \textbf{particularist reading}: synthetic presence alters the salience pattern such that the Watching-Eye cue no longer carries the same moral significance \cite{Dancy2004,McDowell1979}.
\end{itemize}

\noindent
Thus, each normative theory yields a structurally distinct but empirically convergent interpretation. The ethical significance of the experiment lies not in any single framework, but in the \emph{coherent intersection} of all of them: a field-level suppression of moral salience, a deformation of the evaluative topology through which moral meaning becomes action.

\subsection{Why the Synthetic Presence Effect Matters Beyond the Experiment}

\noindent
The attenuation of moral action under synthetic presence is not merely an interesting behavioural anomaly; it demonstrates a deeper principle: \emph{moral cognition is structurally permeable}. It is sensitive to perturbations that operate below the level of explicit reasoning. It is vulnerable to shifts in perceived social ontology. And it is modulated by affectively weighted cues whose influence is seldom acknowledged in normative theory and almost never incorporated in classical Machine Ethics.

\noindent
This has far-reaching implications:
\begin{enumerate}
	\item It challenges the assumption that artificial agents can be designed according to purely deliberative ethical frameworks.
	\item It shows that synthetic presence modulates moral behaviour even without action, speech, intent, or agency.
	\item It reveals that human–robot environments are \emph{ethically loaded} by virtue of perceptual and affective structure alone.
	\item It demands a reconsideration of how artificial systems are situated within the moral ecology of human decision-making.
\end{enumerate}

\noindent
In short, the experiment demonstrates a fact of philosophical significance: \textit{synthetic agents are not normatively inert}. Their presence, even in silent passivity, can deform the evaluative pathways through which moral salience becomes action.

\bigskip

\noindent
The remainder of this chapter builds on this foundation. Subsequent sections provide:
\begin{itemize}
	\item a cluster-by-cluster integrative interpretation,
	\item a cross-framework normative synthesis,
	\item a critique of monolithic Machine Ethics,
	\item a reconstruction of Computational Morality grounded in empirical structure,
	\item and a final consolidation of the thesis’ theoretical contributions.
\end{itemize}

\noindent
The goal is not only to interpret the experiment, but to show how the experiment reconfigures the conceptual terrain on which research in moral psychology, HRI, and Machine Ethics must proceed.

\section{Cluster-by-Cluster Integrative Interpretation}
\label{sec:cluster_interpretation}

\noindent
The experimental results demonstrate that robotic co-presence $\mathscr{R}$ induces a uniform directional attenuation of prosocial donation across participants, yet the \emph{structure} of this attenuation differs meaningfully across the three latent cognitive--affective ecologies uncovered in Chapter~\ref{chap:experimental_methods}. Because these clusters instantiate distinct evaluative topologies---different attractor formations, salience gradients, affective vector fields, and pathways of regulatory modulation---their differential perturbation under $\mathscr{R}$ offers insight into the architecture of moral cognition and the ethical significance of synthetic presence. What follows is an integrative interpretation weaving together the cognitive, topological, normative, and Level-of-Abstraction (LoA) analyses developed across the thesis.

% --------------------------------------------------------
\subsection*{Emotionally Reactive / Low-Structure Ecology}

\noindent
This ecology exhibits high affective volatility, shallow structural integration, and weak systemizing constraints, consistent with established empathizing--systemizing variability \cite{BaronCohen2003}. Its evaluative topology is characterised by \emph{broad, low-gradient attractors}: intuitive responses are strong but unstable; attentional salience fluctuates; and the transition from perception to action is mediated by short-lived affective surges rather than sustained deliberative integration.

\noindent
To avoid terminological ambiguity, it is useful to clarify what is meant here by 
\emph{broad, low-gradient attractors} in the evaluative--topological framework. 
In dynamical-systems terms, an attractor represents a region of the evaluative field $\mathcal{E}$ toward which the system’s state $x$ naturally converges 
\cite{Strogatz1994,Beer1995}. A \emph{broad} attractor denotes a basin of attraction with  wide boundaries and weak curvature, meaning that many initial states can enter it but none are strongly pulled toward a particular behavioural endpoint. A \emph{low-gradient} attractor is one in which the magnitude of the evaluative gradient $\lVert \nabla \mathcal{E}(x)\rVert$ is small across the basin, implying that movement toward prosocial or antisocial trajectories is governed by shallow motivational forces~\cite{SmithThelen2003,Friston2010}.

\noindent
In psychological terms, this configuration corresponds to intuitive reactions that are easily triggered yet weakly stabilised: the agent may experience transient affective spikes (e.g., momentary empathy, irritation, or ambivalence) without these signals generating a consistent or directed behavioural tendency. This interpretation is consistent with empirical models of low-coherence affect, affective lability, and unstable salience allocation~\cite{Kuppens2010,Larsen1987,Hollenstein2015}. Because the evaluative landscape lacks sharply defined slopes, small perturbations---including those introduced by environmental ambiguity---tend not to produce substantial directional change. This explains why the Emotionally Reactive / Low-Structure ecology exhibited behavioural invariance in the experiment: the moral field was already characterised by diffuse attractors and unstable salience dynamics, leaving little structured curvature for $\mathscr{R}$ to deform.

\noindent
Within such a landscape, the experimentally observed pattern---minimal or noisy attenuation---is theoretically revealing. The Watching-Eye stimulus $\sigma_{\mathrm{WE}}$ generates only a modest prosocial gradient for this cluster \cite{Francey2012,Kawamura2017}, and the robot-induced perturbation $\gamma_R$ cannot significantly deform a field that already lacks curvature:
\[
\|\nabla \mathcal{E}_{\mathrm{baseline}}\| \approx 0 
\quad \Rightarrow \quad 
\|\nabla \mathcal{E}_{\mathrm{perturbed}}\| \approx 0.
\]

\noindent
At the cognitive LoA, this ecology functions as a near-critical system: its evaluative machinery exhibits little stability and thus provides minimal structural leverage for $\mathscr{R}$ to disrupt. Normatively, this implies that deontic, sentimental, or virtue-theoretic structures exert limited behavioural influence because the underlying evaluative field lacks the curvature to sustain them.

% --------------------------------------------------------
\subsection*{Prosocial--Empathic / Warm--Sociable Ecology}

\noindent
This cluster displays high empathic resonance, strong sensitivity to social cues, and rich affective attractors. Psychological models of empathic processing support this heightened salience responsiveness \cite{Phelps2006,Zaki2012}. Its evaluative topology is steeply sloped: the Watching-Eye cue generates strong upward gradients toward prosocial action \cite{Francey2012}, mediated by interpersonal appraisal and affective amplification.

\noindent
The robot’s ontological ambiguity \cite{Malle2016,Kuchenbrandt2011,Bremner2022} perturbs precisely this amplification mechanism. As demonstrated in Chapter~\ref{chap:experimental_methods}, the perturbation $\delta \mathcal{E}(x;\mathscr{R})$ acts \emph{upstream}, modifying the salience structure itself:
\[
\delta \mathcal{E}(x;\mathscr{R}) < 0,
\qquad 
\delta \mathbf{A}(x;\mathscr{R}) < 0.
\]

\noindent
Because the empathic system depends on affective curvature, flattening the field produces the \emph{largest attenuation} in this ecology despite its strong baseline gradients. 

\noindent
Normatively, this yields a convergent interpretation:
deontology registers weakened duty-tracking; consequentialism observes a flattened payoff gradient; virtue ethics identifies destabilised prosocial dispositions; sentimentalism finds dampened empathic force-fields; contractualism diagnoses disrupted justificatory orientation; and particularism detects a shift in which contextual features count as reasons.

% --------------------------------------------------------
\subsection*{Analytical--Structured / High-Systemizing Ecology}

\noindent
This ecology exhibits strong systemizing tendencies and comparatively lower empathizing \cite{BaronCohen2003}. Its evaluative topology is governed by structural coherence rather than affective curvature. Here, prosocial action arises from rule-consistency, interpretive stability, and contextually well-defined cues.

\noindent
The experiment reveals only mild attenuation. The Watching-Eye cue produces modest gradients, while $\mathscr{R}$ introduces representational and social-ontological ambiguity \cite{Komatsu2016}, subtly undermining the interpretive regularities on which this ecology relies. The perturbation operates primarily on semantic and predictive structure:
\[
\delta \mathcal{E}(x;\mathscr{R}) \approx 0^{-}, \qquad 
\delta \mathbf{A}(x;\mathscr{R}) \approx 0.
\]

\noindent
At the LoA level, this ecology demonstrates that perturbation need not be affective: synthetic presence also functions as a \emph{semantic disruptor}, altering the representational substrate needed for structured evaluative computation. Normatively, this corresponds to weakened rule-clarity (deontology), distorted outcome-modelling (consequentialism), and destabilised interpretive virtues such as discernment and practical wisdom (virtue ethics).

% --------------------------------------------------------
\subsection*{Integrative Synthesis}

\noindent
Across all three ecologies, a unified conclusion emerges: the humanoid robot operates not through communication, norm expression, or explicit social signalling, but through \emph{topological reconfiguration}. It introduces a perturbation $\gamma_R$ at the cognitive LoA that:

\begin{itemize}
	\item suppresses affective gradients in empathic ecologies,
	\item introduces semantic and predictive ambiguity in analytical ecologies,
	\item and interacts minimally with shallow attractor fields in reactive ecologies.
\end{itemize}

\noindent
Normatively, the attenuation is not a failure of duty, utility estimation, virtue, empathy, or justificatory reasoning. Instead, it represents a \emph{structural displacement of moral salience}. This displacement is invisible to explicit reasoning yet measurable in behaviour and interpretable through evaluative topology.

\noindent
In this sense, the humanoid robot reveals a property of moral cognition that classical ethical theory and classical Machine Ethics could not predict: \emph{moral responsiveness is field-sensitive}. Normativity becomes action only when the evaluative field retains its curvature. Perturb the field, and even well-formed dispositions cannot operate normally.

\noindent
This insight forms the conceptual hinge for the remainder of the General Discussion.

%===========================================================
% 3. GLOBAL NORMATIVE–TOPOLOGICAL SYNTHESIS
%===========================================================

\section{Global Normative--Topological Synthesis}
\label{sec:global_normative_synthesis}

\noindent
The final integrative step requires bringing together the three interpretive lenses that structure this thesis: (i) the \emph{topology} of moral cognition, (ii) the \emph{normative frameworks} reconstructed in the Ethical Cognition chapter, and (iii) the \emph{empirical perturbation} revealed by the experiment. The aim is not to select a single normative theory that “best explains’’ the data, nor to impose a moral verdict on participants’ behaviour. Rather, the task is to demonstrate how the experimental findings become theoretically intelligible \emph{only} when analysed at the correct Level of Abstraction (LoA), through a structure-sensitive account of evaluative dynamics.

\subsection*{Moral Behaviour as a Field-Level Phenomenon}

\noindent
Across deontological, consequentialist, virtue-theoretic, sentimentalist, and contractualist frameworks, one structural insight remains invariant: \textbf{moral action does not arise from isolated psychological modules or explicit rule execution}. Instead, it emerges from the configuration of the evaluative field---a relational structure shaped by perception, affect, social meaning, habituation, and normative commitments.

\noindent
The experiment demonstrates that this field is \emph{globally deformable}: a silent humanoid robot, devoid of agency, instruction, or communication, attenuates prosocial behaviour across all dispositional ecologies. This uniform directionality, combined with cluster-specific differences in amplitude, reveals a core computational insight:

\begin{center}
	\textbf{The presence of $\mathscr{R}$ acts as a field-level perturbation, not a trait-level driver.}
\end{center}

\noindent
In topological terms, the robot introduces a deformation operator
\[
\gamma_R : \mathcal{E} \to \mathcal{E}',
\]
which modifies the curvature of the evaluative manifold such that moral salience diffuses more weakly toward prosocial attractors. This accounts for both the global donation reduction and the heterogeneous susceptibility across ecologies.

\subsection*{Deontological, Consequentialist, and Virtue-Ethical Readings of the Perturbation}

\noindent
The experiment’s ethical significance becomes transparent when interpreted through the normative frameworks reconstructed earlier:

\begin{itemize}
	\item \textbf{Deontological interpretation:} The Watching-Eye cue implicitly invokes deontic norms of accountability and interpersonal respect. The attenuation of donation under $\mathscr{R}$ is thus intelligible as a deformation of the agent’s sensitivity to these constraints. The robot does not induce norm violation; it \emph{weakens the agent’s access} to deontic salience by altering the perceived sociality of the environment.
	
	\item \textbf{Consequentialist interpretation:} Watching-Eye cues are known to reshape the perceived consequence structure of prosocial acts. The robot’s ambiguous presence disrupts this gradient, flattening reputational and affective payoff structures. Donation decreases because the local value landscape is deformed, not because agents become less “ethical.”
	
	\item \textbf{Virtue-ethical interpretation:} The dispositional ecologies uncovered in the clustering analysis map directly onto virtue-ethical accounts of character as a structured, learned sensitivity to moral salience. $\mathscr{R}$ perturbs the field \emph{upstream} of these dispositions, weakening the operative mechanisms of moral perception, especially in the Prosocial–Empathic / Warm–Sociable profile.
\end{itemize}

\noindent
Each framework thus provides a different interpretive contour of the same phenomenon. But they converge on one central point: \textbf{the perturbation acts on the evaluative field, not on the moral principles themselves}. The agents’ normative commitments remain intact; what changes is the salience structure through which those commitments become behaviourally operative.

\subsection*{Sentimentalist, Contractualist, and Particularist Convergence}

\noindent
Sentimentalist theories construe moral judgment as an affective vector field. Under this lens, the robot acts as a dampening force on empathic resonance, decreasing the magnitude of affective gradients required to activate prosocial behaviour. Cluster-specific differences in attenuation severity become intelligible as differences in affective sensitivity and evaluative slope.

\noindent
Contractualist and justificatory theories interpret the perturbation as a shift in the perceived interpersonal structure of the environment. When $\mathscr{R}$ is present, participants implicitly alter their model of who counts as a moral interlocutor---a phenomenon well-documented in human--robot interaction literature. This recategorisation subtly modifies the justificatory landscape in which prosocial acts acquire meaning.

\noindent
Particularist and perceptualist theories emphasise moral \emph{attention}. On this view, the robot acts as a competing centre of salience, pulling attentional weight away from the Watching-Eye cue and thereby diluting the moral percept. This aligns precisely with the empirical finding of attenuated donation despite a strong moral prime.

\subsection*{Floridi’s Level-of-Abstraction Reading}

\noindent
Floridi’s LoA discipline allows us to state the integrative conclusion succinctly:

\begin{itemize}
	\item At the \textbf{cognitive LoA}, the robot perturbs perceptual-affective mechanisms (attention, salience, resonance).
	\item At the \textbf{behavioural LoA}, this perturbation manifests as reduced prosocial action.
	\item At the \textbf{normative LoA}, the agent’s ethical commitments remain unchanged, but the pathway by which they become operative is deformed.
\end{itemize}

\noindent
This avoids the two characteristic errors of Machine Ethics:
\begin{enumerate}
	\item treating normative principles as if they were generative psychological operators;
	\item treating behavioural shifts as if they were moral judgments.
\end{enumerate}

\subsection*{Integrative Conclusion: Moral Salience, Synthetic Presence, and the Architecture of Agency}

\begin{center}
	\begin{tcolorbox}[colback=white,colframe=black!60,title=Integrative Conclusion: The Ethical Significance of Synthetic Perturbation]
		\noindent
		The experiment demonstrates that synthetic presence can alter moral action not by introducing new norms or violating existing ones, but by reshaping the evaluative topology through which moral salience acquires behavioural force. Deontological constraints, consequentialist gradients, virtue-theoretic dispositions, sentimental vector fields, and contractualist justificatory demands all converge on the same structural insight: the moral field is deformable. The humanoid robot acts as a perturbation operator $\gamma_R$ on this field, weakening the pathways that normally lead from moral perception to prosocial action. This field-level deformation explains both the global attenuation effect and the cluster-specific signatures discovered in the experiment. It also reveals a fundamental limitation of classical Machine Ethics: normative content cannot be operationalised without an empirically grounded account of how moral cognition functions within its situational topology. The thesis therefore establishes a new methodological foundation for Computational Morality: synthetic agents must be analysed not merely as potential moral reasoners, but as operators on the moral ecology in which human agency unfolds.
	\end{tcolorbox}
\end{center}


\section{From the Failure of Machine Ethics to a Reconstruction of Computational Morality}
\label{sec:machine_ethics_failure_reconstruction}

\noindent
The preceding analyses show that robotic co-presence $\mathscr{R}$ induces a deformation of the evaluative field within which moral salience becomes action. This has direct implications for artificial moral agency and exposes a structural flaw in classical Machine Ethics. Since its inception, Machine Ethics has assumed that moral behaviour can be engineered by encoding ethical principles inside an artificial system---a view explicit in rule-based architectures \cite{Moor2006,Bringsjord2006}, utilitarian optimisation frameworks \cite{Arkin2009}, virtue-based computational agents \cite{Wallach2008}, and logic-driven decision systems \cite{Anderson2011,Pereira2014}. These approaches presuppose that normative theories function as \emph{implementable specifications}. However, as Floridi’s Levels of Abstraction make clear \cite{Floridi2008,Floridi2004}, this constitutes a category mistake: normative theories belong to a reflective LoA, whereas moral behaviour emerges at the cognitive LoA through complex interactions of salience, affect, social signalling, and controlled appraisal.

\noindent
Moral psychology and cognitive science provide a clear counterpoint to the Machine Ethics assumption. Decades of research show that moral behaviour is not generated by rule execution but by intuitive-affective processes \cite{Haidt2001}, conflict-sensitive valuation systems \cite{Greene2001}, affective-perceptual mappings \cite{Churchland2011}, and schema-based social cognition \cite{Narvaez2005}. Moral appraisal begins with rapid, pre-reflective resonance shaped by perceptual salience \cite{Phelps2006}, empathic responsiveness \cite{Zaki2012}, and contextual cues. The empirical results of this thesis reinforce these findings: robotic presence modifies salience structures upstream of conscious evaluation, consistent with work showing that synthetic agents alter social perception and norm-related behaviour even in minimal-interaction contexts \cite{Bremner2022,Malle2016,Kuchenbrandt2011}.

\noindent
Machine Ethics models fail to capture these mechanisms. Deontic architectures presuppose invariant constraints, yet even deontic cues---such as Watching-Eye effects \cite{Francey2012,Kawamura2017}---can be attenuated by the mere presence of a humanoid robot. Utilitarian architectures assume stable value gradients, yet the data show that gradients of perceived social consequence are flattened by ontological ambiguity \cite{Bremner2022}. Virtue-based systems assume globally stable traits, yet situationist critiques \cite{Doris2002} and schema ecologies \cite{Narvaez2005} reveal substantial dispositional heterogeneity; the experiment confirms that dispositional structure alone cannot explain behavioural attenuation. Sentimentalist architectures—which would predict affective resonance as a core driver of moral action—are almost entirely absent from Machine Ethics, despite overwhelming evidence that empathy and affective salience strongly modulate moral behaviour \cite{Zaki2012,Haidt2001}.

\noindent
The methodological failure is thus profound. Classical Machine Ethics implicitly assumes:
\[
\text{Normative authority} \;\Rightarrow\; \text{Behavioural generation}.
\]
This implication is falsified both empirically and theoretically. Normative principles---deontic, consequentialist, virtue-theoretic---do not by themselves generate behaviour, even in humans. Behaviour arises from the evaluative topology within which norms are interpreted. Watching-Eye cues generate deontic \emph{expectations}, but the behavioural manifestation of these expectations is perturbed by $\gamma_R$ at the level of attention, salience, and affective resonance. A normative rule cannot be enacted when the cognitive--affective substrate enabling its enactment is disrupted.

\noindent
For these reasons, monolithic Machine Ethics fails. It collapses reflective and cognitive LoAs, ignores the topological structure linking salience to action, neglects the role of affect and social signal processing in moral cognition, and treats moral behaviour as rule-following rather than field-sensitive, dynamically realised evaluation.

\subsection{Reconstructing Computational Morality: An Empirically Grounded Paradigm}
\noindent
If Machine Ethics fails because it begins with normative theory, the alternative must begin with \emph{empirical structure}. The present thesis advances a methodological reversal:

\begin{quote}
	\textbf{Computational Morality} begins not by encoding principles, but by modelling the cognitive--affective architecture through which moral behaviour is produced and perturbed.
\end{quote}

\paragraph{(1) Evaluative Topology as Generative Substrate}
Moral behaviour emerges from an evaluative manifold shaped by gradients of salience, attractor basins of affective resonance, normative invariants, and dispositional curvature \cite{Churchland2011}. Robotic presence is formalised as a perturbation operator:
\[
\gamma_R : \mathcal{E} \rightarrow \mathcal{E}',
\]
modifying attentional and affective weights and thereby predicting attenuation of prosocial behaviour without invoking rule-based computation.

\paragraph{(2) Level-of-Abstraction Discipline}
Normative theories enter as reflective structures operating at the normative LoA \cite{Floridi2008}. Deontology provides invariants, consequentialism gradients, virtue ethics dispositional metrics, sentimentalism affective vectors, contractualism justificatory equilibria, and particularism context-sensitive modulations. These structures constrain interpretation, not execution.

\paragraph{(3) Dispositional Ecologies as Moral Topologies}
The PCA--$k$-means clusters define dispositional geometries that shape evaluative trajectories: \emph{Emotionally Reactive} (broad, shallow attractors), \emph{Prosocial--Empathic} (steep affective gradients), and \emph{Analytical--Structured} (narrow, stable valleys). Synthetic presence perturbs the field upstream of these differences \cite{Bremner2022,Malle2016}, revealing that moral behaviour is topologically sensitive rather than trait-determined.

\subsection{Computational Morality as a Scientific Research Programme}
\noindent
The reconstructed paradigm transforms the methodological landscape of moral AI. Rather than engineering moral behaviour by encoding principles, \emph{Computational Morality} aims to:
\begin{enumerate}
	\item model the evaluative field governing moral behaviour;
	\item identify perturbation operators introduced by artificial agents;
	\item integrate normative theory as reflective constraint rather than behavioural generator;
	\item and design artificial systems that stabilise, rather than distort, the evaluative field.
\end{enumerate}
This paradigm extends Social Signal Processing \cite{Pentland2007,Vinciarelli2012} and Affective Computing \cite{Picard1997} by adding a normative dimension grounded not in abstract prescription but in empirically measurable topological structure.

\noindent
In this sense, the robot in the experiment is not an ethical agent but an \emph{evaluative perturbation device}. Its presence reveals the structural sensitivity of human moral cognition. A scientifically responsible programme of moral AI must begin from this insight: artificial agents shape the moral environment long before they act within it.

\noindent
The next section consolidates these findings into a global synthesis, showing how the normative, cognitive, and topological architectures developed across the thesis converge in a unified model of moral perturbation and ethical interpretation.

\section{Thesis-Wide Synthesis and Closing Reflections}
\label{sec:thesis_synthesis}

\noindent
Across its full argumentative trajectory, this thesis has advanced a single, unified claim: \emph{human moral behaviour is structurally sensitive to the architecture of the perceptual--social environment, and synthetic presence---even when silent and non-sentient---is sufficient to reshape that structure}. This concluding section synthesises the theoretical, empirical, and normative strands developed throughout the work and articulates the implications for computation, moral psychology, and the ethics of artificial agents.

\subsection*{1. Moral Cognition is Field-Sensitive and Structurally Rich}

\noindent
The \emph{Morality Primer} established that moral cognition is a distributed, multi-level, dynamically integrated system. Dual-process models, the Social Intuitionist Model, and empirical findings from social neuroscience converge on a view in which moral appraisal emerges from:

\begin{itemize}
	\item rapid affective and attentional processes,
	\item controlled interpretive regulation,
	\item and an evaluative topology shaped by salience, affective resonance, and contextual cues.
\end{itemize}

\noindent
This architecture is not neutral with respect to environmental perturbation. The field in which moral appraisal unfolds has curvature, gradients, attractors, and deformation potentials---all empirically traceable, neurocognitively plausible, and behaviourally measurable.

\subsection*{2. Levels of Abstraction and the Limits of Purely Normative Models}

\noindent
The \emph{Ethical Cognition and Normative Foundations} chapter showed that ethical theory and moral psychology occupy distinct Levels of Abstraction. Normative theories do not function as generative behavioural models; their role is to articulate invariant, justificatory, or virtue-theoretic structures that constrain or interpret behaviour at a reflective LoA.

\noindent
Machine Ethics has historically collapsed these orders, implementing deontic rules, utility functions, or evaluative labels as if they were cognitive operators. This thesis rejects that methodological inversion. Normative content becomes intelligible only when anchored in empirical structure; without such anchoring, computational morality risks degenerating into symbolic simulation devoid of psychological traction.

\subsection*{3. Empirical Evidence for Synthetic Moral Perturbation}

\noindent
Within this framework, the experiment plays a decisive role. It demonstrates that the presence of a humanoid robot:

\begin{itemize}
	\item attenuates prosocial donation in a statistically supported manner,
	\item does so even under a strong moral cue (the Watching-Eye prime),
	\item and produces a uniform directional displacement across dispositional ecologies, albeit with variation in magnitude.
\end{itemize}

\noindent
This attenuation is not reducible to personality differences, response bias, or explicit moral reasoning. The analysis shows that the robot functions as a perturbation operator $\gamma_R$ that modifies the evaluative field \emph{upstream} of trait-specific and deliberative processes. It acts on the conditions under which moral appraisal acquires behavioural force.

\subsection*{4. Dispositional Ecologies Reveal Structural, Not Idiosyncratic, Perturbation}

\noindent
The clustering analysis established three coherent dispositional ecologies:

\begin{itemize}
	\item \textbf{Emotionally Reactive / Low-Structure}, exhibiting broad low-gradient attractors and high affective volatility;
	\item \textbf{Prosocial--Empathic / Warm--Sociable}, with steep empathic gradients and strong responsiveness to social cues;
	\item \textbf{Analytical--Structured / High-Systemizing}, with narrow, stable attractors shaped by deliberative integration.
\end{itemize}

\noindent
Despite their divergent evaluative geometries, all clusters showed the same \emph{direction} of moral displacement. This finding is decisive: it shows that the perturbation is field-level, not agent-level. The robot reshapes the evaluative manifold within which trajectories unfold, rather than interacting with any single cognitive disposition. This is the empirical signature of a \emph{structural perturbator}.

\subsection*{5. Normative Interpretation of Structural Perturbation}

\noindent
The reconstructed normative frameworks illuminate the ethical significance of this empirical result:

\begin{itemize}
	\item deontologically, $\gamma_R$ disrupts the recognition of accountability cues implicit in the Watching-Eye stimulus;
	\item consequentially, it flattens the perceived payoff gradient of beneficence;
	\item virtuously, it weakens the stabilising force of prosocial dispositions;
	\item sentimentally, it dampens empathic vector fields that anchor reactive moral emotions;
	\item contractually, it disrupts justificatory visibility between moral agents;
	\item particularistically, it shifts the situational salience profile.
\end{itemize}

\noindent
These converging interpretations reveal the central structural insight of the thesis: \emph{the robot does not add a new norm; it shifts the evaluative conditions under which norms become behaviourally operative}.

\subsection*{6. Final Position of the Thesis}

\noindent
We may now return to the guiding hypotheses:

\begin{description}
	\item[\textbf{H1 — Evaluative Deformation}] \emph{Confirmed.} The evaluative process $f$ linking perception to action is systematically altered by synthetic presence.
	
	\item[\textbf{H2 — Synthetic Normativity}] \emph{Confirmed.} Synthetic agents acquire derivative normative force by altering the field of salience and accountability.
	
	\item[\textbf{H3 — Synthetic Perturbation of Moral Inference}] \emph{Confirmed.} The robot refracts the transition from moral appraisal to prosocial behaviour, attenuating the expressive force of the Watching-Eye cue.
\end{description}

\noindent
Accordingly, the thesis takes the following stand:

\begin{tcolorbox}[colback=white,colframe=black!75,title=Final Thesis Position (Definitive)]
	\emph{
		Human moral agency is not internally autonomous.  
		It is structurally coupled to the perceptual--social field in which it is embedded.  
		Synthetic agents, even when lacking sentience, intentionality, or communicative acts, act as  
		\textbf{modulators of that field}.  
		They reshape attentional gradients, dampen empathic resonance, and deform the topological  
		structures through which moral appraisal acquires behavioural expression.  
		Moral displacement under synthetic presence is therefore not a behavioural curiosity,  
		but a structural fact about the architecture of moral cognition.}
\end{tcolorbox}

\subsection*{7. Implications for the Future of Computational Morality}

\noindent
This final insight reshapes the methodological landscape. Artificial agents cannot be treated as moral subjects but must be understood as \textbf{moral modifiers}: entities whose design implicitly reconfigures the evaluative field. Future research in computational morality must therefore move beyond rule encoding and value annotation toward a structural science of moral environments, moral salience, and field-sensitive interaction.

\medskip

\noindent
In this sense, the thesis does not simply present an experimental result; it offers a new conceptual foundation for the empirical and ethical study of artificial agents. It reorients the field toward a \emph{topological}, \emph{empirically grounded}, and \emph{LoA-disciplined} understanding of moral cognition—one capable of addressing the forms of synthetic presence that will increasingly populate human social life.

\bigskip

\noindent
\emph{With this synthesis, the thesis closes. Its central claim is now complete:  
	moral behaviour is field-dependent, and synthetic presence reshapes that field.}